{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "union-alcohol",
      "metadata": {
        "id": "union-alcohol"
      },
      "source": [
        "# Activity 1.2 : Training Neural Networks - de Leon\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "floppy-teens",
      "metadata": {
        "id": "floppy-teens"
      },
      "source": [
        "#### Objective(s):\n",
        "\n",
        "This activity aims to demonstrate how to train neural networks using keras"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "engaged-modem",
      "metadata": {
        "id": "engaged-modem"
      },
      "source": [
        "#### Intended Learning Outcomes (ILOs):\n",
        "* Demonstrate how to build and train neural networks\n",
        "* Demonstrate how to evaluate and plot the model using training and validation loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "structured-april",
      "metadata": {
        "id": "structured-april"
      },
      "source": [
        "#### Resources:\n",
        "* Jupyter Notebook\n",
        "\n",
        "CI Pima Diabetes Dataset\n",
        "\n",
        "* pima-indians-diabetes.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cutting-fountain",
      "metadata": {
        "id": "cutting-fountain"
      },
      "source": [
        "#### Procedures"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "entertaining-therapist",
      "metadata": {
        "id": "entertaining-therapist"
      },
      "source": [
        "Load the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "differential-native",
      "metadata": {
        "id": "differential-native"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "other-married",
      "metadata": {
        "id": "other-married"
      },
      "outputs": [],
      "source": [
        "## Import Keras objects for Deep Learning\n",
        "\n",
        "from keras.models  import Sequential\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam, SGD, RMSprop"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mexican-newsletter",
      "metadata": {
        "id": "mexican-newsletter"
      },
      "source": [
        "Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "studied-twelve",
      "metadata": {
        "id": "studied-twelve"
      },
      "outputs": [],
      "source": [
        "\n",
        "filepath = \"pima-indians-diabetes.csv\"\n",
        "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\",\n",
        "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
        "diabetes_df = pd.read_csv(filepath, names=names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "photographic-carnival",
      "metadata": {
        "id": "photographic-carnival"
      },
      "source": [
        "Check the top 5 samples of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "undefined-inventory",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "undefined-inventory",
        "outputId": "bf13b5f6-dab8-47da-fafd-58051c45279c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(768, 9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
              "484               0                     145               0               0   \n",
              "42                7                     106              92              18   \n",
              "490               2                      83              65              28   \n",
              "392               1                     131              64              14   \n",
              "98                6                      93              50              30   \n",
              "\n",
              "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
              "484        0  44.2              0.630   31             1  \n",
              "42         0  22.7              0.235   48             0  \n",
              "490       66  36.8              0.629   24             0  \n",
              "392      415  23.7              0.389   21             0  \n",
              "98        64  28.7              0.356   23             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bb0e6261-9525-4075-bf0e-a3fadd2656ef\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>times_pregnant</th>\n",
              "      <th>glucose_tolerance_test</th>\n",
              "      <th>blood_pressure</th>\n",
              "      <th>skin_thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>pedigree_function</th>\n",
              "      <th>age</th>\n",
              "      <th>has_diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>484</th>\n",
              "      <td>0</td>\n",
              "      <td>145</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>44.2</td>\n",
              "      <td>0.630</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>7</td>\n",
              "      <td>106</td>\n",
              "      <td>92</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>22.7</td>\n",
              "      <td>0.235</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>490</th>\n",
              "      <td>2</td>\n",
              "      <td>83</td>\n",
              "      <td>65</td>\n",
              "      <td>28</td>\n",
              "      <td>66</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.629</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>392</th>\n",
              "      <td>1</td>\n",
              "      <td>131</td>\n",
              "      <td>64</td>\n",
              "      <td>14</td>\n",
              "      <td>415</td>\n",
              "      <td>23.7</td>\n",
              "      <td>0.389</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>6</td>\n",
              "      <td>93</td>\n",
              "      <td>50</td>\n",
              "      <td>30</td>\n",
              "      <td>64</td>\n",
              "      <td>28.7</td>\n",
              "      <td>0.356</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb0e6261-9525-4075-bf0e-a3fadd2656ef')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bb0e6261-9525-4075-bf0e-a3fadd2656ef button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bb0e6261-9525-4075-bf0e-a3fadd2656ef');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-11066c3b-11a5-478d-b840-cb6101453d78\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-11066c3b-11a5-478d-b840-cb6101453d78')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-11066c3b-11a5-478d-b840-cb6101453d78 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"diabetes_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"times_pregnant\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 7,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7,\n          6,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"glucose_tolerance_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25,\n        \"min\": 83,\n        \"max\": 145,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          106,\n          93,\n          83\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"blood_pressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 33,\n        \"min\": 0,\n        \"max\": 92,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          92,\n          50,\n          65\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"skin_thickness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 0,\n        \"max\": 30,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          18,\n          30,\n          28\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"insulin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 174,\n        \"min\": 0,\n        \"max\": 415,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          66,\n          64,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bmi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.152977657571332,\n        \"min\": 22.7,\n        \"max\": 44.2,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          22.7,\n          28.7,\n          36.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pedigree_function\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17549843304143772,\n        \"min\": 0.235,\n        \"max\": 0.63,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.235,\n          0.356,\n          0.629\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 21,\n        \"max\": 48,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          48,\n          23,\n          24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"has_diabetes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "\n",
        "print(diabetes_df.shape)\n",
        "diabetes_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "systematic-motorcycle",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "systematic-motorcycle",
        "outputId": "bfce52d5-9754-40d3-91be-07c567d5908d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "times_pregnant              int64\n",
              "glucose_tolerance_test      int64\n",
              "blood_pressure              int64\n",
              "skin_thickness              int64\n",
              "insulin                     int64\n",
              "bmi                       float64\n",
              "pedigree_function         float64\n",
              "age                         int64\n",
              "has_diabetes                int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "diabetes_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "collected-lafayette",
      "metadata": {
        "id": "collected-lafayette"
      },
      "outputs": [],
      "source": [
        "X = diabetes_df.iloc[:, :-1].values\n",
        "y = diabetes_df[\"has_diabetes\"].values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acquired-parallel",
      "metadata": {
        "id": "acquired-parallel"
      },
      "source": [
        "Split the data to Train, and Test (75%, 25%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rational-hollow",
      "metadata": {
        "id": "rational-hollow"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acceptable-equity",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acceptable-equity",
        "outputId": "2d5c2cf2-641e-4612-8740-eedab37a640a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3489583333333333, 0.6510416666666666)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "np.mean(y), np.mean(1-y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "thick-reconstruction",
      "metadata": {
        "id": "thick-reconstruction"
      },
      "source": [
        "Build a single hidden layer neural network using 12 nodes.\n",
        "Use the sequential model with single layer network and input shape to 8.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dramatic-zealand",
      "metadata": {
        "id": "dramatic-zealand"
      },
      "source": [
        "Normalize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "painted-mathematics",
      "metadata": {
        "id": "painted-mathematics"
      },
      "outputs": [],
      "source": [
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "previous-electricity",
      "metadata": {
        "id": "previous-electricity"
      },
      "source": [
        "Define the model:\n",
        "* Input size is 8-dimensional\n",
        "* 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
        "* Final layer with one node and sigmoid activation (standard for binary classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "found-bowling",
      "metadata": {
        "id": "found-bowling"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "model  = Sequential([\n",
        "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "level-terminal",
      "metadata": {
        "id": "level-terminal"
      },
      "source": [
        "View the model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "correct-kingdom",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "correct-kingdom",
        "outputId": "756735a2-bcae-4ff2-de35-4ccb1ac14a3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 12)                108       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 13        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121 (484.00 Byte)\n",
            "Trainable params: 121 (484.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "herbal-anderson",
      "metadata": {
        "id": "herbal-anderson"
      },
      "source": [
        "Train the model\n",
        "* Compile the model with optimizer, loss function and metrics\n",
        "* Use the fit function to return the run history.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "happy-prompt",
      "metadata": {
        "id": "happy-prompt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "697da484-6875-4ce2-c89f-6a7573386dc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "18/18 [==============================] - 1s 18ms/step - loss: 0.8656 - accuracy: 0.3976 - val_loss: 0.8793 - val_accuracy: 0.4271\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8257 - accuracy: 0.4201 - val_loss: 0.8393 - val_accuracy: 0.4531\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7912 - accuracy: 0.4566 - val_loss: 0.8048 - val_accuracy: 0.4948\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7612 - accuracy: 0.4844 - val_loss: 0.7749 - val_accuracy: 0.5417\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7348 - accuracy: 0.5208 - val_loss: 0.7491 - val_accuracy: 0.5573\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7116 - accuracy: 0.5486 - val_loss: 0.7265 - val_accuracy: 0.5833\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6908 - accuracy: 0.5799 - val_loss: 0.7063 - val_accuracy: 0.5938\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6059 - val_loss: 0.6882 - val_accuracy: 0.6094\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6560 - accuracy: 0.6302 - val_loss: 0.6722 - val_accuracy: 0.6354\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6411 - accuracy: 0.6476 - val_loss: 0.6578 - val_accuracy: 0.6615\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6278 - accuracy: 0.6701 - val_loss: 0.6449 - val_accuracy: 0.6875\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6157 - accuracy: 0.6840 - val_loss: 0.6330 - val_accuracy: 0.6875\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6044 - accuracy: 0.6927 - val_loss: 0.6220 - val_accuracy: 0.6979\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5940 - accuracy: 0.7135 - val_loss: 0.6119 - val_accuracy: 0.7083\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5844 - accuracy: 0.7222 - val_loss: 0.6026 - val_accuracy: 0.7135\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5755 - accuracy: 0.7240 - val_loss: 0.5940 - val_accuracy: 0.7031\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5673 - accuracy: 0.7309 - val_loss: 0.5863 - val_accuracy: 0.7083\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5596 - accuracy: 0.7344 - val_loss: 0.5790 - val_accuracy: 0.7031\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5524 - accuracy: 0.7431 - val_loss: 0.5723 - val_accuracy: 0.7240\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5457 - accuracy: 0.7517 - val_loss: 0.5663 - val_accuracy: 0.7188\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5393 - accuracy: 0.7552 - val_loss: 0.5607 - val_accuracy: 0.7240\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5334 - accuracy: 0.7587 - val_loss: 0.5555 - val_accuracy: 0.7188\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.7674 - val_loss: 0.5508 - val_accuracy: 0.7240\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5228 - accuracy: 0.7743 - val_loss: 0.5465 - val_accuracy: 0.7188\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5180 - accuracy: 0.7760 - val_loss: 0.5425 - val_accuracy: 0.7292\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5137 - accuracy: 0.7795 - val_loss: 0.5388 - val_accuracy: 0.7292\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5095 - accuracy: 0.7830 - val_loss: 0.5353 - val_accuracy: 0.7240\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5056 - accuracy: 0.7795 - val_loss: 0.5322 - val_accuracy: 0.7240\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5019 - accuracy: 0.7830 - val_loss: 0.5292 - val_accuracy: 0.7240\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4984 - accuracy: 0.7865 - val_loss: 0.5265 - val_accuracy: 0.7344\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4952 - accuracy: 0.7882 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4921 - accuracy: 0.7882 - val_loss: 0.5215 - val_accuracy: 0.7448\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.7865 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4864 - accuracy: 0.7882 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.7865 - val_loss: 0.5154 - val_accuracy: 0.7448\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.7917 - val_loss: 0.5137 - val_accuracy: 0.7448\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4790 - accuracy: 0.7934 - val_loss: 0.5122 - val_accuracy: 0.7448\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4768 - accuracy: 0.7934 - val_loss: 0.5107 - val_accuracy: 0.7448\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.7917 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4728 - accuracy: 0.7934 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7917 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7934 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.7934 - val_loss: 0.5050 - val_accuracy: 0.7448\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.7934 - val_loss: 0.5041 - val_accuracy: 0.7448\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7951 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7448\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7969 - val_loss: 0.5017 - val_accuracy: 0.7396\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7986 - val_loss: 0.5011 - val_accuracy: 0.7396\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.8003 - val_loss: 0.5004 - val_accuracy: 0.7396\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.8003 - val_loss: 0.4999 - val_accuracy: 0.7396\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4570 - accuracy: 0.8021 - val_loss: 0.4994 - val_accuracy: 0.7396\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.8021 - val_loss: 0.4989 - val_accuracy: 0.7396\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4549 - accuracy: 0.8056 - val_loss: 0.4984 - val_accuracy: 0.7344\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4540 - accuracy: 0.8056 - val_loss: 0.4980 - val_accuracy: 0.7344\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4529 - accuracy: 0.8056 - val_loss: 0.4976 - val_accuracy: 0.7344\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4521 - accuracy: 0.8038 - val_loss: 0.4973 - val_accuracy: 0.7344\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4513 - accuracy: 0.8038 - val_loss: 0.4970 - val_accuracy: 0.7344\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4503 - accuracy: 0.8056 - val_loss: 0.4967 - val_accuracy: 0.7344\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4496 - accuracy: 0.8056 - val_loss: 0.4964 - val_accuracy: 0.7344\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4489 - accuracy: 0.8056 - val_loss: 0.4962 - val_accuracy: 0.7344\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4481 - accuracy: 0.8056 - val_loss: 0.4959 - val_accuracy: 0.7344\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.8056 - val_loss: 0.4957 - val_accuracy: 0.7344\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4468 - accuracy: 0.8056 - val_loss: 0.4955 - val_accuracy: 0.7396\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4462 - accuracy: 0.8056 - val_loss: 0.4954 - val_accuracy: 0.7396\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4456 - accuracy: 0.8038 - val_loss: 0.4952 - val_accuracy: 0.7344\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4450 - accuracy: 0.8073 - val_loss: 0.4950 - val_accuracy: 0.7344\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4445 - accuracy: 0.8073 - val_loss: 0.4949 - val_accuracy: 0.7344\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4440 - accuracy: 0.8073 - val_loss: 0.4948 - val_accuracy: 0.7344\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4434 - accuracy: 0.8056 - val_loss: 0.4946 - val_accuracy: 0.7344\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4429 - accuracy: 0.8038 - val_loss: 0.4945 - val_accuracy: 0.7344\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4425 - accuracy: 0.8056 - val_loss: 0.4944 - val_accuracy: 0.7344\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4420 - accuracy: 0.8021 - val_loss: 0.4943 - val_accuracy: 0.7344\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4415 - accuracy: 0.8073 - val_loss: 0.4942 - val_accuracy: 0.7344\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.8038 - val_loss: 0.4941 - val_accuracy: 0.7344\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.8056 - val_loss: 0.4941 - val_accuracy: 0.7344\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.8056 - val_loss: 0.4940 - val_accuracy: 0.7344\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.8056 - val_loss: 0.4940 - val_accuracy: 0.7344\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.8056 - val_loss: 0.4940 - val_accuracy: 0.7344\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4390 - accuracy: 0.8056 - val_loss: 0.4940 - val_accuracy: 0.7344\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4388 - accuracy: 0.8090 - val_loss: 0.4939 - val_accuracy: 0.7344\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.8090 - val_loss: 0.4940 - val_accuracy: 0.7344\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.8090 - val_loss: 0.4940 - val_accuracy: 0.7344\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4377 - accuracy: 0.8090 - val_loss: 0.4940 - val_accuracy: 0.7344\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.8073 - val_loss: 0.4940 - val_accuracy: 0.7344\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.8056 - val_loss: 0.4940 - val_accuracy: 0.7344\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.8073 - val_loss: 0.4941 - val_accuracy: 0.7344\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4364 - accuracy: 0.8073 - val_loss: 0.4941 - val_accuracy: 0.7344\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.8073 - val_loss: 0.4942 - val_accuracy: 0.7344\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4358 - accuracy: 0.8073 - val_loss: 0.4943 - val_accuracy: 0.7344\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.8073 - val_loss: 0.4943 - val_accuracy: 0.7344\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.8073 - val_loss: 0.4944 - val_accuracy: 0.7344\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.8073 - val_loss: 0.4944 - val_accuracy: 0.7344\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.8056 - val_loss: 0.4945 - val_accuracy: 0.7344\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.8056 - val_loss: 0.4945 - val_accuracy: 0.7396\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4342 - accuracy: 0.8056 - val_loss: 0.4946 - val_accuracy: 0.7396\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.8073 - val_loss: 0.4947 - val_accuracy: 0.7396\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.8073 - val_loss: 0.4947 - val_accuracy: 0.7396\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.8056 - val_loss: 0.4948 - val_accuracy: 0.7396\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4334 - accuracy: 0.8073 - val_loss: 0.4948 - val_accuracy: 0.7396\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.8073 - val_loss: 0.4949 - val_accuracy: 0.7396\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.8073 - val_loss: 0.4949 - val_accuracy: 0.7396\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.8090 - val_loss: 0.4950 - val_accuracy: 0.7396\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4325 - accuracy: 0.8090 - val_loss: 0.4951 - val_accuracy: 0.7396\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.8090 - val_loss: 0.4951 - val_accuracy: 0.7396\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.8090 - val_loss: 0.4952 - val_accuracy: 0.7396\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.8073 - val_loss: 0.4952 - val_accuracy: 0.7396\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4318 - accuracy: 0.8090 - val_loss: 0.4953 - val_accuracy: 0.7396\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4317 - accuracy: 0.8090 - val_loss: 0.4953 - val_accuracy: 0.7396\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4314 - accuracy: 0.8090 - val_loss: 0.4954 - val_accuracy: 0.7396\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4313 - accuracy: 0.8090 - val_loss: 0.4954 - val_accuracy: 0.7344\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4311 - accuracy: 0.8090 - val_loss: 0.4955 - val_accuracy: 0.7344\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4310 - accuracy: 0.8090 - val_loss: 0.4955 - val_accuracy: 0.7344\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4308 - accuracy: 0.8090 - val_loss: 0.4956 - val_accuracy: 0.7344\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4307 - accuracy: 0.8090 - val_loss: 0.4956 - val_accuracy: 0.7344\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4305 - accuracy: 0.8090 - val_loss: 0.4957 - val_accuracy: 0.7344\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4304 - accuracy: 0.8090 - val_loss: 0.4957 - val_accuracy: 0.7292\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4301 - accuracy: 0.8090 - val_loss: 0.4957 - val_accuracy: 0.7292\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4300 - accuracy: 0.8090 - val_loss: 0.4958 - val_accuracy: 0.7292\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4297 - accuracy: 0.8073 - val_loss: 0.4958 - val_accuracy: 0.7292\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4296 - accuracy: 0.8073 - val_loss: 0.4958 - val_accuracy: 0.7292\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4295 - accuracy: 0.8073 - val_loss: 0.4959 - val_accuracy: 0.7292\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4293 - accuracy: 0.8073 - val_loss: 0.4959 - val_accuracy: 0.7292\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4290 - accuracy: 0.8073 - val_loss: 0.4959 - val_accuracy: 0.7292\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4288 - accuracy: 0.8090 - val_loss: 0.4960 - val_accuracy: 0.7292\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.4288 - accuracy: 0.8090 - val_loss: 0.4960 - val_accuracy: 0.7292\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4285 - accuracy: 0.8108 - val_loss: 0.4961 - val_accuracy: 0.7292\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.4284 - accuracy: 0.8090 - val_loss: 0.4961 - val_accuracy: 0.7292\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4282 - accuracy: 0.8073 - val_loss: 0.4962 - val_accuracy: 0.7292\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4280 - accuracy: 0.8090 - val_loss: 0.4962 - val_accuracy: 0.7292\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.4280 - accuracy: 0.8090 - val_loss: 0.4962 - val_accuracy: 0.7292\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4277 - accuracy: 0.8090 - val_loss: 0.4963 - val_accuracy: 0.7292\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4275 - accuracy: 0.8090 - val_loss: 0.4963 - val_accuracy: 0.7292\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4273 - accuracy: 0.8090 - val_loss: 0.4963 - val_accuracy: 0.7292\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4271 - accuracy: 0.8090 - val_loss: 0.4963 - val_accuracy: 0.7292\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4270 - accuracy: 0.8090 - val_loss: 0.4964 - val_accuracy: 0.7292\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4269 - accuracy: 0.8090 - val_loss: 0.4964 - val_accuracy: 0.7292\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.4267 - accuracy: 0.8090 - val_loss: 0.4964 - val_accuracy: 0.7292\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.4266 - accuracy: 0.8073 - val_loss: 0.4965 - val_accuracy: 0.7292\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.4264 - accuracy: 0.8090 - val_loss: 0.4965 - val_accuracy: 0.7292\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4262 - accuracy: 0.8090 - val_loss: 0.4965 - val_accuracy: 0.7292\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4260 - accuracy: 0.8090 - val_loss: 0.4965 - val_accuracy: 0.7292\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.4259 - accuracy: 0.8090 - val_loss: 0.4965 - val_accuracy: 0.7292\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4258 - accuracy: 0.8090 - val_loss: 0.4965 - val_accuracy: 0.7292\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.4257 - accuracy: 0.8073 - val_loss: 0.4965 - val_accuracy: 0.7292\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.4255 - accuracy: 0.8090 - val_loss: 0.4966 - val_accuracy: 0.7292\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4254 - accuracy: 0.8073 - val_loss: 0.4966 - val_accuracy: 0.7292\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.4252 - accuracy: 0.8073 - val_loss: 0.4966 - val_accuracy: 0.7292\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.4250 - accuracy: 0.8073 - val_loss: 0.4966 - val_accuracy: 0.7292\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4249 - accuracy: 0.8073 - val_loss: 0.4967 - val_accuracy: 0.7292\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.8073 - val_loss: 0.4967 - val_accuracy: 0.7292\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.8073 - val_loss: 0.4967 - val_accuracy: 0.7292\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.8073 - val_loss: 0.4968 - val_accuracy: 0.7292\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.8073 - val_loss: 0.4968 - val_accuracy: 0.7292\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.8073 - val_loss: 0.4968 - val_accuracy: 0.7292\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.8073 - val_loss: 0.4969 - val_accuracy: 0.7292\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.8073 - val_loss: 0.4969 - val_accuracy: 0.7292\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.8073 - val_loss: 0.4969 - val_accuracy: 0.7292\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.8073 - val_loss: 0.4969 - val_accuracy: 0.7292\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.8073 - val_loss: 0.4970 - val_accuracy: 0.7292\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4235 - accuracy: 0.8073 - val_loss: 0.4970 - val_accuracy: 0.7292\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.8073 - val_loss: 0.4970 - val_accuracy: 0.7292\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.8073 - val_loss: 0.4971 - val_accuracy: 0.7344\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.8073 - val_loss: 0.4971 - val_accuracy: 0.7344\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.8073 - val_loss: 0.4971 - val_accuracy: 0.7344\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.8073 - val_loss: 0.4971 - val_accuracy: 0.7344\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.8073 - val_loss: 0.4971 - val_accuracy: 0.7344\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.8056 - val_loss: 0.4971 - val_accuracy: 0.7396\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.8073 - val_loss: 0.4971 - val_accuracy: 0.7396\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.8073 - val_loss: 0.4971 - val_accuracy: 0.7396\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.8090 - val_loss: 0.4972 - val_accuracy: 0.7396\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.8056 - val_loss: 0.4972 - val_accuracy: 0.7396\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.8073 - val_loss: 0.4972 - val_accuracy: 0.7396\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.8090 - val_loss: 0.4972 - val_accuracy: 0.7396\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.8073 - val_loss: 0.4972 - val_accuracy: 0.7396\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.8073 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.8073 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.8073 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.8073 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.8073 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.8073 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.8073 - val_loss: 0.4975 - val_accuracy: 0.7448\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4208 - accuracy: 0.8073 - val_loss: 0.4975 - val_accuracy: 0.7448\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.8073 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.8073 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.8073 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.8073 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.8073 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4203 - accuracy: 0.8073 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4202 - accuracy: 0.8073 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.8073 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4199 - accuracy: 0.8073 - val_loss: 0.4978 - val_accuracy: 0.7448\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4199 - accuracy: 0.8073 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4198 - accuracy: 0.8073 - val_loss: 0.4978 - val_accuracy: 0.7448\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.8073 - val_loss: 0.4978 - val_accuracy: 0.7448\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.8073 - val_loss: 0.4978 - val_accuracy: 0.7448\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.8073 - val_loss: 0.4978 - val_accuracy: 0.7448\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.8073 - val_loss: 0.4978 - val_accuracy: 0.7448\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4193 - accuracy: 0.8073 - val_loss: 0.4979 - val_accuracy: 0.7448\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4193 - accuracy: 0.8073 - val_loss: 0.4979 - val_accuracy: 0.7448\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4192 - accuracy: 0.8073 - val_loss: 0.4980 - val_accuracy: 0.7448\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_1 = model.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "unsigned-nevada",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unsigned-nevada",
        "outputId": "99bf18ea-4c16-4630-cfc3-0566eb2dfda5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 3ms/step\n",
            "6/6 [==============================] - 0s 3ms/step\n"
          ]
        }
      ],
      "source": [
        "## Like we did for the Random Forest, we generate two kinds of predictions\n",
        "#  One is a hard decision, the other is a probabilitistic score.\n",
        "\n",
        "y_pred_class_nn_1 = model.predict(X_test_norm)\n",
        "y_pred_prob_nn_1 = model.predict(X_test_norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tough-catering",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tough-catering",
        "outputId": "ab90bd71-a5cf-4c34-a7e3-9e7dac8cc414"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.55269986],\n",
              "       [0.72737   ],\n",
              "       [0.33087015],\n",
              "       [0.14952181],\n",
              "       [0.2388396 ],\n",
              "       [0.5021038 ],\n",
              "       [0.01537702],\n",
              "       [0.24771738],\n",
              "       [0.9610592 ],\n",
              "       [0.1646194 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Let's check out the outputs to get a feel for how keras apis work.\n",
        "y_pred_class_nn_1[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "combined-zimbabwe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "combined-zimbabwe",
        "outputId": "be97e7c1-1190-4b75-d3ab-b6d609bf22d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.55269986],\n",
              "       [0.72737   ],\n",
              "       [0.33087015],\n",
              "       [0.14952181],\n",
              "       [0.2388396 ],\n",
              "       [0.5021038 ],\n",
              "       [0.01537702],\n",
              "       [0.24771738],\n",
              "       [0.9610592 ],\n",
              "       [0.1646194 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "y_pred_prob_nn_1[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "going-estonia",
      "metadata": {
        "id": "going-estonia"
      },
      "source": [
        "Create the plot_roc function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "supposed-moderator",
      "metadata": {
        "id": "supposed-moderator"
      },
      "outputs": [],
      "source": [
        "def plot_roc(y_test, y_pred, model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "second-festival",
      "metadata": {
        "id": "second-festival"
      },
      "source": [
        "Evaluate the model performance and plot the ROC CURVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eleven-nebraska",
      "metadata": {
        "id": "eleven-nebraska"
      },
      "outputs": [],
      "source": [
        "\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "invalid-nevada",
      "metadata": {
        "id": "invalid-nevada"
      },
      "source": [
        " Plot the training loss and the validation loss over the different epochs and see how it looks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hidden-physics",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hidden-physics",
        "outputId": "f9653988-04d2-4b12-c2b4-0992bea14266"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "run_hist_1.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "banned-spider",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "banned-spider",
        "outputId": "a0a6dc9d-880c-4875-a06d-7e96f4a23e05"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x78fe76c15990>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "superb-circus",
      "metadata": {
        "id": "superb-circus"
      },
      "source": [
        "What is your interpretation about the result of the train and validation loss?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "german-cherry",
      "metadata": {
        "id": "german-cherry"
      },
      "source": [
        "- The figure above denotes the process at which the neural network learns. We can see that for the initial epochs, the model has not yet encountered the data we had inputted initially, to which is then reflected with a high loss. However, as the model starts to make out the underlying relationships between the variables, the loss gradually goes down, indicating that the model is learning without overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "involved-slovak",
      "metadata": {
        "id": "involved-slovak"
      },
      "source": [
        "#### Supplementary Activity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pending-publisher",
      "metadata": {
        "id": "pending-publisher"
      },
      "source": [
        "* Build a model with two hidden layers, each with 6 nodes\n",
        "* Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
        "* Use a learning rate of .003 and train for 1500 epochs\n",
        "* Graph the trajectory of the loss functions, accuracy on both train and test set\n",
        "* Plot the roc curve for the predictions\n",
        "* Use different learning rates, numbers of epochs, and network structures.\n",
        "* Plot the results of training and validation loss using different learning rates, number of epocgs and network structures\n",
        "* Interpret your result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Build a model with two hidden layers, each with six nodes\n",
        "#use relu for the 2 hidden layers and sigmoid for the final layer\n",
        "\n",
        "model2 = Sequential()\n",
        "\n",
        "#hidden layer\n",
        "\n",
        "model2.add(Dense(6, activation = 'relu'))\n",
        "model2.add(Dense(6, activation = 'relu'))\n",
        "\n",
        "#output layer\n",
        "\n",
        "model2.add(Dense(1, activation = 'sigmoid'))"
      ],
      "metadata": {
        "id": "1aM5glFCfX0H"
      },
      "id": "1aM5glFCfX0H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#use a learning rate of .003 and train for 1500 epochs\n",
        "\n",
        "model2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_2 = model2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
      ],
      "metadata": {
        "id": "o74RtfH5hB3s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85228fae-abb9-4df1-89f5-9a6dd5922f63"
      },
      "id": "o74RtfH5hB3s",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1500\n",
            "18/18 [==============================] - 1s 14ms/step - loss: 1.3157 - accuracy: 0.3542 - val_loss: 1.0958 - val_accuracy: 0.3958\n",
            "Epoch 2/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9884 - accuracy: 0.4097 - val_loss: 0.8692 - val_accuracy: 0.4375\n",
            "Epoch 3/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8156 - accuracy: 0.5156 - val_loss: 0.7496 - val_accuracy: 0.5677\n",
            "Epoch 4/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7210 - accuracy: 0.6059 - val_loss: 0.6822 - val_accuracy: 0.6458\n",
            "Epoch 5/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6655 - accuracy: 0.6580 - val_loss: 0.6422 - val_accuracy: 0.6667\n",
            "Epoch 6/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6314 - accuracy: 0.7014 - val_loss: 0.6173 - val_accuracy: 0.6771\n",
            "Epoch 7/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6088 - accuracy: 0.7083 - val_loss: 0.6006 - val_accuracy: 0.7083\n",
            "Epoch 8/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5933 - accuracy: 0.6979 - val_loss: 0.5887 - val_accuracy: 0.7083\n",
            "Epoch 9/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5819 - accuracy: 0.7014 - val_loss: 0.5798 - val_accuracy: 0.7083\n",
            "Epoch 10/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5732 - accuracy: 0.7101 - val_loss: 0.5728 - val_accuracy: 0.7135\n",
            "Epoch 11/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5660 - accuracy: 0.7083 - val_loss: 0.5671 - val_accuracy: 0.7188\n",
            "Epoch 12/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5602 - accuracy: 0.7083 - val_loss: 0.5621 - val_accuracy: 0.7292\n",
            "Epoch 13/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5550 - accuracy: 0.7118 - val_loss: 0.5578 - val_accuracy: 0.7344\n",
            "Epoch 14/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5504 - accuracy: 0.7188 - val_loss: 0.5538 - val_accuracy: 0.7344\n",
            "Epoch 15/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5463 - accuracy: 0.7240 - val_loss: 0.5501 - val_accuracy: 0.7396\n",
            "Epoch 16/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5424 - accuracy: 0.7292 - val_loss: 0.5468 - val_accuracy: 0.7396\n",
            "Epoch 17/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5386 - accuracy: 0.7292 - val_loss: 0.5436 - val_accuracy: 0.7396\n",
            "Epoch 18/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5351 - accuracy: 0.7344 - val_loss: 0.5406 - val_accuracy: 0.7604\n",
            "Epoch 19/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5319 - accuracy: 0.7413 - val_loss: 0.5379 - val_accuracy: 0.7604\n",
            "Epoch 20/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5287 - accuracy: 0.7431 - val_loss: 0.5354 - val_accuracy: 0.7656\n",
            "Epoch 21/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5257 - accuracy: 0.7465 - val_loss: 0.5329 - val_accuracy: 0.7604\n",
            "Epoch 22/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5231 - accuracy: 0.7517 - val_loss: 0.5306 - val_accuracy: 0.7552\n",
            "Epoch 23/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5204 - accuracy: 0.7517 - val_loss: 0.5283 - val_accuracy: 0.7604\n",
            "Epoch 24/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5179 - accuracy: 0.7535 - val_loss: 0.5261 - val_accuracy: 0.7552\n",
            "Epoch 25/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5152 - accuracy: 0.7569 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
            "Epoch 26/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5127 - accuracy: 0.7552 - val_loss: 0.5221 - val_accuracy: 0.7552\n",
            "Epoch 27/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5105 - accuracy: 0.7587 - val_loss: 0.5203 - val_accuracy: 0.7552\n",
            "Epoch 28/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5083 - accuracy: 0.7604 - val_loss: 0.5186 - val_accuracy: 0.7552\n",
            "Epoch 29/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5063 - accuracy: 0.7587 - val_loss: 0.5170 - val_accuracy: 0.7552\n",
            "Epoch 30/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5043 - accuracy: 0.7604 - val_loss: 0.5154 - val_accuracy: 0.7552\n",
            "Epoch 31/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5025 - accuracy: 0.7569 - val_loss: 0.5139 - val_accuracy: 0.7552\n",
            "Epoch 32/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5007 - accuracy: 0.7587 - val_loss: 0.5125 - val_accuracy: 0.7552\n",
            "Epoch 33/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4991 - accuracy: 0.7604 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
            "Epoch 34/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.7604 - val_loss: 0.5101 - val_accuracy: 0.7552\n",
            "Epoch 35/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4960 - accuracy: 0.7622 - val_loss: 0.5090 - val_accuracy: 0.7552\n",
            "Epoch 36/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4947 - accuracy: 0.7639 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
            "Epoch 37/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4931 - accuracy: 0.7639 - val_loss: 0.5068 - val_accuracy: 0.7552\n",
            "Epoch 38/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4918 - accuracy: 0.7656 - val_loss: 0.5059 - val_accuracy: 0.7552\n",
            "Epoch 39/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4905 - accuracy: 0.7674 - val_loss: 0.5050 - val_accuracy: 0.7552\n",
            "Epoch 40/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.7674 - val_loss: 0.5041 - val_accuracy: 0.7500\n",
            "Epoch 41/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4880 - accuracy: 0.7708 - val_loss: 0.5034 - val_accuracy: 0.7500\n",
            "Epoch 42/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4868 - accuracy: 0.7708 - val_loss: 0.5028 - val_accuracy: 0.7552\n",
            "Epoch 43/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.7708 - val_loss: 0.5023 - val_accuracy: 0.7552\n",
            "Epoch 44/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4847 - accuracy: 0.7726 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
            "Epoch 45/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4837 - accuracy: 0.7726 - val_loss: 0.5013 - val_accuracy: 0.7552\n",
            "Epoch 46/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4827 - accuracy: 0.7760 - val_loss: 0.5008 - val_accuracy: 0.7656\n",
            "Epoch 47/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4818 - accuracy: 0.7726 - val_loss: 0.5003 - val_accuracy: 0.7604\n",
            "Epoch 48/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4811 - accuracy: 0.7708 - val_loss: 0.5000 - val_accuracy: 0.7604\n",
            "Epoch 49/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.7743 - val_loss: 0.4995 - val_accuracy: 0.7604\n",
            "Epoch 50/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4795 - accuracy: 0.7760 - val_loss: 0.4992 - val_accuracy: 0.7656\n",
            "Epoch 51/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4787 - accuracy: 0.7708 - val_loss: 0.4990 - val_accuracy: 0.7656\n",
            "Epoch 52/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.7708 - val_loss: 0.4987 - val_accuracy: 0.7656\n",
            "Epoch 53/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4773 - accuracy: 0.7674 - val_loss: 0.4985 - val_accuracy: 0.7656\n",
            "Epoch 54/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.7708 - val_loss: 0.4983 - val_accuracy: 0.7656\n",
            "Epoch 55/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4761 - accuracy: 0.7691 - val_loss: 0.4982 - val_accuracy: 0.7656\n",
            "Epoch 56/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.7726 - val_loss: 0.4980 - val_accuracy: 0.7656\n",
            "Epoch 57/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.7639 - val_loss: 0.4979 - val_accuracy: 0.7656\n",
            "Epoch 58/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4745 - accuracy: 0.7656 - val_loss: 0.4978 - val_accuracy: 0.7656\n",
            "Epoch 59/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4739 - accuracy: 0.7674 - val_loss: 0.4977 - val_accuracy: 0.7656\n",
            "Epoch 60/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.7639 - val_loss: 0.4976 - val_accuracy: 0.7604\n",
            "Epoch 61/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.7656 - val_loss: 0.4976 - val_accuracy: 0.7604\n",
            "Epoch 62/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7639 - val_loss: 0.4975 - val_accuracy: 0.7552\n",
            "Epoch 63/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.7639 - val_loss: 0.4974 - val_accuracy: 0.7500\n",
            "Epoch 64/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7656 - val_loss: 0.4973 - val_accuracy: 0.7500\n",
            "Epoch 65/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7674 - val_loss: 0.4973 - val_accuracy: 0.7500\n",
            "Epoch 66/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4708 - accuracy: 0.7674 - val_loss: 0.4972 - val_accuracy: 0.7500\n",
            "Epoch 67/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7674 - val_loss: 0.4971 - val_accuracy: 0.7552\n",
            "Epoch 68/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.7691 - val_loss: 0.4970 - val_accuracy: 0.7552\n",
            "Epoch 69/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4698 - accuracy: 0.7674 - val_loss: 0.4970 - val_accuracy: 0.7552\n",
            "Epoch 70/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7691 - val_loss: 0.4968 - val_accuracy: 0.7552\n",
            "Epoch 71/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4692 - accuracy: 0.7674 - val_loss: 0.4967 - val_accuracy: 0.7552\n",
            "Epoch 72/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4691 - accuracy: 0.7726 - val_loss: 0.4967 - val_accuracy: 0.7500\n",
            "Epoch 73/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4685 - accuracy: 0.7708 - val_loss: 0.4967 - val_accuracy: 0.7500\n",
            "Epoch 74/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.7691 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
            "Epoch 75/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4680 - accuracy: 0.7708 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
            "Epoch 76/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4678 - accuracy: 0.7726 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
            "Epoch 77/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7708 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
            "Epoch 78/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4672 - accuracy: 0.7691 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
            "Epoch 79/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7691 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
            "Epoch 80/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4666 - accuracy: 0.7691 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
            "Epoch 81/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4664 - accuracy: 0.7708 - val_loss: 0.4963 - val_accuracy: 0.7500\n",
            "Epoch 82/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4661 - accuracy: 0.7726 - val_loss: 0.4963 - val_accuracy: 0.7500\n",
            "Epoch 83/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4658 - accuracy: 0.7708 - val_loss: 0.4963 - val_accuracy: 0.7500\n",
            "Epoch 84/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4657 - accuracy: 0.7726 - val_loss: 0.4963 - val_accuracy: 0.7552\n",
            "Epoch 85/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4653 - accuracy: 0.7708 - val_loss: 0.4962 - val_accuracy: 0.7552\n",
            "Epoch 86/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4651 - accuracy: 0.7726 - val_loss: 0.4961 - val_accuracy: 0.7552\n",
            "Epoch 87/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4649 - accuracy: 0.7726 - val_loss: 0.4961 - val_accuracy: 0.7552\n",
            "Epoch 88/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4645 - accuracy: 0.7726 - val_loss: 0.4961 - val_accuracy: 0.7552\n",
            "Epoch 89/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4644 - accuracy: 0.7760 - val_loss: 0.4960 - val_accuracy: 0.7552\n",
            "Epoch 90/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4642 - accuracy: 0.7743 - val_loss: 0.4959 - val_accuracy: 0.7552\n",
            "Epoch 91/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4638 - accuracy: 0.7743 - val_loss: 0.4959 - val_accuracy: 0.7552\n",
            "Epoch 92/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7743 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
            "Epoch 93/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.7760 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
            "Epoch 94/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7743 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
            "Epoch 95/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4629 - accuracy: 0.7726 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
            "Epoch 96/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4628 - accuracy: 0.7726 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
            "Epoch 97/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4627 - accuracy: 0.7743 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
            "Epoch 98/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4623 - accuracy: 0.7726 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
            "Epoch 99/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4621 - accuracy: 0.7726 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
            "Epoch 100/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4620 - accuracy: 0.7726 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
            "Epoch 101/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4618 - accuracy: 0.7726 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
            "Epoch 102/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4617 - accuracy: 0.7726 - val_loss: 0.4957 - val_accuracy: 0.7656\n",
            "Epoch 103/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4614 - accuracy: 0.7743 - val_loss: 0.4958 - val_accuracy: 0.7656\n",
            "Epoch 104/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7708 - val_loss: 0.4957 - val_accuracy: 0.7656\n",
            "Epoch 105/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7708 - val_loss: 0.4957 - val_accuracy: 0.7656\n",
            "Epoch 106/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4608 - accuracy: 0.7726 - val_loss: 0.4958 - val_accuracy: 0.7656\n",
            "Epoch 107/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7708 - val_loss: 0.4958 - val_accuracy: 0.7656\n",
            "Epoch 108/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7726 - val_loss: 0.4958 - val_accuracy: 0.7656\n",
            "Epoch 109/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7726 - val_loss: 0.4959 - val_accuracy: 0.7656\n",
            "Epoch 110/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.7726 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
            "Epoch 111/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7726 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
            "Epoch 112/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4596 - accuracy: 0.7726 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
            "Epoch 113/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7708 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
            "Epoch 114/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7726 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
            "Epoch 115/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7708 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
            "Epoch 116/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7726 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
            "Epoch 117/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7726 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
            "Epoch 118/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4585 - accuracy: 0.7726 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
            "Epoch 119/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7743 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
            "Epoch 120/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7708 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
            "Epoch 121/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4578 - accuracy: 0.7708 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
            "Epoch 122/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4575 - accuracy: 0.7743 - val_loss: 0.4960 - val_accuracy: 0.7604\n",
            "Epoch 123/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7743 - val_loss: 0.4960 - val_accuracy: 0.7604\n",
            "Epoch 124/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4572 - accuracy: 0.7743 - val_loss: 0.4960 - val_accuracy: 0.7604\n",
            "Epoch 125/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7726 - val_loss: 0.4959 - val_accuracy: 0.7552\n",
            "Epoch 126/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7743 - val_loss: 0.4960 - val_accuracy: 0.7552\n",
            "Epoch 127/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7726 - val_loss: 0.4960 - val_accuracy: 0.7552\n",
            "Epoch 128/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4562 - accuracy: 0.7726 - val_loss: 0.4960 - val_accuracy: 0.7552\n",
            "Epoch 129/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4560 - accuracy: 0.7743 - val_loss: 0.4961 - val_accuracy: 0.7552\n",
            "Epoch 130/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.7708 - val_loss: 0.4960 - val_accuracy: 0.7552\n",
            "Epoch 131/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7743 - val_loss: 0.4959 - val_accuracy: 0.7552\n",
            "Epoch 132/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7743 - val_loss: 0.4958 - val_accuracy: 0.7552\n",
            "Epoch 133/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4550 - accuracy: 0.7726 - val_loss: 0.4959 - val_accuracy: 0.7552\n",
            "Epoch 134/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4547 - accuracy: 0.7743 - val_loss: 0.4957 - val_accuracy: 0.7552\n",
            "Epoch 135/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4544 - accuracy: 0.7726 - val_loss: 0.4956 - val_accuracy: 0.7552\n",
            "Epoch 136/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4540 - accuracy: 0.7743 - val_loss: 0.4956 - val_accuracy: 0.7552\n",
            "Epoch 137/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4538 - accuracy: 0.7708 - val_loss: 0.4955 - val_accuracy: 0.7552\n",
            "Epoch 138/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4538 - accuracy: 0.7726 - val_loss: 0.4954 - val_accuracy: 0.7552\n",
            "Epoch 139/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7708 - val_loss: 0.4954 - val_accuracy: 0.7552\n",
            "Epoch 140/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4531 - accuracy: 0.7708 - val_loss: 0.4954 - val_accuracy: 0.7552\n",
            "Epoch 141/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4529 - accuracy: 0.7726 - val_loss: 0.4954 - val_accuracy: 0.7552\n",
            "Epoch 142/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7708 - val_loss: 0.4953 - val_accuracy: 0.7552\n",
            "Epoch 143/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4523 - accuracy: 0.7708 - val_loss: 0.4954 - val_accuracy: 0.7552\n",
            "Epoch 144/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4522 - accuracy: 0.7708 - val_loss: 0.4953 - val_accuracy: 0.7552\n",
            "Epoch 145/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7708 - val_loss: 0.4953 - val_accuracy: 0.7552\n",
            "Epoch 146/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7708 - val_loss: 0.4954 - val_accuracy: 0.7552\n",
            "Epoch 147/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4516 - accuracy: 0.7726 - val_loss: 0.4954 - val_accuracy: 0.7552\n",
            "Epoch 148/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7726 - val_loss: 0.4954 - val_accuracy: 0.7552\n",
            "Epoch 149/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4510 - accuracy: 0.7708 - val_loss: 0.4954 - val_accuracy: 0.7552\n",
            "Epoch 150/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.7726 - val_loss: 0.4955 - val_accuracy: 0.7552\n",
            "Epoch 151/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7708 - val_loss: 0.4956 - val_accuracy: 0.7552\n",
            "Epoch 152/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4506 - accuracy: 0.7743 - val_loss: 0.4956 - val_accuracy: 0.7604\n",
            "Epoch 153/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.7726 - val_loss: 0.4955 - val_accuracy: 0.7604\n",
            "Epoch 154/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7743 - val_loss: 0.4956 - val_accuracy: 0.7604\n",
            "Epoch 155/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4500 - accuracy: 0.7760 - val_loss: 0.4956 - val_accuracy: 0.7604\n",
            "Epoch 156/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4499 - accuracy: 0.7760 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
            "Epoch 157/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4497 - accuracy: 0.7760 - val_loss: 0.4958 - val_accuracy: 0.7552\n",
            "Epoch 158/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4495 - accuracy: 0.7760 - val_loss: 0.4958 - val_accuracy: 0.7552\n",
            "Epoch 159/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4493 - accuracy: 0.7760 - val_loss: 0.4958 - val_accuracy: 0.7552\n",
            "Epoch 160/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4492 - accuracy: 0.7760 - val_loss: 0.4959 - val_accuracy: 0.7552\n",
            "Epoch 161/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.7743 - val_loss: 0.4959 - val_accuracy: 0.7552\n",
            "Epoch 162/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7760 - val_loss: 0.4959 - val_accuracy: 0.7552\n",
            "Epoch 163/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7760 - val_loss: 0.4959 - val_accuracy: 0.7552\n",
            "Epoch 164/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4486 - accuracy: 0.7778 - val_loss: 0.4961 - val_accuracy: 0.7552\n",
            "Epoch 165/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.7760 - val_loss: 0.4962 - val_accuracy: 0.7552\n",
            "Epoch 166/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.7760 - val_loss: 0.4962 - val_accuracy: 0.7552\n",
            "Epoch 167/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4481 - accuracy: 0.7760 - val_loss: 0.4963 - val_accuracy: 0.7552\n",
            "Epoch 168/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4479 - accuracy: 0.7760 - val_loss: 0.4963 - val_accuracy: 0.7552\n",
            "Epoch 169/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7778 - val_loss: 0.4964 - val_accuracy: 0.7552\n",
            "Epoch 170/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.7760 - val_loss: 0.4965 - val_accuracy: 0.7552\n",
            "Epoch 171/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4474 - accuracy: 0.7795 - val_loss: 0.4966 - val_accuracy: 0.7552\n",
            "Epoch 172/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4473 - accuracy: 0.7760 - val_loss: 0.4967 - val_accuracy: 0.7552\n",
            "Epoch 173/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4471 - accuracy: 0.7760 - val_loss: 0.4968 - val_accuracy: 0.7552\n",
            "Epoch 174/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7795 - val_loss: 0.4968 - val_accuracy: 0.7552\n",
            "Epoch 175/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4468 - accuracy: 0.7795 - val_loss: 0.4969 - val_accuracy: 0.7552\n",
            "Epoch 176/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4467 - accuracy: 0.7795 - val_loss: 0.4968 - val_accuracy: 0.7552\n",
            "Epoch 177/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7795 - val_loss: 0.4969 - val_accuracy: 0.7552\n",
            "Epoch 178/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7795 - val_loss: 0.4969 - val_accuracy: 0.7552\n",
            "Epoch 179/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4464 - accuracy: 0.7795 - val_loss: 0.4969 - val_accuracy: 0.7552\n",
            "Epoch 180/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4463 - accuracy: 0.7778 - val_loss: 0.4970 - val_accuracy: 0.7552\n",
            "Epoch 181/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.7812 - val_loss: 0.4970 - val_accuracy: 0.7552\n",
            "Epoch 182/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7795 - val_loss: 0.4971 - val_accuracy: 0.7552\n",
            "Epoch 183/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4459 - accuracy: 0.7812 - val_loss: 0.4972 - val_accuracy: 0.7604\n",
            "Epoch 184/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4459 - accuracy: 0.7778 - val_loss: 0.4973 - val_accuracy: 0.7604\n",
            "Epoch 185/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7812 - val_loss: 0.4973 - val_accuracy: 0.7604\n",
            "Epoch 186/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7812 - val_loss: 0.4973 - val_accuracy: 0.7604\n",
            "Epoch 187/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7795 - val_loss: 0.4975 - val_accuracy: 0.7604\n",
            "Epoch 188/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4454 - accuracy: 0.7812 - val_loss: 0.4975 - val_accuracy: 0.7604\n",
            "Epoch 189/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7812 - val_loss: 0.4976 - val_accuracy: 0.7604\n",
            "Epoch 190/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7812 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
            "Epoch 191/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.7830 - val_loss: 0.4978 - val_accuracy: 0.7604\n",
            "Epoch 192/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.7795 - val_loss: 0.4978 - val_accuracy: 0.7604\n",
            "Epoch 193/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7812 - val_loss: 0.4979 - val_accuracy: 0.7604\n",
            "Epoch 194/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7830 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
            "Epoch 195/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.7830 - val_loss: 0.4981 - val_accuracy: 0.7604\n",
            "Epoch 196/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4444 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7604\n",
            "Epoch 197/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7604\n",
            "Epoch 198/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.7830 - val_loss: 0.4983 - val_accuracy: 0.7604\n",
            "Epoch 199/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4439 - accuracy: 0.7812 - val_loss: 0.4984 - val_accuracy: 0.7604\n",
            "Epoch 200/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4439 - accuracy: 0.7830 - val_loss: 0.4984 - val_accuracy: 0.7604\n",
            "Epoch 201/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4436 - accuracy: 0.7812 - val_loss: 0.4985 - val_accuracy: 0.7604\n",
            "Epoch 202/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4436 - accuracy: 0.7830 - val_loss: 0.4986 - val_accuracy: 0.7656\n",
            "Epoch 203/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4434 - accuracy: 0.7830 - val_loss: 0.4987 - val_accuracy: 0.7656\n",
            "Epoch 204/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4433 - accuracy: 0.7830 - val_loss: 0.4988 - val_accuracy: 0.7656\n",
            "Epoch 205/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4432 - accuracy: 0.7812 - val_loss: 0.4990 - val_accuracy: 0.7656\n",
            "Epoch 206/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4430 - accuracy: 0.7830 - val_loss: 0.4991 - val_accuracy: 0.7656\n",
            "Epoch 207/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4429 - accuracy: 0.7830 - val_loss: 0.4992 - val_accuracy: 0.7656\n",
            "Epoch 208/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.7812 - val_loss: 0.4992 - val_accuracy: 0.7656\n",
            "Epoch 209/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4427 - accuracy: 0.7830 - val_loss: 0.4994 - val_accuracy: 0.7656\n",
            "Epoch 210/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4426 - accuracy: 0.7812 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
            "Epoch 211/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4425 - accuracy: 0.7812 - val_loss: 0.4994 - val_accuracy: 0.7656\n",
            "Epoch 212/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4423 - accuracy: 0.7812 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
            "Epoch 213/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4421 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
            "Epoch 214/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.7812 - val_loss: 0.4998 - val_accuracy: 0.7656\n",
            "Epoch 215/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4420 - accuracy: 0.7812 - val_loss: 0.4998 - val_accuracy: 0.7656\n",
            "Epoch 216/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4419 - accuracy: 0.7812 - val_loss: 0.4998 - val_accuracy: 0.7656\n",
            "Epoch 217/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4417 - accuracy: 0.7812 - val_loss: 0.4999 - val_accuracy: 0.7656\n",
            "Epoch 218/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4415 - accuracy: 0.7830 - val_loss: 0.5000 - val_accuracy: 0.7656\n",
            "Epoch 219/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4416 - accuracy: 0.7812 - val_loss: 0.5001 - val_accuracy: 0.7656\n",
            "Epoch 220/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4414 - accuracy: 0.7812 - val_loss: 0.5002 - val_accuracy: 0.7656\n",
            "Epoch 221/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4412 - accuracy: 0.7812 - val_loss: 0.5003 - val_accuracy: 0.7656\n",
            "Epoch 222/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7812 - val_loss: 0.5003 - val_accuracy: 0.7656\n",
            "Epoch 223/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7812 - val_loss: 0.5004 - val_accuracy: 0.7604\n",
            "Epoch 224/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4412 - accuracy: 0.7812 - val_loss: 0.5003 - val_accuracy: 0.7604\n",
            "Epoch 225/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4409 - accuracy: 0.7812 - val_loss: 0.5004 - val_accuracy: 0.7604\n",
            "Epoch 226/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.7795 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
            "Epoch 227/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.7812 - val_loss: 0.5008 - val_accuracy: 0.7552\n",
            "Epoch 228/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7795 - val_loss: 0.5008 - val_accuracy: 0.7552\n",
            "Epoch 229/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7812 - val_loss: 0.5009 - val_accuracy: 0.7552\n",
            "Epoch 230/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.7812 - val_loss: 0.5010 - val_accuracy: 0.7552\n",
            "Epoch 231/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7812 - val_loss: 0.5011 - val_accuracy: 0.7552\n",
            "Epoch 232/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4402 - accuracy: 0.7795 - val_loss: 0.5013 - val_accuracy: 0.7552\n",
            "Epoch 233/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4402 - accuracy: 0.7795 - val_loss: 0.5013 - val_accuracy: 0.7552\n",
            "Epoch 234/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4399 - accuracy: 0.7795 - val_loss: 0.5014 - val_accuracy: 0.7552\n",
            "Epoch 235/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7795 - val_loss: 0.5014 - val_accuracy: 0.7552\n",
            "Epoch 236/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4396 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 237/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7812 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 238/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7812 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
            "Epoch 239/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7812 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 240/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7812 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 241/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4389 - accuracy: 0.7795 - val_loss: 0.5021 - val_accuracy: 0.7552\n",
            "Epoch 242/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4388 - accuracy: 0.7812 - val_loss: 0.5021 - val_accuracy: 0.7552\n",
            "Epoch 243/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7795 - val_loss: 0.5022 - val_accuracy: 0.7552\n",
            "Epoch 244/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7795 - val_loss: 0.5023 - val_accuracy: 0.7552\n",
            "Epoch 245/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7830 - val_loss: 0.5023 - val_accuracy: 0.7552\n",
            "Epoch 246/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7812 - val_loss: 0.5025 - val_accuracy: 0.7552\n",
            "Epoch 247/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7812 - val_loss: 0.5026 - val_accuracy: 0.7552\n",
            "Epoch 248/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4381 - accuracy: 0.7812 - val_loss: 0.5027 - val_accuracy: 0.7552\n",
            "Epoch 249/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4381 - accuracy: 0.7795 - val_loss: 0.5027 - val_accuracy: 0.7552\n",
            "Epoch 250/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7795 - val_loss: 0.5027 - val_accuracy: 0.7552\n",
            "Epoch 251/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7812 - val_loss: 0.5028 - val_accuracy: 0.7552\n",
            "Epoch 252/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4378 - accuracy: 0.7830 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
            "Epoch 253/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4378 - accuracy: 0.7812 - val_loss: 0.5030 - val_accuracy: 0.7552\n",
            "Epoch 254/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4375 - accuracy: 0.7795 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
            "Epoch 255/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4376 - accuracy: 0.7812 - val_loss: 0.5030 - val_accuracy: 0.7552\n",
            "Epoch 256/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7812 - val_loss: 0.5031 - val_accuracy: 0.7552\n",
            "Epoch 257/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7830 - val_loss: 0.5031 - val_accuracy: 0.7552\n",
            "Epoch 258/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4373 - accuracy: 0.7830 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 259/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4372 - accuracy: 0.7812 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 260/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7830 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 261/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7812 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 262/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4371 - accuracy: 0.7812 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 263/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.7812 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 264/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.7812 - val_loss: 0.5034 - val_accuracy: 0.7552\n",
            "Epoch 265/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4367 - accuracy: 0.7812 - val_loss: 0.5035 - val_accuracy: 0.7552\n",
            "Epoch 266/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7812 - val_loss: 0.5035 - val_accuracy: 0.7552\n",
            "Epoch 267/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7812 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
            "Epoch 268/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7812 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
            "Epoch 269/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4363 - accuracy: 0.7795 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 270/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7812 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 271/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7812 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 272/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7795 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
            "Epoch 273/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4359 - accuracy: 0.7795 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
            "Epoch 274/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4357 - accuracy: 0.7812 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
            "Epoch 275/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4358 - accuracy: 0.7830 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
            "Epoch 276/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4357 - accuracy: 0.7812 - val_loss: 0.5048 - val_accuracy: 0.7552\n",
            "Epoch 277/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7830 - val_loss: 0.5050 - val_accuracy: 0.7552\n",
            "Epoch 278/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4355 - accuracy: 0.7812 - val_loss: 0.5050 - val_accuracy: 0.7552\n",
            "Epoch 279/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7812 - val_loss: 0.5050 - val_accuracy: 0.7552\n",
            "Epoch 280/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4354 - accuracy: 0.7778 - val_loss: 0.5049 - val_accuracy: 0.7552\n",
            "Epoch 281/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7830 - val_loss: 0.5049 - val_accuracy: 0.7552\n",
            "Epoch 282/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7830 - val_loss: 0.5049 - val_accuracy: 0.7552\n",
            "Epoch 283/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7795 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
            "Epoch 284/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4351 - accuracy: 0.7795 - val_loss: 0.5050 - val_accuracy: 0.7604\n",
            "Epoch 285/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4351 - accuracy: 0.7760 - val_loss: 0.5051 - val_accuracy: 0.7604\n",
            "Epoch 286/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.7795 - val_loss: 0.5052 - val_accuracy: 0.7604\n",
            "Epoch 287/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4348 - accuracy: 0.7795 - val_loss: 0.5053 - val_accuracy: 0.7604\n",
            "Epoch 288/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4348 - accuracy: 0.7778 - val_loss: 0.5056 - val_accuracy: 0.7552\n",
            "Epoch 289/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7812 - val_loss: 0.5058 - val_accuracy: 0.7552\n",
            "Epoch 290/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4346 - accuracy: 0.7778 - val_loss: 0.5058 - val_accuracy: 0.7552\n",
            "Epoch 291/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7778 - val_loss: 0.5061 - val_accuracy: 0.7552\n",
            "Epoch 292/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7795 - val_loss: 0.5061 - val_accuracy: 0.7552\n",
            "Epoch 293/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7795 - val_loss: 0.5062 - val_accuracy: 0.7552\n",
            "Epoch 294/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4344 - accuracy: 0.7743 - val_loss: 0.5064 - val_accuracy: 0.7552\n",
            "Epoch 295/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7743 - val_loss: 0.5067 - val_accuracy: 0.7552\n",
            "Epoch 296/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4342 - accuracy: 0.7760 - val_loss: 0.5067 - val_accuracy: 0.7552\n",
            "Epoch 297/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4341 - accuracy: 0.7760 - val_loss: 0.5068 - val_accuracy: 0.7552\n",
            "Epoch 298/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7760 - val_loss: 0.5069 - val_accuracy: 0.7552\n",
            "Epoch 299/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4340 - accuracy: 0.7760 - val_loss: 0.5070 - val_accuracy: 0.7604\n",
            "Epoch 300/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.7760 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
            "Epoch 301/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7795 - val_loss: 0.5073 - val_accuracy: 0.7708\n",
            "Epoch 302/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.7743 - val_loss: 0.5072 - val_accuracy: 0.7708\n",
            "Epoch 303/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.7778 - val_loss: 0.5074 - val_accuracy: 0.7708\n",
            "Epoch 304/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.7795 - val_loss: 0.5076 - val_accuracy: 0.7708\n",
            "Epoch 305/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4334 - accuracy: 0.7760 - val_loss: 0.5077 - val_accuracy: 0.7708\n",
            "Epoch 306/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7760 - val_loss: 0.5076 - val_accuracy: 0.7708\n",
            "Epoch 307/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7760 - val_loss: 0.5077 - val_accuracy: 0.7708\n",
            "Epoch 308/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.7778 - val_loss: 0.5079 - val_accuracy: 0.7708\n",
            "Epoch 309/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7812 - val_loss: 0.5081 - val_accuracy: 0.7708\n",
            "Epoch 310/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4332 - accuracy: 0.7812 - val_loss: 0.5083 - val_accuracy: 0.7708\n",
            "Epoch 311/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4330 - accuracy: 0.7778 - val_loss: 0.5084 - val_accuracy: 0.7708\n",
            "Epoch 312/1500\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.4331 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7708\n",
            "Epoch 313/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4329 - accuracy: 0.7812 - val_loss: 0.5087 - val_accuracy: 0.7708\n",
            "Epoch 314/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4330 - accuracy: 0.7778 - val_loss: 0.5088 - val_accuracy: 0.7708\n",
            "Epoch 315/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4327 - accuracy: 0.7795 - val_loss: 0.5089 - val_accuracy: 0.7708\n",
            "Epoch 316/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4327 - accuracy: 0.7812 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
            "Epoch 317/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7812 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
            "Epoch 318/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4324 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
            "Epoch 319/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7795 - val_loss: 0.5095 - val_accuracy: 0.7708\n",
            "Epoch 320/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4323 - accuracy: 0.7778 - val_loss: 0.5095 - val_accuracy: 0.7708\n",
            "Epoch 321/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4323 - accuracy: 0.7795 - val_loss: 0.5096 - val_accuracy: 0.7708\n",
            "Epoch 322/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4320 - accuracy: 0.7795 - val_loss: 0.5098 - val_accuracy: 0.7708\n",
            "Epoch 323/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4323 - accuracy: 0.7812 - val_loss: 0.5099 - val_accuracy: 0.7708\n",
            "Epoch 324/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.7812 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
            "Epoch 325/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4319 - accuracy: 0.7812 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
            "Epoch 326/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4319 - accuracy: 0.7812 - val_loss: 0.5104 - val_accuracy: 0.7708\n",
            "Epoch 327/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4320 - accuracy: 0.7795 - val_loss: 0.5105 - val_accuracy: 0.7708\n",
            "Epoch 328/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4315 - accuracy: 0.7830 - val_loss: 0.5106 - val_accuracy: 0.7708\n",
            "Epoch 329/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4318 - accuracy: 0.7812 - val_loss: 0.5106 - val_accuracy: 0.7708\n",
            "Epoch 330/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4317 - accuracy: 0.7812 - val_loss: 0.5108 - val_accuracy: 0.7708\n",
            "Epoch 331/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4314 - accuracy: 0.7830 - val_loss: 0.5111 - val_accuracy: 0.7656\n",
            "Epoch 332/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.7795 - val_loss: 0.5111 - val_accuracy: 0.7708\n",
            "Epoch 333/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4313 - accuracy: 0.7830 - val_loss: 0.5112 - val_accuracy: 0.7708\n",
            "Epoch 334/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4313 - accuracy: 0.7847 - val_loss: 0.5114 - val_accuracy: 0.7708\n",
            "Epoch 335/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4312 - accuracy: 0.7830 - val_loss: 0.5116 - val_accuracy: 0.7708\n",
            "Epoch 336/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4310 - accuracy: 0.7795 - val_loss: 0.5116 - val_accuracy: 0.7708\n",
            "Epoch 337/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4311 - accuracy: 0.7812 - val_loss: 0.5118 - val_accuracy: 0.7708\n",
            "Epoch 338/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4310 - accuracy: 0.7778 - val_loss: 0.5119 - val_accuracy: 0.7708\n",
            "Epoch 339/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4311 - accuracy: 0.7812 - val_loss: 0.5121 - val_accuracy: 0.7708\n",
            "Epoch 340/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4309 - accuracy: 0.7795 - val_loss: 0.5122 - val_accuracy: 0.7708\n",
            "Epoch 341/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4307 - accuracy: 0.7795 - val_loss: 0.5122 - val_accuracy: 0.7708\n",
            "Epoch 342/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4307 - accuracy: 0.7812 - val_loss: 0.5123 - val_accuracy: 0.7708\n",
            "Epoch 343/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4306 - accuracy: 0.7812 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
            "Epoch 344/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4305 - accuracy: 0.7795 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
            "Epoch 345/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4304 - accuracy: 0.7795 - val_loss: 0.5124 - val_accuracy: 0.7708\n",
            "Epoch 346/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4306 - accuracy: 0.7795 - val_loss: 0.5126 - val_accuracy: 0.7708\n",
            "Epoch 347/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4304 - accuracy: 0.7812 - val_loss: 0.5127 - val_accuracy: 0.7708\n",
            "Epoch 348/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7778 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
            "Epoch 349/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7795 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
            "Epoch 350/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7795 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
            "Epoch 351/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4301 - accuracy: 0.7778 - val_loss: 0.5130 - val_accuracy: 0.7708\n",
            "Epoch 352/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4301 - accuracy: 0.7812 - val_loss: 0.5132 - val_accuracy: 0.7708\n",
            "Epoch 353/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7830 - val_loss: 0.5133 - val_accuracy: 0.7708\n",
            "Epoch 354/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7830 - val_loss: 0.5133 - val_accuracy: 0.7708\n",
            "Epoch 355/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7795 - val_loss: 0.5135 - val_accuracy: 0.7708\n",
            "Epoch 356/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7812 - val_loss: 0.5135 - val_accuracy: 0.7708\n",
            "Epoch 357/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7830 - val_loss: 0.5136 - val_accuracy: 0.7708\n",
            "Epoch 358/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4299 - accuracy: 0.7812 - val_loss: 0.5137 - val_accuracy: 0.7708\n",
            "Epoch 359/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7760 - val_loss: 0.5137 - val_accuracy: 0.7708\n",
            "Epoch 360/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.7812 - val_loss: 0.5139 - val_accuracy: 0.7708\n",
            "Epoch 361/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4295 - accuracy: 0.7812 - val_loss: 0.5140 - val_accuracy: 0.7708\n",
            "Epoch 362/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.7778 - val_loss: 0.5140 - val_accuracy: 0.7708\n",
            "Epoch 363/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4294 - accuracy: 0.7795 - val_loss: 0.5142 - val_accuracy: 0.7708\n",
            "Epoch 364/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4293 - accuracy: 0.7812 - val_loss: 0.5142 - val_accuracy: 0.7708\n",
            "Epoch 365/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4293 - accuracy: 0.7812 - val_loss: 0.5143 - val_accuracy: 0.7656\n",
            "Epoch 366/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7847 - val_loss: 0.5143 - val_accuracy: 0.7656\n",
            "Epoch 367/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7812 - val_loss: 0.5144 - val_accuracy: 0.7656\n",
            "Epoch 368/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7812 - val_loss: 0.5144 - val_accuracy: 0.7656\n",
            "Epoch 369/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4291 - accuracy: 0.7778 - val_loss: 0.5146 - val_accuracy: 0.7656\n",
            "Epoch 370/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4290 - accuracy: 0.7778 - val_loss: 0.5145 - val_accuracy: 0.7656\n",
            "Epoch 371/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4291 - accuracy: 0.7812 - val_loss: 0.5146 - val_accuracy: 0.7656\n",
            "Epoch 372/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4290 - accuracy: 0.7778 - val_loss: 0.5147 - val_accuracy: 0.7656\n",
            "Epoch 373/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4288 - accuracy: 0.7795 - val_loss: 0.5147 - val_accuracy: 0.7656\n",
            "Epoch 374/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.7795 - val_loss: 0.5148 - val_accuracy: 0.7656\n",
            "Epoch 375/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7778 - val_loss: 0.5149 - val_accuracy: 0.7656\n",
            "Epoch 376/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7795 - val_loss: 0.5151 - val_accuracy: 0.7656\n",
            "Epoch 377/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.7795 - val_loss: 0.5151 - val_accuracy: 0.7656\n",
            "Epoch 378/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4285 - accuracy: 0.7760 - val_loss: 0.5152 - val_accuracy: 0.7656\n",
            "Epoch 379/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.7812 - val_loss: 0.5152 - val_accuracy: 0.7656\n",
            "Epoch 380/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4283 - accuracy: 0.7812 - val_loss: 0.5153 - val_accuracy: 0.7656\n",
            "Epoch 381/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.7795 - val_loss: 0.5153 - val_accuracy: 0.7656\n",
            "Epoch 382/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4283 - accuracy: 0.7778 - val_loss: 0.5153 - val_accuracy: 0.7604\n",
            "Epoch 383/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.7812 - val_loss: 0.5157 - val_accuracy: 0.7604\n",
            "Epoch 384/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.7795 - val_loss: 0.5158 - val_accuracy: 0.7604\n",
            "Epoch 385/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4281 - accuracy: 0.7795 - val_loss: 0.5160 - val_accuracy: 0.7604\n",
            "Epoch 386/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.7778 - val_loss: 0.5161 - val_accuracy: 0.7604\n",
            "Epoch 387/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.7812 - val_loss: 0.5161 - val_accuracy: 0.7604\n",
            "Epoch 388/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.7812 - val_loss: 0.5163 - val_accuracy: 0.7604\n",
            "Epoch 389/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.7778 - val_loss: 0.5163 - val_accuracy: 0.7604\n",
            "Epoch 390/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.7812 - val_loss: 0.5165 - val_accuracy: 0.7604\n",
            "Epoch 391/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.7795 - val_loss: 0.5167 - val_accuracy: 0.7604\n",
            "Epoch 392/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7795 - val_loss: 0.5167 - val_accuracy: 0.7604\n",
            "Epoch 393/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7760 - val_loss: 0.5168 - val_accuracy: 0.7604\n",
            "Epoch 394/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4276 - accuracy: 0.7778 - val_loss: 0.5170 - val_accuracy: 0.7604\n",
            "Epoch 395/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7760 - val_loss: 0.5169 - val_accuracy: 0.7552\n",
            "Epoch 396/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4274 - accuracy: 0.7760 - val_loss: 0.5171 - val_accuracy: 0.7604\n",
            "Epoch 397/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.7778 - val_loss: 0.5172 - val_accuracy: 0.7604\n",
            "Epoch 398/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4274 - accuracy: 0.7795 - val_loss: 0.5173 - val_accuracy: 0.7604\n",
            "Epoch 399/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4274 - accuracy: 0.7778 - val_loss: 0.5174 - val_accuracy: 0.7604\n",
            "Epoch 400/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.7760 - val_loss: 0.5176 - val_accuracy: 0.7604\n",
            "Epoch 401/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.7812 - val_loss: 0.5178 - val_accuracy: 0.7604\n",
            "Epoch 402/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.7760 - val_loss: 0.5179 - val_accuracy: 0.7604\n",
            "Epoch 403/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.7743 - val_loss: 0.5179 - val_accuracy: 0.7552\n",
            "Epoch 404/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.7795 - val_loss: 0.5183 - val_accuracy: 0.7604\n",
            "Epoch 405/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.7760 - val_loss: 0.5185 - val_accuracy: 0.7604\n",
            "Epoch 406/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.7778 - val_loss: 0.5187 - val_accuracy: 0.7604\n",
            "Epoch 407/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4267 - accuracy: 0.7778 - val_loss: 0.5187 - val_accuracy: 0.7552\n",
            "Epoch 408/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4267 - accuracy: 0.7778 - val_loss: 0.5186 - val_accuracy: 0.7552\n",
            "Epoch 409/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7795 - val_loss: 0.5187 - val_accuracy: 0.7552\n",
            "Epoch 410/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7778 - val_loss: 0.5187 - val_accuracy: 0.7552\n",
            "Epoch 411/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7812 - val_loss: 0.5187 - val_accuracy: 0.7552\n",
            "Epoch 412/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4264 - accuracy: 0.7795 - val_loss: 0.5188 - val_accuracy: 0.7552\n",
            "Epoch 413/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.7830 - val_loss: 0.5192 - val_accuracy: 0.7552\n",
            "Epoch 414/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7552\n",
            "Epoch 415/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4261 - accuracy: 0.7795 - val_loss: 0.5195 - val_accuracy: 0.7552\n",
            "Epoch 416/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4262 - accuracy: 0.7760 - val_loss: 0.5195 - val_accuracy: 0.7552\n",
            "Epoch 417/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.7812 - val_loss: 0.5196 - val_accuracy: 0.7552\n",
            "Epoch 418/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4260 - accuracy: 0.7812 - val_loss: 0.5197 - val_accuracy: 0.7552\n",
            "Epoch 419/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.7795 - val_loss: 0.5198 - val_accuracy: 0.7552\n",
            "Epoch 420/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7795 - val_loss: 0.5197 - val_accuracy: 0.7552\n",
            "Epoch 421/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7552\n",
            "Epoch 422/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7795 - val_loss: 0.5200 - val_accuracy: 0.7552\n",
            "Epoch 423/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7795 - val_loss: 0.5201 - val_accuracy: 0.7552\n",
            "Epoch 424/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7812 - val_loss: 0.5202 - val_accuracy: 0.7552\n",
            "Epoch 425/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7760 - val_loss: 0.5202 - val_accuracy: 0.7604\n",
            "Epoch 426/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.7795 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
            "Epoch 427/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4255 - accuracy: 0.7795 - val_loss: 0.5203 - val_accuracy: 0.7552\n",
            "Epoch 428/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4255 - accuracy: 0.7795 - val_loss: 0.5201 - val_accuracy: 0.7552\n",
            "Epoch 429/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4255 - accuracy: 0.7812 - val_loss: 0.5201 - val_accuracy: 0.7552\n",
            "Epoch 430/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4255 - accuracy: 0.7795 - val_loss: 0.5205 - val_accuracy: 0.7552\n",
            "Epoch 431/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.7812 - val_loss: 0.5205 - val_accuracy: 0.7552\n",
            "Epoch 432/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.7795 - val_loss: 0.5206 - val_accuracy: 0.7552\n",
            "Epoch 433/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.7778 - val_loss: 0.5207 - val_accuracy: 0.7552\n",
            "Epoch 434/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.7795 - val_loss: 0.5206 - val_accuracy: 0.7552\n",
            "Epoch 435/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.7812 - val_loss: 0.5209 - val_accuracy: 0.7552\n",
            "Epoch 436/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7795 - val_loss: 0.5207 - val_accuracy: 0.7552\n",
            "Epoch 437/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7795 - val_loss: 0.5209 - val_accuracy: 0.7604\n",
            "Epoch 438/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.7795 - val_loss: 0.5208 - val_accuracy: 0.7552\n",
            "Epoch 439/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.7795 - val_loss: 0.5207 - val_accuracy: 0.7552\n",
            "Epoch 440/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4249 - accuracy: 0.7795 - val_loss: 0.5208 - val_accuracy: 0.7552\n",
            "Epoch 441/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.7795 - val_loss: 0.5209 - val_accuracy: 0.7604\n",
            "Epoch 442/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.7795 - val_loss: 0.5209 - val_accuracy: 0.7552\n",
            "Epoch 443/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.7760 - val_loss: 0.5210 - val_accuracy: 0.7552\n",
            "Epoch 444/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.7830 - val_loss: 0.5208 - val_accuracy: 0.7552\n",
            "Epoch 445/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7795 - val_loss: 0.5207 - val_accuracy: 0.7552\n",
            "Epoch 446/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7812 - val_loss: 0.5204 - val_accuracy: 0.7552\n",
            "Epoch 447/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.7795 - val_loss: 0.5204 - val_accuracy: 0.7552\n",
            "Epoch 448/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.7743 - val_loss: 0.5203 - val_accuracy: 0.7552\n",
            "Epoch 449/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.7795 - val_loss: 0.5204 - val_accuracy: 0.7552\n",
            "Epoch 450/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4244 - accuracy: 0.7778 - val_loss: 0.5206 - val_accuracy: 0.7552\n",
            "Epoch 451/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4241 - accuracy: 0.7795 - val_loss: 0.5206 - val_accuracy: 0.7552\n",
            "Epoch 452/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.7812 - val_loss: 0.5206 - val_accuracy: 0.7552\n",
            "Epoch 453/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.7778 - val_loss: 0.5205 - val_accuracy: 0.7552\n",
            "Epoch 454/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4241 - accuracy: 0.7795 - val_loss: 0.5203 - val_accuracy: 0.7552\n",
            "Epoch 455/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4241 - accuracy: 0.7778 - val_loss: 0.5205 - val_accuracy: 0.7552\n",
            "Epoch 456/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4239 - accuracy: 0.7778 - val_loss: 0.5206 - val_accuracy: 0.7552\n",
            "Epoch 457/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4239 - accuracy: 0.7795 - val_loss: 0.5209 - val_accuracy: 0.7500\n",
            "Epoch 458/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4238 - accuracy: 0.7743 - val_loss: 0.5207 - val_accuracy: 0.7552\n",
            "Epoch 459/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4238 - accuracy: 0.7795 - val_loss: 0.5208 - val_accuracy: 0.7552\n",
            "Epoch 460/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4237 - accuracy: 0.7778 - val_loss: 0.5210 - val_accuracy: 0.7552\n",
            "Epoch 461/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4238 - accuracy: 0.7778 - val_loss: 0.5208 - val_accuracy: 0.7552\n",
            "Epoch 462/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4236 - accuracy: 0.7795 - val_loss: 0.5208 - val_accuracy: 0.7552\n",
            "Epoch 463/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4236 - accuracy: 0.7795 - val_loss: 0.5211 - val_accuracy: 0.7552\n",
            "Epoch 464/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4235 - accuracy: 0.7778 - val_loss: 0.5211 - val_accuracy: 0.7552\n",
            "Epoch 465/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.7760 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
            "Epoch 466/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4236 - accuracy: 0.7778 - val_loss: 0.5209 - val_accuracy: 0.7500\n",
            "Epoch 467/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4236 - accuracy: 0.7778 - val_loss: 0.5209 - val_accuracy: 0.7604\n",
            "Epoch 468/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4234 - accuracy: 0.7778 - val_loss: 0.5208 - val_accuracy: 0.7604\n",
            "Epoch 469/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4233 - accuracy: 0.7795 - val_loss: 0.5209 - val_accuracy: 0.7552\n",
            "Epoch 470/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4232 - accuracy: 0.7760 - val_loss: 0.5207 - val_accuracy: 0.7552\n",
            "Epoch 471/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4232 - accuracy: 0.7795 - val_loss: 0.5209 - val_accuracy: 0.7604\n",
            "Epoch 472/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4232 - accuracy: 0.7760 - val_loss: 0.5210 - val_accuracy: 0.7604\n",
            "Epoch 473/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4232 - accuracy: 0.7795 - val_loss: 0.5209 - val_accuracy: 0.7604\n",
            "Epoch 474/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4231 - accuracy: 0.7760 - val_loss: 0.5210 - val_accuracy: 0.7604\n",
            "Epoch 475/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4230 - accuracy: 0.7760 - val_loss: 0.5208 - val_accuracy: 0.7604\n",
            "Epoch 476/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4229 - accuracy: 0.7795 - val_loss: 0.5207 - val_accuracy: 0.7604\n",
            "Epoch 477/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4228 - accuracy: 0.7778 - val_loss: 0.5206 - val_accuracy: 0.7552\n",
            "Epoch 478/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4229 - accuracy: 0.7830 - val_loss: 0.5208 - val_accuracy: 0.7552\n",
            "Epoch 479/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4228 - accuracy: 0.7778 - val_loss: 0.5206 - val_accuracy: 0.7552\n",
            "Epoch 480/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.7778 - val_loss: 0.5205 - val_accuracy: 0.7552\n",
            "Epoch 481/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.7778 - val_loss: 0.5205 - val_accuracy: 0.7552\n",
            "Epoch 482/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.7778 - val_loss: 0.5204 - val_accuracy: 0.7604\n",
            "Epoch 483/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.7812 - val_loss: 0.5207 - val_accuracy: 0.7552\n",
            "Epoch 484/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4226 - accuracy: 0.7778 - val_loss: 0.5205 - val_accuracy: 0.7604\n",
            "Epoch 485/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.7778 - val_loss: 0.5206 - val_accuracy: 0.7552\n",
            "Epoch 486/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.7778 - val_loss: 0.5207 - val_accuracy: 0.7552\n",
            "Epoch 487/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.7778 - val_loss: 0.5207 - val_accuracy: 0.7552\n",
            "Epoch 488/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.7830 - val_loss: 0.5210 - val_accuracy: 0.7604\n",
            "Epoch 489/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4222 - accuracy: 0.7778 - val_loss: 0.5209 - val_accuracy: 0.7552\n",
            "Epoch 490/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.7812 - val_loss: 0.5209 - val_accuracy: 0.7552\n",
            "Epoch 491/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7812 - val_loss: 0.5210 - val_accuracy: 0.7552\n",
            "Epoch 492/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.7812 - val_loss: 0.5210 - val_accuracy: 0.7552\n",
            "Epoch 493/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.7812 - val_loss: 0.5211 - val_accuracy: 0.7552\n",
            "Epoch 494/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.7795 - val_loss: 0.5212 - val_accuracy: 0.7604\n",
            "Epoch 495/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4221 - accuracy: 0.7760 - val_loss: 0.5213 - val_accuracy: 0.7604\n",
            "Epoch 496/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.7812 - val_loss: 0.5212 - val_accuracy: 0.7552\n",
            "Epoch 497/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4222 - accuracy: 0.7795 - val_loss: 0.5212 - val_accuracy: 0.7604\n",
            "Epoch 498/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.7812 - val_loss: 0.5212 - val_accuracy: 0.7604\n",
            "Epoch 499/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.7795 - val_loss: 0.5212 - val_accuracy: 0.7604\n",
            "Epoch 500/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.7812 - val_loss: 0.5211 - val_accuracy: 0.7552\n",
            "Epoch 501/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.7795 - val_loss: 0.5211 - val_accuracy: 0.7552\n",
            "Epoch 502/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.7830 - val_loss: 0.5213 - val_accuracy: 0.7604\n",
            "Epoch 503/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.7795 - val_loss: 0.5213 - val_accuracy: 0.7552\n",
            "Epoch 504/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.7812 - val_loss: 0.5215 - val_accuracy: 0.7604\n",
            "Epoch 505/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4218 - accuracy: 0.7812 - val_loss: 0.5214 - val_accuracy: 0.7604\n",
            "Epoch 506/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.7778 - val_loss: 0.5213 - val_accuracy: 0.7552\n",
            "Epoch 507/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7795 - val_loss: 0.5213 - val_accuracy: 0.7552\n",
            "Epoch 508/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.7795 - val_loss: 0.5212 - val_accuracy: 0.7552\n",
            "Epoch 509/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.7778 - val_loss: 0.5211 - val_accuracy: 0.7552\n",
            "Epoch 510/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.7812 - val_loss: 0.5212 - val_accuracy: 0.7552\n",
            "Epoch 511/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7812 - val_loss: 0.5211 - val_accuracy: 0.7552\n",
            "Epoch 512/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.7812 - val_loss: 0.5212 - val_accuracy: 0.7552\n",
            "Epoch 513/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7812 - val_loss: 0.5211 - val_accuracy: 0.7552\n",
            "Epoch 514/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7795 - val_loss: 0.5210 - val_accuracy: 0.7552\n",
            "Epoch 515/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.7778 - val_loss: 0.5209 - val_accuracy: 0.7552\n",
            "Epoch 516/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.7795 - val_loss: 0.5208 - val_accuracy: 0.7604\n",
            "Epoch 517/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7795 - val_loss: 0.5209 - val_accuracy: 0.7552\n",
            "Epoch 518/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7795 - val_loss: 0.5209 - val_accuracy: 0.7552\n",
            "Epoch 519/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.7812 - val_loss: 0.5211 - val_accuracy: 0.7552\n",
            "Epoch 520/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.7795 - val_loss: 0.5209 - val_accuracy: 0.7604\n",
            "Epoch 521/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.7795 - val_loss: 0.5212 - val_accuracy: 0.7604\n",
            "Epoch 522/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.7778 - val_loss: 0.5211 - val_accuracy: 0.7604\n",
            "Epoch 523/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.7812 - val_loss: 0.5210 - val_accuracy: 0.7552\n",
            "Epoch 524/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.7795 - val_loss: 0.5208 - val_accuracy: 0.7656\n",
            "Epoch 525/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.7812 - val_loss: 0.5207 - val_accuracy: 0.7604\n",
            "Epoch 526/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7830 - val_loss: 0.5209 - val_accuracy: 0.7604\n",
            "Epoch 527/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.7812 - val_loss: 0.5210 - val_accuracy: 0.7656\n",
            "Epoch 528/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7830 - val_loss: 0.5210 - val_accuracy: 0.7656\n",
            "Epoch 529/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.7812 - val_loss: 0.5210 - val_accuracy: 0.7656\n",
            "Epoch 530/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7778 - val_loss: 0.5207 - val_accuracy: 0.7708\n",
            "Epoch 531/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.7812 - val_loss: 0.5204 - val_accuracy: 0.7656\n",
            "Epoch 532/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4209 - accuracy: 0.7812 - val_loss: 0.5207 - val_accuracy: 0.7708\n",
            "Epoch 533/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.7795 - val_loss: 0.5207 - val_accuracy: 0.7708\n",
            "Epoch 534/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4208 - accuracy: 0.7830 - val_loss: 0.5205 - val_accuracy: 0.7708\n",
            "Epoch 535/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.7778 - val_loss: 0.5207 - val_accuracy: 0.7760\n",
            "Epoch 536/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.7830 - val_loss: 0.5206 - val_accuracy: 0.7708\n",
            "Epoch 537/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4208 - accuracy: 0.7812 - val_loss: 0.5207 - val_accuracy: 0.7760\n",
            "Epoch 538/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4207 - accuracy: 0.7830 - val_loss: 0.5206 - val_accuracy: 0.7760\n",
            "Epoch 539/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.7812 - val_loss: 0.5203 - val_accuracy: 0.7708\n",
            "Epoch 540/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.7847 - val_loss: 0.5206 - val_accuracy: 0.7760\n",
            "Epoch 541/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4206 - accuracy: 0.7847 - val_loss: 0.5205 - val_accuracy: 0.7760\n",
            "Epoch 542/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.7830 - val_loss: 0.5205 - val_accuracy: 0.7760\n",
            "Epoch 543/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.7812 - val_loss: 0.5202 - val_accuracy: 0.7708\n",
            "Epoch 544/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.7812 - val_loss: 0.5207 - val_accuracy: 0.7760\n",
            "Epoch 545/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7830 - val_loss: 0.5205 - val_accuracy: 0.7708\n",
            "Epoch 546/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.7830 - val_loss: 0.5203 - val_accuracy: 0.7708\n",
            "Epoch 547/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4204 - accuracy: 0.7830 - val_loss: 0.5204 - val_accuracy: 0.7708\n",
            "Epoch 548/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4203 - accuracy: 0.7847 - val_loss: 0.5205 - val_accuracy: 0.7708\n",
            "Epoch 549/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.7812 - val_loss: 0.5209 - val_accuracy: 0.7760\n",
            "Epoch 550/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.7847 - val_loss: 0.5210 - val_accuracy: 0.7708\n",
            "Epoch 551/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4203 - accuracy: 0.7812 - val_loss: 0.5209 - val_accuracy: 0.7760\n",
            "Epoch 552/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4204 - accuracy: 0.7812 - val_loss: 0.5209 - val_accuracy: 0.7760\n",
            "Epoch 553/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4203 - accuracy: 0.7847 - val_loss: 0.5207 - val_accuracy: 0.7760\n",
            "Epoch 554/1500\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.4202 - accuracy: 0.7830 - val_loss: 0.5206 - val_accuracy: 0.7708\n",
            "Epoch 555/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4201 - accuracy: 0.7847 - val_loss: 0.5206 - val_accuracy: 0.7708\n",
            "Epoch 556/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4201 - accuracy: 0.7847 - val_loss: 0.5204 - val_accuracy: 0.7708\n",
            "Epoch 557/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.7812 - val_loss: 0.5202 - val_accuracy: 0.7708\n",
            "Epoch 558/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.7847 - val_loss: 0.5204 - val_accuracy: 0.7708\n",
            "Epoch 559/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4202 - accuracy: 0.7847 - val_loss: 0.5207 - val_accuracy: 0.7708\n",
            "Epoch 560/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4199 - accuracy: 0.7847 - val_loss: 0.5209 - val_accuracy: 0.7760\n",
            "Epoch 561/1500\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.4198 - accuracy: 0.7847 - val_loss: 0.5210 - val_accuracy: 0.7760\n",
            "Epoch 562/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4200 - accuracy: 0.7830 - val_loss: 0.5211 - val_accuracy: 0.7760\n",
            "Epoch 563/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.7830 - val_loss: 0.5210 - val_accuracy: 0.7708\n",
            "Epoch 564/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4198 - accuracy: 0.7812 - val_loss: 0.5207 - val_accuracy: 0.7708\n",
            "Epoch 565/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4200 - accuracy: 0.7795 - val_loss: 0.5206 - val_accuracy: 0.7708\n",
            "Epoch 566/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4199 - accuracy: 0.7830 - val_loss: 0.5208 - val_accuracy: 0.7708\n",
            "Epoch 567/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4199 - accuracy: 0.7812 - val_loss: 0.5208 - val_accuracy: 0.7708\n",
            "Epoch 568/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4198 - accuracy: 0.7830 - val_loss: 0.5210 - val_accuracy: 0.7708\n",
            "Epoch 569/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4196 - accuracy: 0.7830 - val_loss: 0.5209 - val_accuracy: 0.7708\n",
            "Epoch 570/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4196 - accuracy: 0.7830 - val_loss: 0.5209 - val_accuracy: 0.7708\n",
            "Epoch 571/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4197 - accuracy: 0.7812 - val_loss: 0.5209 - val_accuracy: 0.7708\n",
            "Epoch 572/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4197 - accuracy: 0.7812 - val_loss: 0.5208 - val_accuracy: 0.7708\n",
            "Epoch 573/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4196 - accuracy: 0.7830 - val_loss: 0.5212 - val_accuracy: 0.7708\n",
            "Epoch 574/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4197 - accuracy: 0.7830 - val_loss: 0.5212 - val_accuracy: 0.7708\n",
            "Epoch 575/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4197 - accuracy: 0.7847 - val_loss: 0.5212 - val_accuracy: 0.7656\n",
            "Epoch 576/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4195 - accuracy: 0.7830 - val_loss: 0.5211 - val_accuracy: 0.7708\n",
            "Epoch 577/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4196 - accuracy: 0.7847 - val_loss: 0.5210 - val_accuracy: 0.7708\n",
            "Epoch 578/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4195 - accuracy: 0.7830 - val_loss: 0.5210 - val_accuracy: 0.7708\n",
            "Epoch 579/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4194 - accuracy: 0.7847 - val_loss: 0.5209 - val_accuracy: 0.7708\n",
            "Epoch 580/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4193 - accuracy: 0.7847 - val_loss: 0.5208 - val_accuracy: 0.7708\n",
            "Epoch 581/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4195 - accuracy: 0.7847 - val_loss: 0.5208 - val_accuracy: 0.7708\n",
            "Epoch 582/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4194 - accuracy: 0.7830 - val_loss: 0.5206 - val_accuracy: 0.7656\n",
            "Epoch 583/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4194 - accuracy: 0.7830 - val_loss: 0.5211 - val_accuracy: 0.7656\n",
            "Epoch 584/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4194 - accuracy: 0.7830 - val_loss: 0.5211 - val_accuracy: 0.7656\n",
            "Epoch 585/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4193 - accuracy: 0.7830 - val_loss: 0.5213 - val_accuracy: 0.7604\n",
            "Epoch 586/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4191 - accuracy: 0.7847 - val_loss: 0.5213 - val_accuracy: 0.7604\n",
            "Epoch 587/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4192 - accuracy: 0.7847 - val_loss: 0.5216 - val_accuracy: 0.7552\n",
            "Epoch 588/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4191 - accuracy: 0.7847 - val_loss: 0.5217 - val_accuracy: 0.7552\n",
            "Epoch 589/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4190 - accuracy: 0.7812 - val_loss: 0.5220 - val_accuracy: 0.7656\n",
            "Epoch 590/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4190 - accuracy: 0.7830 - val_loss: 0.5221 - val_accuracy: 0.7656\n",
            "Epoch 591/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4189 - accuracy: 0.7830 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
            "Epoch 592/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4188 - accuracy: 0.7830 - val_loss: 0.5223 - val_accuracy: 0.7604\n",
            "Epoch 593/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4190 - accuracy: 0.7847 - val_loss: 0.5223 - val_accuracy: 0.7604\n",
            "Epoch 594/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4189 - accuracy: 0.7812 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
            "Epoch 595/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.7830 - val_loss: 0.5222 - val_accuracy: 0.7604\n",
            "Epoch 596/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.7812 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
            "Epoch 597/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.7812 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
            "Epoch 598/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.7830 - val_loss: 0.5224 - val_accuracy: 0.7656\n",
            "Epoch 599/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.7795 - val_loss: 0.5224 - val_accuracy: 0.7604\n",
            "Epoch 600/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4186 - accuracy: 0.7812 - val_loss: 0.5227 - val_accuracy: 0.7656\n",
            "Epoch 601/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4185 - accuracy: 0.7795 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 602/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.7795 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 603/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4184 - accuracy: 0.7795 - val_loss: 0.5225 - val_accuracy: 0.7604\n",
            "Epoch 604/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4183 - accuracy: 0.7795 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 605/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4182 - accuracy: 0.7812 - val_loss: 0.5230 - val_accuracy: 0.7656\n",
            "Epoch 606/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.7812 - val_loss: 0.5230 - val_accuracy: 0.7656\n",
            "Epoch 607/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4182 - accuracy: 0.7830 - val_loss: 0.5231 - val_accuracy: 0.7656\n",
            "Epoch 608/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4183 - accuracy: 0.7812 - val_loss: 0.5230 - val_accuracy: 0.7656\n",
            "Epoch 609/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4181 - accuracy: 0.7812 - val_loss: 0.5230 - val_accuracy: 0.7656\n",
            "Epoch 610/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.7830 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 611/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4179 - accuracy: 0.7830 - val_loss: 0.5230 - val_accuracy: 0.7656\n",
            "Epoch 612/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.7847 - val_loss: 0.5231 - val_accuracy: 0.7656\n",
            "Epoch 613/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.7847 - val_loss: 0.5229 - val_accuracy: 0.7656\n",
            "Epoch 614/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.7865 - val_loss: 0.5231 - val_accuracy: 0.7656\n",
            "Epoch 615/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.7847 - val_loss: 0.5230 - val_accuracy: 0.7656\n",
            "Epoch 616/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.7830 - val_loss: 0.5232 - val_accuracy: 0.7656\n",
            "Epoch 617/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.7847 - val_loss: 0.5233 - val_accuracy: 0.7656\n",
            "Epoch 618/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.7865 - val_loss: 0.5233 - val_accuracy: 0.7656\n",
            "Epoch 619/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.7865 - val_loss: 0.5237 - val_accuracy: 0.7656\n",
            "Epoch 620/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.7917 - val_loss: 0.5237 - val_accuracy: 0.7656\n",
            "Epoch 621/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.7847 - val_loss: 0.5234 - val_accuracy: 0.7656\n",
            "Epoch 622/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4174 - accuracy: 0.7882 - val_loss: 0.5234 - val_accuracy: 0.7656\n",
            "Epoch 623/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.7865 - val_loss: 0.5235 - val_accuracy: 0.7656\n",
            "Epoch 624/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.7830 - val_loss: 0.5235 - val_accuracy: 0.7656\n",
            "Epoch 625/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4173 - accuracy: 0.7847 - val_loss: 0.5232 - val_accuracy: 0.7656\n",
            "Epoch 626/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.7865 - val_loss: 0.5230 - val_accuracy: 0.7656\n",
            "Epoch 627/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4171 - accuracy: 0.7830 - val_loss: 0.5229 - val_accuracy: 0.7604\n",
            "Epoch 628/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4170 - accuracy: 0.7830 - val_loss: 0.5231 - val_accuracy: 0.7604\n",
            "Epoch 629/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4171 - accuracy: 0.7882 - val_loss: 0.5236 - val_accuracy: 0.7656\n",
            "Epoch 630/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4170 - accuracy: 0.7830 - val_loss: 0.5233 - val_accuracy: 0.7604\n",
            "Epoch 631/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.7882 - val_loss: 0.5234 - val_accuracy: 0.7656\n",
            "Epoch 632/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.7899 - val_loss: 0.5240 - val_accuracy: 0.7656\n",
            "Epoch 633/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.7882 - val_loss: 0.5242 - val_accuracy: 0.7656\n",
            "Epoch 634/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4170 - accuracy: 0.7830 - val_loss: 0.5238 - val_accuracy: 0.7656\n",
            "Epoch 635/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.7899 - val_loss: 0.5240 - val_accuracy: 0.7656\n",
            "Epoch 636/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4168 - accuracy: 0.7865 - val_loss: 0.5238 - val_accuracy: 0.7604\n",
            "Epoch 637/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4166 - accuracy: 0.7917 - val_loss: 0.5237 - val_accuracy: 0.7604\n",
            "Epoch 638/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.7865 - val_loss: 0.5236 - val_accuracy: 0.7604\n",
            "Epoch 639/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4166 - accuracy: 0.7917 - val_loss: 0.5238 - val_accuracy: 0.7604\n",
            "Epoch 640/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4165 - accuracy: 0.7899 - val_loss: 0.5235 - val_accuracy: 0.7604\n",
            "Epoch 641/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4164 - accuracy: 0.7865 - val_loss: 0.5235 - val_accuracy: 0.7604\n",
            "Epoch 642/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4166 - accuracy: 0.7899 - val_loss: 0.5234 - val_accuracy: 0.7604\n",
            "Epoch 643/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4166 - accuracy: 0.7951 - val_loss: 0.5238 - val_accuracy: 0.7604\n",
            "Epoch 644/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.7865 - val_loss: 0.5235 - val_accuracy: 0.7604\n",
            "Epoch 645/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4166 - accuracy: 0.7882 - val_loss: 0.5237 - val_accuracy: 0.7604\n",
            "Epoch 646/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4164 - accuracy: 0.7899 - val_loss: 0.5238 - val_accuracy: 0.7604\n",
            "Epoch 647/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.7917 - val_loss: 0.5238 - val_accuracy: 0.7604\n",
            "Epoch 648/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4164 - accuracy: 0.7899 - val_loss: 0.5237 - val_accuracy: 0.7604\n",
            "Epoch 649/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4161 - accuracy: 0.7899 - val_loss: 0.5239 - val_accuracy: 0.7604\n",
            "Epoch 650/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4162 - accuracy: 0.7882 - val_loss: 0.5243 - val_accuracy: 0.7604\n",
            "Epoch 651/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4161 - accuracy: 0.7882 - val_loss: 0.5243 - val_accuracy: 0.7604\n",
            "Epoch 652/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4162 - accuracy: 0.7865 - val_loss: 0.5239 - val_accuracy: 0.7604\n",
            "Epoch 653/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4161 - accuracy: 0.7899 - val_loss: 0.5235 - val_accuracy: 0.7604\n",
            "Epoch 654/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4161 - accuracy: 0.7899 - val_loss: 0.5237 - val_accuracy: 0.7604\n",
            "Epoch 655/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4161 - accuracy: 0.7882 - val_loss: 0.5238 - val_accuracy: 0.7604\n",
            "Epoch 656/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4159 - accuracy: 0.7917 - val_loss: 0.5241 - val_accuracy: 0.7604\n",
            "Epoch 657/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4162 - accuracy: 0.7899 - val_loss: 0.5243 - val_accuracy: 0.7604\n",
            "Epoch 658/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4160 - accuracy: 0.7917 - val_loss: 0.5245 - val_accuracy: 0.7604\n",
            "Epoch 659/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4161 - accuracy: 0.7899 - val_loss: 0.5243 - val_accuracy: 0.7604\n",
            "Epoch 660/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.4159 - accuracy: 0.7899 - val_loss: 0.5244 - val_accuracy: 0.7604\n",
            "Epoch 661/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4158 - accuracy: 0.7899 - val_loss: 0.5243 - val_accuracy: 0.7604\n",
            "Epoch 662/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4158 - accuracy: 0.7899 - val_loss: 0.5245 - val_accuracy: 0.7604\n",
            "Epoch 663/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.4159 - accuracy: 0.7882 - val_loss: 0.5247 - val_accuracy: 0.7604\n",
            "Epoch 664/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4158 - accuracy: 0.7917 - val_loss: 0.5247 - val_accuracy: 0.7604\n",
            "Epoch 665/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4156 - accuracy: 0.7917 - val_loss: 0.5254 - val_accuracy: 0.7604\n",
            "Epoch 666/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.4157 - accuracy: 0.7865 - val_loss: 0.5252 - val_accuracy: 0.7604\n",
            "Epoch 667/1500\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.4154 - accuracy: 0.7899 - val_loss: 0.5254 - val_accuracy: 0.7604\n",
            "Epoch 668/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4154 - accuracy: 0.7917 - val_loss: 0.5255 - val_accuracy: 0.7604\n",
            "Epoch 669/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4154 - accuracy: 0.7899 - val_loss: 0.5259 - val_accuracy: 0.7604\n",
            "Epoch 670/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4154 - accuracy: 0.7899 - val_loss: 0.5261 - val_accuracy: 0.7604\n",
            "Epoch 671/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4152 - accuracy: 0.7882 - val_loss: 0.5262 - val_accuracy: 0.7604\n",
            "Epoch 672/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.4153 - accuracy: 0.7899 - val_loss: 0.5260 - val_accuracy: 0.7604\n",
            "Epoch 673/1500\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.4152 - accuracy: 0.7917 - val_loss: 0.5260 - val_accuracy: 0.7604\n",
            "Epoch 674/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.4153 - accuracy: 0.7882 - val_loss: 0.5258 - val_accuracy: 0.7604\n",
            "Epoch 675/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.4151 - accuracy: 0.7917 - val_loss: 0.5260 - val_accuracy: 0.7604\n",
            "Epoch 676/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4152 - accuracy: 0.7882 - val_loss: 0.5261 - val_accuracy: 0.7604\n",
            "Epoch 677/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.4151 - accuracy: 0.7899 - val_loss: 0.5262 - val_accuracy: 0.7604\n",
            "Epoch 678/1500\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.4152 - accuracy: 0.7917 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
            "Epoch 679/1500\n",
            "18/18 [==============================] - 1s 39ms/step - loss: 0.4150 - accuracy: 0.7934 - val_loss: 0.5267 - val_accuracy: 0.7604\n",
            "Epoch 680/1500\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.4149 - accuracy: 0.7899 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
            "Epoch 681/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4149 - accuracy: 0.7899 - val_loss: 0.5267 - val_accuracy: 0.7604\n",
            "Epoch 682/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4149 - accuracy: 0.7882 - val_loss: 0.5268 - val_accuracy: 0.7604\n",
            "Epoch 683/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4147 - accuracy: 0.7899 - val_loss: 0.5267 - val_accuracy: 0.7604\n",
            "Epoch 684/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4146 - accuracy: 0.7917 - val_loss: 0.5267 - val_accuracy: 0.7604\n",
            "Epoch 685/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4146 - accuracy: 0.7917 - val_loss: 0.5272 - val_accuracy: 0.7656\n",
            "Epoch 686/1500\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.4146 - accuracy: 0.7934 - val_loss: 0.5272 - val_accuracy: 0.7656\n",
            "Epoch 687/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4146 - accuracy: 0.7882 - val_loss: 0.5272 - val_accuracy: 0.7656\n",
            "Epoch 688/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4144 - accuracy: 0.7882 - val_loss: 0.5272 - val_accuracy: 0.7656\n",
            "Epoch 689/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4144 - accuracy: 0.7899 - val_loss: 0.5271 - val_accuracy: 0.7656\n",
            "Epoch 690/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4142 - accuracy: 0.7899 - val_loss: 0.5269 - val_accuracy: 0.7656\n",
            "Epoch 691/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4141 - accuracy: 0.7899 - val_loss: 0.5266 - val_accuracy: 0.7656\n",
            "Epoch 692/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.4140 - accuracy: 0.7899 - val_loss: 0.5269 - val_accuracy: 0.7656\n",
            "Epoch 693/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4140 - accuracy: 0.7899 - val_loss: 0.5273 - val_accuracy: 0.7656\n",
            "Epoch 694/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4140 - accuracy: 0.7899 - val_loss: 0.5272 - val_accuracy: 0.7656\n",
            "Epoch 695/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4140 - accuracy: 0.7917 - val_loss: 0.5275 - val_accuracy: 0.7656\n",
            "Epoch 696/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4139 - accuracy: 0.7934 - val_loss: 0.5279 - val_accuracy: 0.7656\n",
            "Epoch 697/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4139 - accuracy: 0.7899 - val_loss: 0.5280 - val_accuracy: 0.7656\n",
            "Epoch 698/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.4136 - accuracy: 0.7917 - val_loss: 0.5277 - val_accuracy: 0.7656\n",
            "Epoch 699/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4136 - accuracy: 0.7917 - val_loss: 0.5279 - val_accuracy: 0.7604\n",
            "Epoch 700/1500\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.4135 - accuracy: 0.7917 - val_loss: 0.5278 - val_accuracy: 0.7604\n",
            "Epoch 701/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.4134 - accuracy: 0.7899 - val_loss: 0.5278 - val_accuracy: 0.7604\n",
            "Epoch 702/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4134 - accuracy: 0.7899 - val_loss: 0.5279 - val_accuracy: 0.7604\n",
            "Epoch 703/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.4134 - accuracy: 0.7882 - val_loss: 0.5284 - val_accuracy: 0.7604\n",
            "Epoch 704/1500\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.4133 - accuracy: 0.7934 - val_loss: 0.5283 - val_accuracy: 0.7604\n",
            "Epoch 705/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4132 - accuracy: 0.7917 - val_loss: 0.5290 - val_accuracy: 0.7604\n",
            "Epoch 706/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4132 - accuracy: 0.7899 - val_loss: 0.5287 - val_accuracy: 0.7604\n",
            "Epoch 707/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4130 - accuracy: 0.7899 - val_loss: 0.5288 - val_accuracy: 0.7604\n",
            "Epoch 708/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4131 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7604\n",
            "Epoch 709/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4129 - accuracy: 0.7899 - val_loss: 0.5291 - val_accuracy: 0.7604\n",
            "Epoch 710/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.7917 - val_loss: 0.5289 - val_accuracy: 0.7604\n",
            "Epoch 711/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7604\n",
            "Epoch 712/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.7899 - val_loss: 0.5290 - val_accuracy: 0.7604\n",
            "Epoch 713/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.7899 - val_loss: 0.5292 - val_accuracy: 0.7604\n",
            "Epoch 714/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.7899 - val_loss: 0.5293 - val_accuracy: 0.7604\n",
            "Epoch 715/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.7882 - val_loss: 0.5291 - val_accuracy: 0.7604\n",
            "Epoch 716/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.7934 - val_loss: 0.5292 - val_accuracy: 0.7604\n",
            "Epoch 717/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.7899 - val_loss: 0.5294 - val_accuracy: 0.7604\n",
            "Epoch 718/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.7917 - val_loss: 0.5302 - val_accuracy: 0.7604\n",
            "Epoch 719/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.7917 - val_loss: 0.5300 - val_accuracy: 0.7604\n",
            "Epoch 720/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.7951 - val_loss: 0.5304 - val_accuracy: 0.7604\n",
            "Epoch 721/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.7917 - val_loss: 0.5302 - val_accuracy: 0.7604\n",
            "Epoch 722/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.7934 - val_loss: 0.5301 - val_accuracy: 0.7604\n",
            "Epoch 723/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.7917 - val_loss: 0.5303 - val_accuracy: 0.7604\n",
            "Epoch 724/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.7917 - val_loss: 0.5303 - val_accuracy: 0.7604\n",
            "Epoch 725/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.7934 - val_loss: 0.5305 - val_accuracy: 0.7604\n",
            "Epoch 726/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4120 - accuracy: 0.7917 - val_loss: 0.5304 - val_accuracy: 0.7604\n",
            "Epoch 727/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4120 - accuracy: 0.7934 - val_loss: 0.5305 - val_accuracy: 0.7604\n",
            "Epoch 728/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.7917 - val_loss: 0.5304 - val_accuracy: 0.7604\n",
            "Epoch 729/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.7917 - val_loss: 0.5303 - val_accuracy: 0.7604\n",
            "Epoch 730/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.7951 - val_loss: 0.5305 - val_accuracy: 0.7604\n",
            "Epoch 731/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.7934 - val_loss: 0.5308 - val_accuracy: 0.7604\n",
            "Epoch 732/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.7934 - val_loss: 0.5310 - val_accuracy: 0.7604\n",
            "Epoch 733/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4117 - accuracy: 0.7917 - val_loss: 0.5314 - val_accuracy: 0.7604\n",
            "Epoch 734/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4118 - accuracy: 0.7917 - val_loss: 0.5310 - val_accuracy: 0.7604\n",
            "Epoch 735/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4117 - accuracy: 0.7951 - val_loss: 0.5312 - val_accuracy: 0.7604\n",
            "Epoch 736/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.7934 - val_loss: 0.5310 - val_accuracy: 0.7604\n",
            "Epoch 737/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.7934 - val_loss: 0.5310 - val_accuracy: 0.7604\n",
            "Epoch 738/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4115 - accuracy: 0.7934 - val_loss: 0.5310 - val_accuracy: 0.7604\n",
            "Epoch 739/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4115 - accuracy: 0.7899 - val_loss: 0.5308 - val_accuracy: 0.7604\n",
            "Epoch 740/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4114 - accuracy: 0.7934 - val_loss: 0.5311 - val_accuracy: 0.7604\n",
            "Epoch 741/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4113 - accuracy: 0.7934 - val_loss: 0.5309 - val_accuracy: 0.7604\n",
            "Epoch 742/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4114 - accuracy: 0.7934 - val_loss: 0.5309 - val_accuracy: 0.7604\n",
            "Epoch 743/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4113 - accuracy: 0.7934 - val_loss: 0.5312 - val_accuracy: 0.7604\n",
            "Epoch 744/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4112 - accuracy: 0.7934 - val_loss: 0.5313 - val_accuracy: 0.7604\n",
            "Epoch 745/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4112 - accuracy: 0.7917 - val_loss: 0.5312 - val_accuracy: 0.7552\n",
            "Epoch 746/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4114 - accuracy: 0.7917 - val_loss: 0.5311 - val_accuracy: 0.7552\n",
            "Epoch 747/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4114 - accuracy: 0.7934 - val_loss: 0.5313 - val_accuracy: 0.7604\n",
            "Epoch 748/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4112 - accuracy: 0.7899 - val_loss: 0.5309 - val_accuracy: 0.7604\n",
            "Epoch 749/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4112 - accuracy: 0.7917 - val_loss: 0.5311 - val_accuracy: 0.7604\n",
            "Epoch 750/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4112 - accuracy: 0.7934 - val_loss: 0.5316 - val_accuracy: 0.7604\n",
            "Epoch 751/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4111 - accuracy: 0.7882 - val_loss: 0.5314 - val_accuracy: 0.7604\n",
            "Epoch 752/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4110 - accuracy: 0.7934 - val_loss: 0.5310 - val_accuracy: 0.7656\n",
            "Epoch 753/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4109 - accuracy: 0.7951 - val_loss: 0.5320 - val_accuracy: 0.7604\n",
            "Epoch 754/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.7934 - val_loss: 0.5319 - val_accuracy: 0.7604\n",
            "Epoch 755/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.7917 - val_loss: 0.5317 - val_accuracy: 0.7604\n",
            "Epoch 756/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.7934 - val_loss: 0.5320 - val_accuracy: 0.7604\n",
            "Epoch 757/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.7951 - val_loss: 0.5321 - val_accuracy: 0.7604\n",
            "Epoch 758/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.7917 - val_loss: 0.5320 - val_accuracy: 0.7604\n",
            "Epoch 759/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.7934 - val_loss: 0.5324 - val_accuracy: 0.7604\n",
            "Epoch 760/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.7917 - val_loss: 0.5324 - val_accuracy: 0.7604\n",
            "Epoch 761/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.7934 - val_loss: 0.5322 - val_accuracy: 0.7604\n",
            "Epoch 762/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.7917 - val_loss: 0.5320 - val_accuracy: 0.7604\n",
            "Epoch 763/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.7899 - val_loss: 0.5320 - val_accuracy: 0.7604\n",
            "Epoch 764/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.7917 - val_loss: 0.5322 - val_accuracy: 0.7604\n",
            "Epoch 765/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.7917 - val_loss: 0.5322 - val_accuracy: 0.7604\n",
            "Epoch 766/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.7934 - val_loss: 0.5324 - val_accuracy: 0.7604\n",
            "Epoch 767/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.7934 - val_loss: 0.5325 - val_accuracy: 0.7604\n",
            "Epoch 768/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.7934 - val_loss: 0.5326 - val_accuracy: 0.7604\n",
            "Epoch 769/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.7934 - val_loss: 0.5326 - val_accuracy: 0.7604\n",
            "Epoch 770/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.7951 - val_loss: 0.5326 - val_accuracy: 0.7604\n",
            "Epoch 771/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.7899 - val_loss: 0.5328 - val_accuracy: 0.7604\n",
            "Epoch 772/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.7917 - val_loss: 0.5325 - val_accuracy: 0.7604\n",
            "Epoch 773/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4102 - accuracy: 0.7917 - val_loss: 0.5326 - val_accuracy: 0.7604\n",
            "Epoch 774/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.7917 - val_loss: 0.5329 - val_accuracy: 0.7604\n",
            "Epoch 775/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.7917 - val_loss: 0.5326 - val_accuracy: 0.7604\n",
            "Epoch 776/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.7917 - val_loss: 0.5326 - val_accuracy: 0.7604\n",
            "Epoch 777/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.7917 - val_loss: 0.5326 - val_accuracy: 0.7604\n",
            "Epoch 778/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.7882 - val_loss: 0.5324 - val_accuracy: 0.7656\n",
            "Epoch 779/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.7899 - val_loss: 0.5325 - val_accuracy: 0.7656\n",
            "Epoch 780/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.7934 - val_loss: 0.5326 - val_accuracy: 0.7656\n",
            "Epoch 781/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.7917 - val_loss: 0.5323 - val_accuracy: 0.7656\n",
            "Epoch 782/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.7934 - val_loss: 0.5324 - val_accuracy: 0.7656\n",
            "Epoch 783/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4102 - accuracy: 0.7917 - val_loss: 0.5325 - val_accuracy: 0.7656\n",
            "Epoch 784/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.7917 - val_loss: 0.5327 - val_accuracy: 0.7656\n",
            "Epoch 785/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.7899 - val_loss: 0.5327 - val_accuracy: 0.7656\n",
            "Epoch 786/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.7969 - val_loss: 0.5329 - val_accuracy: 0.7656\n",
            "Epoch 787/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4102 - accuracy: 0.7934 - val_loss: 0.5328 - val_accuracy: 0.7656\n",
            "Epoch 788/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.7917 - val_loss: 0.5328 - val_accuracy: 0.7656\n",
            "Epoch 789/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.7934 - val_loss: 0.5328 - val_accuracy: 0.7656\n",
            "Epoch 790/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4102 - accuracy: 0.7917 - val_loss: 0.5328 - val_accuracy: 0.7656\n",
            "Epoch 791/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4101 - accuracy: 0.7917 - val_loss: 0.5329 - val_accuracy: 0.7656\n",
            "Epoch 792/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4099 - accuracy: 0.7934 - val_loss: 0.5329 - val_accuracy: 0.7656\n",
            "Epoch 793/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.7934 - val_loss: 0.5327 - val_accuracy: 0.7656\n",
            "Epoch 794/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.7951 - val_loss: 0.5330 - val_accuracy: 0.7656\n",
            "Epoch 795/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.7934 - val_loss: 0.5330 - val_accuracy: 0.7656\n",
            "Epoch 796/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4098 - accuracy: 0.7951 - val_loss: 0.5334 - val_accuracy: 0.7656\n",
            "Epoch 797/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4099 - accuracy: 0.7951 - val_loss: 0.5336 - val_accuracy: 0.7656\n",
            "Epoch 798/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.7917 - val_loss: 0.5337 - val_accuracy: 0.7604\n",
            "Epoch 799/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4099 - accuracy: 0.7951 - val_loss: 0.5337 - val_accuracy: 0.7656\n",
            "Epoch 800/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.7934 - val_loss: 0.5335 - val_accuracy: 0.7656\n",
            "Epoch 801/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.7934 - val_loss: 0.5335 - val_accuracy: 0.7708\n",
            "Epoch 802/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4098 - accuracy: 0.7882 - val_loss: 0.5333 - val_accuracy: 0.7708\n",
            "Epoch 803/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.7951 - val_loss: 0.5335 - val_accuracy: 0.7708\n",
            "Epoch 804/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.7917 - val_loss: 0.5333 - val_accuracy: 0.7656\n",
            "Epoch 805/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.7934 - val_loss: 0.5329 - val_accuracy: 0.7656\n",
            "Epoch 806/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4095 - accuracy: 0.7917 - val_loss: 0.5331 - val_accuracy: 0.7656\n",
            "Epoch 807/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4096 - accuracy: 0.7934 - val_loss: 0.5333 - val_accuracy: 0.7708\n",
            "Epoch 808/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.7934 - val_loss: 0.5333 - val_accuracy: 0.7708\n",
            "Epoch 809/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4095 - accuracy: 0.7951 - val_loss: 0.5336 - val_accuracy: 0.7708\n",
            "Epoch 810/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.7969 - val_loss: 0.5339 - val_accuracy: 0.7708\n",
            "Epoch 811/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.7934 - val_loss: 0.5338 - val_accuracy: 0.7708\n",
            "Epoch 812/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.7934 - val_loss: 0.5334 - val_accuracy: 0.7708\n",
            "Epoch 813/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.7951 - val_loss: 0.5333 - val_accuracy: 0.7708\n",
            "Epoch 814/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.7951 - val_loss: 0.5334 - val_accuracy: 0.7708\n",
            "Epoch 815/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.7951 - val_loss: 0.5333 - val_accuracy: 0.7708\n",
            "Epoch 816/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4093 - accuracy: 0.7934 - val_loss: 0.5336 - val_accuracy: 0.7708\n",
            "Epoch 817/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4094 - accuracy: 0.7951 - val_loss: 0.5335 - val_accuracy: 0.7708\n",
            "Epoch 818/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4096 - accuracy: 0.7969 - val_loss: 0.5338 - val_accuracy: 0.7708\n",
            "Epoch 819/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4093 - accuracy: 0.7934 - val_loss: 0.5335 - val_accuracy: 0.7708\n",
            "Epoch 820/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.7951 - val_loss: 0.5335 - val_accuracy: 0.7708\n",
            "Epoch 821/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4093 - accuracy: 0.7951 - val_loss: 0.5338 - val_accuracy: 0.7708\n",
            "Epoch 822/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4093 - accuracy: 0.7934 - val_loss: 0.5342 - val_accuracy: 0.7708\n",
            "Epoch 823/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.7934 - val_loss: 0.5338 - val_accuracy: 0.7708\n",
            "Epoch 824/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.7951 - val_loss: 0.5335 - val_accuracy: 0.7708\n",
            "Epoch 825/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4093 - accuracy: 0.7951 - val_loss: 0.5337 - val_accuracy: 0.7708\n",
            "Epoch 826/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4092 - accuracy: 0.7951 - val_loss: 0.5337 - val_accuracy: 0.7708\n",
            "Epoch 827/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.7917 - val_loss: 0.5334 - val_accuracy: 0.7708\n",
            "Epoch 828/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4090 - accuracy: 0.7951 - val_loss: 0.5334 - val_accuracy: 0.7708\n",
            "Epoch 829/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4091 - accuracy: 0.7934 - val_loss: 0.5335 - val_accuracy: 0.7656\n",
            "Epoch 830/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4093 - accuracy: 0.7934 - val_loss: 0.5338 - val_accuracy: 0.7708\n",
            "Epoch 831/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4090 - accuracy: 0.7951 - val_loss: 0.5338 - val_accuracy: 0.7708\n",
            "Epoch 832/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4090 - accuracy: 0.7969 - val_loss: 0.5340 - val_accuracy: 0.7708\n",
            "Epoch 833/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.7951 - val_loss: 0.5340 - val_accuracy: 0.7708\n",
            "Epoch 834/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.7951 - val_loss: 0.5339 - val_accuracy: 0.7656\n",
            "Epoch 835/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4091 - accuracy: 0.7969 - val_loss: 0.5336 - val_accuracy: 0.7708\n",
            "Epoch 836/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4091 - accuracy: 0.7951 - val_loss: 0.5339 - val_accuracy: 0.7656\n",
            "Epoch 837/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4089 - accuracy: 0.7969 - val_loss: 0.5339 - val_accuracy: 0.7708\n",
            "Epoch 838/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4090 - accuracy: 0.7951 - val_loss: 0.5337 - val_accuracy: 0.7656\n",
            "Epoch 839/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4090 - accuracy: 0.7917 - val_loss: 0.5343 - val_accuracy: 0.7708\n",
            "Epoch 840/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4090 - accuracy: 0.7951 - val_loss: 0.5341 - val_accuracy: 0.7708\n",
            "Epoch 841/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4089 - accuracy: 0.7969 - val_loss: 0.5338 - val_accuracy: 0.7708\n",
            "Epoch 842/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4090 - accuracy: 0.7951 - val_loss: 0.5344 - val_accuracy: 0.7708\n",
            "Epoch 843/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4089 - accuracy: 0.7969 - val_loss: 0.5346 - val_accuracy: 0.7656\n",
            "Epoch 844/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4088 - accuracy: 0.7951 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 845/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4090 - accuracy: 0.7969 - val_loss: 0.5343 - val_accuracy: 0.7708\n",
            "Epoch 846/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4087 - accuracy: 0.7969 - val_loss: 0.5345 - val_accuracy: 0.7708\n",
            "Epoch 847/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4087 - accuracy: 0.7969 - val_loss: 0.5343 - val_accuracy: 0.7656\n",
            "Epoch 848/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4087 - accuracy: 0.7934 - val_loss: 0.5341 - val_accuracy: 0.7656\n",
            "Epoch 849/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4088 - accuracy: 0.7969 - val_loss: 0.5338 - val_accuracy: 0.7656\n",
            "Epoch 850/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4086 - accuracy: 0.7969 - val_loss: 0.5338 - val_accuracy: 0.7656\n",
            "Epoch 851/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4088 - accuracy: 0.7951 - val_loss: 0.5337 - val_accuracy: 0.7708\n",
            "Epoch 852/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4086 - accuracy: 0.7951 - val_loss: 0.5340 - val_accuracy: 0.7656\n",
            "Epoch 853/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4087 - accuracy: 0.7951 - val_loss: 0.5342 - val_accuracy: 0.7656\n",
            "Epoch 854/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4086 - accuracy: 0.7969 - val_loss: 0.5344 - val_accuracy: 0.7708\n",
            "Epoch 855/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4085 - accuracy: 0.7951 - val_loss: 0.5343 - val_accuracy: 0.7708\n",
            "Epoch 856/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4089 - accuracy: 0.7951 - val_loss: 0.5345 - val_accuracy: 0.7708\n",
            "Epoch 857/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4086 - accuracy: 0.7934 - val_loss: 0.5345 - val_accuracy: 0.7708\n",
            "Epoch 858/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4087 - accuracy: 0.7951 - val_loss: 0.5348 - val_accuracy: 0.7708\n",
            "Epoch 859/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4086 - accuracy: 0.7951 - val_loss: 0.5344 - val_accuracy: 0.7656\n",
            "Epoch 860/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4085 - accuracy: 0.7934 - val_loss: 0.5340 - val_accuracy: 0.7656\n",
            "Epoch 861/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4085 - accuracy: 0.7951 - val_loss: 0.5344 - val_accuracy: 0.7656\n",
            "Epoch 862/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4085 - accuracy: 0.7951 - val_loss: 0.5342 - val_accuracy: 0.7656\n",
            "Epoch 863/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4086 - accuracy: 0.7951 - val_loss: 0.5342 - val_accuracy: 0.7656\n",
            "Epoch 864/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4085 - accuracy: 0.7951 - val_loss: 0.5339 - val_accuracy: 0.7708\n",
            "Epoch 865/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4084 - accuracy: 0.7934 - val_loss: 0.5342 - val_accuracy: 0.7656\n",
            "Epoch 866/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4085 - accuracy: 0.7934 - val_loss: 0.5345 - val_accuracy: 0.7656\n",
            "Epoch 867/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4084 - accuracy: 0.7951 - val_loss: 0.5344 - val_accuracy: 0.7656\n",
            "Epoch 868/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4084 - accuracy: 0.7934 - val_loss: 0.5343 - val_accuracy: 0.7656\n",
            "Epoch 869/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4084 - accuracy: 0.7951 - val_loss: 0.5342 - val_accuracy: 0.7656\n",
            "Epoch 870/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4086 - accuracy: 0.7951 - val_loss: 0.5342 - val_accuracy: 0.7708\n",
            "Epoch 871/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4085 - accuracy: 0.7951 - val_loss: 0.5344 - val_accuracy: 0.7656\n",
            "Epoch 872/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4085 - accuracy: 0.7917 - val_loss: 0.5342 - val_accuracy: 0.7708\n",
            "Epoch 873/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.7951 - val_loss: 0.5342 - val_accuracy: 0.7708\n",
            "Epoch 874/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.7951 - val_loss: 0.5340 - val_accuracy: 0.7708\n",
            "Epoch 875/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4082 - accuracy: 0.7951 - val_loss: 0.5337 - val_accuracy: 0.7708\n",
            "Epoch 876/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4082 - accuracy: 0.7934 - val_loss: 0.5337 - val_accuracy: 0.7708\n",
            "Epoch 877/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4084 - accuracy: 0.7951 - val_loss: 0.5341 - val_accuracy: 0.7708\n",
            "Epoch 878/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4082 - accuracy: 0.7951 - val_loss: 0.5339 - val_accuracy: 0.7708\n",
            "Epoch 879/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4081 - accuracy: 0.7951 - val_loss: 0.5340 - val_accuracy: 0.7708\n",
            "Epoch 880/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4082 - accuracy: 0.7934 - val_loss: 0.5339 - val_accuracy: 0.7708\n",
            "Epoch 881/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4081 - accuracy: 0.7934 - val_loss: 0.5339 - val_accuracy: 0.7708\n",
            "Epoch 882/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4085 - accuracy: 0.7951 - val_loss: 0.5343 - val_accuracy: 0.7708\n",
            "Epoch 883/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4081 - accuracy: 0.7969 - val_loss: 0.5348 - val_accuracy: 0.7708\n",
            "Epoch 884/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4081 - accuracy: 0.7934 - val_loss: 0.5348 - val_accuracy: 0.7708\n",
            "Epoch 885/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4081 - accuracy: 0.7934 - val_loss: 0.5349 - val_accuracy: 0.7708\n",
            "Epoch 886/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4079 - accuracy: 0.7934 - val_loss: 0.5347 - val_accuracy: 0.7708\n",
            "Epoch 887/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4079 - accuracy: 0.7934 - val_loss: 0.5350 - val_accuracy: 0.7708\n",
            "Epoch 888/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4080 - accuracy: 0.7934 - val_loss: 0.5345 - val_accuracy: 0.7708\n",
            "Epoch 889/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4079 - accuracy: 0.7934 - val_loss: 0.5345 - val_accuracy: 0.7708\n",
            "Epoch 890/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4080 - accuracy: 0.7934 - val_loss: 0.5349 - val_accuracy: 0.7708\n",
            "Epoch 891/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4078 - accuracy: 0.7934 - val_loss: 0.5350 - val_accuracy: 0.7708\n",
            "Epoch 892/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4079 - accuracy: 0.7969 - val_loss: 0.5348 - val_accuracy: 0.7708\n",
            "Epoch 893/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4079 - accuracy: 0.7951 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 894/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4078 - accuracy: 0.7951 - val_loss: 0.5349 - val_accuracy: 0.7708\n",
            "Epoch 895/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4079 - accuracy: 0.7934 - val_loss: 0.5348 - val_accuracy: 0.7708\n",
            "Epoch 896/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4079 - accuracy: 0.7951 - val_loss: 0.5348 - val_accuracy: 0.7708\n",
            "Epoch 897/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4078 - accuracy: 0.7934 - val_loss: 0.5349 - val_accuracy: 0.7708\n",
            "Epoch 898/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4078 - accuracy: 0.7951 - val_loss: 0.5347 - val_accuracy: 0.7708\n",
            "Epoch 899/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4078 - accuracy: 0.7951 - val_loss: 0.5352 - val_accuracy: 0.7708\n",
            "Epoch 900/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.7934 - val_loss: 0.5352 - val_accuracy: 0.7708\n",
            "Epoch 901/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.7934 - val_loss: 0.5348 - val_accuracy: 0.7708\n",
            "Epoch 902/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.7934 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
            "Epoch 903/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.7934 - val_loss: 0.5354 - val_accuracy: 0.7708\n",
            "Epoch 904/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4075 - accuracy: 0.7934 - val_loss: 0.5354 - val_accuracy: 0.7708\n",
            "Epoch 905/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.7934 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
            "Epoch 906/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4075 - accuracy: 0.7951 - val_loss: 0.5351 - val_accuracy: 0.7708\n",
            "Epoch 907/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4076 - accuracy: 0.7934 - val_loss: 0.5350 - val_accuracy: 0.7708\n",
            "Epoch 908/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.7934 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
            "Epoch 909/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.7934 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
            "Epoch 910/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4075 - accuracy: 0.7934 - val_loss: 0.5351 - val_accuracy: 0.7708\n",
            "Epoch 911/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4075 - accuracy: 0.7934 - val_loss: 0.5351 - val_accuracy: 0.7708\n",
            "Epoch 912/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.7934 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
            "Epoch 913/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4075 - accuracy: 0.7934 - val_loss: 0.5351 - val_accuracy: 0.7708\n",
            "Epoch 914/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.7934 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
            "Epoch 915/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4074 - accuracy: 0.7934 - val_loss: 0.5354 - val_accuracy: 0.7708\n",
            "Epoch 916/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4074 - accuracy: 0.7934 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
            "Epoch 917/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4073 - accuracy: 0.7951 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
            "Epoch 918/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4073 - accuracy: 0.7934 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
            "Epoch 919/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4073 - accuracy: 0.7934 - val_loss: 0.5351 - val_accuracy: 0.7708\n",
            "Epoch 920/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4074 - accuracy: 0.7951 - val_loss: 0.5347 - val_accuracy: 0.7708\n",
            "Epoch 921/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4073 - accuracy: 0.7934 - val_loss: 0.5348 - val_accuracy: 0.7708\n",
            "Epoch 922/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4073 - accuracy: 0.7934 - val_loss: 0.5345 - val_accuracy: 0.7708\n",
            "Epoch 923/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4073 - accuracy: 0.7934 - val_loss: 0.5341 - val_accuracy: 0.7708\n",
            "Epoch 924/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4073 - accuracy: 0.7934 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 925/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.7934 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 926/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4072 - accuracy: 0.7934 - val_loss: 0.5347 - val_accuracy: 0.7708\n",
            "Epoch 927/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4072 - accuracy: 0.7934 - val_loss: 0.5351 - val_accuracy: 0.7708\n",
            "Epoch 928/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4071 - accuracy: 0.7934 - val_loss: 0.5352 - val_accuracy: 0.7708\n",
            "Epoch 929/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4073 - accuracy: 0.7951 - val_loss: 0.5351 - val_accuracy: 0.7708\n",
            "Epoch 930/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4071 - accuracy: 0.7934 - val_loss: 0.5350 - val_accuracy: 0.7708\n",
            "Epoch 931/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4071 - accuracy: 0.7917 - val_loss: 0.5349 - val_accuracy: 0.7708\n",
            "Epoch 932/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4071 - accuracy: 0.7951 - val_loss: 0.5349 - val_accuracy: 0.7708\n",
            "Epoch 933/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4071 - accuracy: 0.7917 - val_loss: 0.5349 - val_accuracy: 0.7708\n",
            "Epoch 934/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4072 - accuracy: 0.7917 - val_loss: 0.5348 - val_accuracy: 0.7708\n",
            "Epoch 935/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4070 - accuracy: 0.7934 - val_loss: 0.5350 - val_accuracy: 0.7708\n",
            "Epoch 936/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.7934 - val_loss: 0.5351 - val_accuracy: 0.7708\n",
            "Epoch 937/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4072 - accuracy: 0.7917 - val_loss: 0.5352 - val_accuracy: 0.7708\n",
            "Epoch 938/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4068 - accuracy: 0.7969 - val_loss: 0.5354 - val_accuracy: 0.7708\n",
            "Epoch 939/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4069 - accuracy: 0.7934 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
            "Epoch 940/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4069 - accuracy: 0.7934 - val_loss: 0.5351 - val_accuracy: 0.7708\n",
            "Epoch 941/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.7951 - val_loss: 0.5351 - val_accuracy: 0.7708\n",
            "Epoch 942/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4069 - accuracy: 0.7934 - val_loss: 0.5348 - val_accuracy: 0.7708\n",
            "Epoch 943/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4069 - accuracy: 0.7951 - val_loss: 0.5350 - val_accuracy: 0.7708\n",
            "Epoch 944/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4069 - accuracy: 0.7934 - val_loss: 0.5350 - val_accuracy: 0.7708\n",
            "Epoch 945/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4069 - accuracy: 0.7934 - val_loss: 0.5352 - val_accuracy: 0.7708\n",
            "Epoch 946/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4066 - accuracy: 0.7951 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
            "Epoch 947/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4067 - accuracy: 0.7951 - val_loss: 0.5355 - val_accuracy: 0.7708\n",
            "Epoch 948/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.7934 - val_loss: 0.5352 - val_accuracy: 0.7708\n",
            "Epoch 949/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.7934 - val_loss: 0.5355 - val_accuracy: 0.7708\n",
            "Epoch 950/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.7934 - val_loss: 0.5354 - val_accuracy: 0.7708\n",
            "Epoch 951/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4066 - accuracy: 0.7917 - val_loss: 0.5352 - val_accuracy: 0.7708\n",
            "Epoch 952/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4064 - accuracy: 0.7969 - val_loss: 0.5355 - val_accuracy: 0.7708\n",
            "Epoch 953/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4066 - accuracy: 0.7969 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
            "Epoch 954/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.7917 - val_loss: 0.5352 - val_accuracy: 0.7708\n",
            "Epoch 955/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4063 - accuracy: 0.7934 - val_loss: 0.5354 - val_accuracy: 0.7708\n",
            "Epoch 956/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.7917 - val_loss: 0.5354 - val_accuracy: 0.7708\n",
            "Epoch 957/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.7951 - val_loss: 0.5352 - val_accuracy: 0.7708\n",
            "Epoch 958/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.7951 - val_loss: 0.5357 - val_accuracy: 0.7708\n",
            "Epoch 959/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4061 - accuracy: 0.7934 - val_loss: 0.5354 - val_accuracy: 0.7708\n",
            "Epoch 960/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4063 - accuracy: 0.7951 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
            "Epoch 961/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4063 - accuracy: 0.7934 - val_loss: 0.5355 - val_accuracy: 0.7708\n",
            "Epoch 962/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4062 - accuracy: 0.7969 - val_loss: 0.5354 - val_accuracy: 0.7708\n",
            "Epoch 963/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4061 - accuracy: 0.7951 - val_loss: 0.5356 - val_accuracy: 0.7708\n",
            "Epoch 964/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4062 - accuracy: 0.7951 - val_loss: 0.5357 - val_accuracy: 0.7708\n",
            "Epoch 965/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4061 - accuracy: 0.7934 - val_loss: 0.5358 - val_accuracy: 0.7708\n",
            "Epoch 966/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4060 - accuracy: 0.7951 - val_loss: 0.5355 - val_accuracy: 0.7760\n",
            "Epoch 967/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4062 - accuracy: 0.7934 - val_loss: 0.5358 - val_accuracy: 0.7760\n",
            "Epoch 968/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4060 - accuracy: 0.7969 - val_loss: 0.5359 - val_accuracy: 0.7760\n",
            "Epoch 969/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4062 - accuracy: 0.7951 - val_loss: 0.5357 - val_accuracy: 0.7760\n",
            "Epoch 970/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4060 - accuracy: 0.7934 - val_loss: 0.5357 - val_accuracy: 0.7760\n",
            "Epoch 971/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4062 - accuracy: 0.7969 - val_loss: 0.5358 - val_accuracy: 0.7708\n",
            "Epoch 972/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4061 - accuracy: 0.7934 - val_loss: 0.5356 - val_accuracy: 0.7760\n",
            "Epoch 973/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4059 - accuracy: 0.7951 - val_loss: 0.5357 - val_accuracy: 0.7760\n",
            "Epoch 974/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4061 - accuracy: 0.7969 - val_loss: 0.5357 - val_accuracy: 0.7760\n",
            "Epoch 975/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4060 - accuracy: 0.7934 - val_loss: 0.5358 - val_accuracy: 0.7760\n",
            "Epoch 976/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4060 - accuracy: 0.7951 - val_loss: 0.5357 - val_accuracy: 0.7760\n",
            "Epoch 977/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4059 - accuracy: 0.7969 - val_loss: 0.5356 - val_accuracy: 0.7760\n",
            "Epoch 978/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4059 - accuracy: 0.7951 - val_loss: 0.5352 - val_accuracy: 0.7760\n",
            "Epoch 979/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4059 - accuracy: 0.7969 - val_loss: 0.5352 - val_accuracy: 0.7760\n",
            "Epoch 980/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4058 - accuracy: 0.7951 - val_loss: 0.5354 - val_accuracy: 0.7708\n",
            "Epoch 981/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4058 - accuracy: 0.7969 - val_loss: 0.5353 - val_accuracy: 0.7760\n",
            "Epoch 982/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4059 - accuracy: 0.7969 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
            "Epoch 983/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4059 - accuracy: 0.7951 - val_loss: 0.5354 - val_accuracy: 0.7708\n",
            "Epoch 984/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4057 - accuracy: 0.7951 - val_loss: 0.5354 - val_accuracy: 0.7708\n",
            "Epoch 985/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4056 - accuracy: 0.7969 - val_loss: 0.5354 - val_accuracy: 0.7708\n",
            "Epoch 986/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4056 - accuracy: 0.7969 - val_loss: 0.5352 - val_accuracy: 0.7708\n",
            "Epoch 987/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4059 - accuracy: 0.7969 - val_loss: 0.5350 - val_accuracy: 0.7708\n",
            "Epoch 988/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4056 - accuracy: 0.7951 - val_loss: 0.5348 - val_accuracy: 0.7708\n",
            "Epoch 989/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4057 - accuracy: 0.7951 - val_loss: 0.5345 - val_accuracy: 0.7708\n",
            "Epoch 990/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4057 - accuracy: 0.7951 - val_loss: 0.5347 - val_accuracy: 0.7708\n",
            "Epoch 991/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4056 - accuracy: 0.7969 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 992/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4057 - accuracy: 0.7969 - val_loss: 0.5345 - val_accuracy: 0.7760\n",
            "Epoch 993/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4056 - accuracy: 0.7969 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 994/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4055 - accuracy: 0.7986 - val_loss: 0.5350 - val_accuracy: 0.7708\n",
            "Epoch 995/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4054 - accuracy: 0.7969 - val_loss: 0.5351 - val_accuracy: 0.7708\n",
            "Epoch 996/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4056 - accuracy: 0.7969 - val_loss: 0.5351 - val_accuracy: 0.7708\n",
            "Epoch 997/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4056 - accuracy: 0.7969 - val_loss: 0.5349 - val_accuracy: 0.7708\n",
            "Epoch 998/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4057 - accuracy: 0.7951 - val_loss: 0.5351 - val_accuracy: 0.7708\n",
            "Epoch 999/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.7986 - val_loss: 0.5352 - val_accuracy: 0.7708\n",
            "Epoch 1000/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4054 - accuracy: 0.7951 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
            "Epoch 1001/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4054 - accuracy: 0.7969 - val_loss: 0.5351 - val_accuracy: 0.7708\n",
            "Epoch 1002/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4053 - accuracy: 0.7951 - val_loss: 0.5352 - val_accuracy: 0.7708\n",
            "Epoch 1003/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4052 - accuracy: 0.7969 - val_loss: 0.5350 - val_accuracy: 0.7708\n",
            "Epoch 1004/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4053 - accuracy: 0.7986 - val_loss: 0.5349 - val_accuracy: 0.7708\n",
            "Epoch 1005/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4053 - accuracy: 0.7986 - val_loss: 0.5348 - val_accuracy: 0.7708\n",
            "Epoch 1006/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.7969 - val_loss: 0.5345 - val_accuracy: 0.7708\n",
            "Epoch 1007/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.7986 - val_loss: 0.5348 - val_accuracy: 0.7708\n",
            "Epoch 1008/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4052 - accuracy: 0.7951 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 1009/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4052 - accuracy: 0.7986 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 1010/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4052 - accuracy: 0.7986 - val_loss: 0.5345 - val_accuracy: 0.7708\n",
            "Epoch 1011/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4051 - accuracy: 0.7951 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 1012/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4052 - accuracy: 0.7969 - val_loss: 0.5345 - val_accuracy: 0.7708\n",
            "Epoch 1013/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4051 - accuracy: 0.7986 - val_loss: 0.5349 - val_accuracy: 0.7708\n",
            "Epoch 1014/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4052 - accuracy: 0.7951 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 1015/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4049 - accuracy: 0.7969 - val_loss: 0.5349 - val_accuracy: 0.7708\n",
            "Epoch 1016/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4050 - accuracy: 0.7951 - val_loss: 0.5351 - val_accuracy: 0.7708\n",
            "Epoch 1017/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4051 - accuracy: 0.7969 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
            "Epoch 1018/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4050 - accuracy: 0.7986 - val_loss: 0.5350 - val_accuracy: 0.7708\n",
            "Epoch 1019/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4050 - accuracy: 0.7986 - val_loss: 0.5349 - val_accuracy: 0.7708\n",
            "Epoch 1020/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4049 - accuracy: 0.7969 - val_loss: 0.5348 - val_accuracy: 0.7708\n",
            "Epoch 1021/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4048 - accuracy: 0.7986 - val_loss: 0.5344 - val_accuracy: 0.7708\n",
            "Epoch 1022/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4050 - accuracy: 0.7969 - val_loss: 0.5345 - val_accuracy: 0.7708\n",
            "Epoch 1023/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4051 - accuracy: 0.7969 - val_loss: 0.5343 - val_accuracy: 0.7708\n",
            "Epoch 1024/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.7969 - val_loss: 0.5347 - val_accuracy: 0.7708\n",
            "Epoch 1025/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4047 - accuracy: 0.7986 - val_loss: 0.5350 - val_accuracy: 0.7708\n",
            "Epoch 1026/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.7986 - val_loss: 0.5345 - val_accuracy: 0.7708\n",
            "Epoch 1027/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4049 - accuracy: 0.7951 - val_loss: 0.5347 - val_accuracy: 0.7708\n",
            "Epoch 1028/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4049 - accuracy: 0.7951 - val_loss: 0.5347 - val_accuracy: 0.7708\n",
            "Epoch 1029/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4049 - accuracy: 0.7969 - val_loss: 0.5349 - val_accuracy: 0.7708\n",
            "Epoch 1030/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4049 - accuracy: 0.7969 - val_loss: 0.5348 - val_accuracy: 0.7708\n",
            "Epoch 1031/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4047 - accuracy: 0.7969 - val_loss: 0.5344 - val_accuracy: 0.7708\n",
            "Epoch 1032/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.7969 - val_loss: 0.5345 - val_accuracy: 0.7708\n",
            "Epoch 1033/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4047 - accuracy: 0.7969 - val_loss: 0.5345 - val_accuracy: 0.7708\n",
            "Epoch 1034/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4045 - accuracy: 0.7986 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 1035/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4045 - accuracy: 0.7951 - val_loss: 0.5344 - val_accuracy: 0.7708\n",
            "Epoch 1036/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.7951 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 1037/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4049 - accuracy: 0.7986 - val_loss: 0.5347 - val_accuracy: 0.7708\n",
            "Epoch 1038/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4046 - accuracy: 0.7986 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 1039/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4046 - accuracy: 0.7986 - val_loss: 0.5349 - val_accuracy: 0.7708\n",
            "Epoch 1040/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.7986 - val_loss: 0.5345 - val_accuracy: 0.7708\n",
            "Epoch 1041/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4045 - accuracy: 0.7969 - val_loss: 0.5348 - val_accuracy: 0.7708\n",
            "Epoch 1042/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4045 - accuracy: 0.7969 - val_loss: 0.5347 - val_accuracy: 0.7708\n",
            "Epoch 1043/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.7969 - val_loss: 0.5347 - val_accuracy: 0.7708\n",
            "Epoch 1044/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.7951 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 1045/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.7986 - val_loss: 0.5350 - val_accuracy: 0.7708\n",
            "Epoch 1046/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4043 - accuracy: 0.7969 - val_loss: 0.5351 - val_accuracy: 0.7708\n",
            "Epoch 1047/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.7969 - val_loss: 0.5350 - val_accuracy: 0.7708\n",
            "Epoch 1048/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4043 - accuracy: 0.7969 - val_loss: 0.5352 - val_accuracy: 0.7708\n",
            "Epoch 1049/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4043 - accuracy: 0.7969 - val_loss: 0.5351 - val_accuracy: 0.7708\n",
            "Epoch 1050/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4044 - accuracy: 0.7951 - val_loss: 0.5352 - val_accuracy: 0.7708\n",
            "Epoch 1051/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.7969 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
            "Epoch 1052/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4043 - accuracy: 0.7986 - val_loss: 0.5355 - val_accuracy: 0.7708\n",
            "Epoch 1053/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4043 - accuracy: 0.7951 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
            "Epoch 1054/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4043 - accuracy: 0.7951 - val_loss: 0.5351 - val_accuracy: 0.7708\n",
            "Epoch 1055/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4043 - accuracy: 0.7969 - val_loss: 0.5350 - val_accuracy: 0.7708\n",
            "Epoch 1056/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.7969 - val_loss: 0.5348 - val_accuracy: 0.7708\n",
            "Epoch 1057/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.7969 - val_loss: 0.5349 - val_accuracy: 0.7708\n",
            "Epoch 1058/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4044 - accuracy: 0.7951 - val_loss: 0.5350 - val_accuracy: 0.7708\n",
            "Epoch 1059/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4041 - accuracy: 0.7969 - val_loss: 0.5347 - val_accuracy: 0.7708\n",
            "Epoch 1060/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4041 - accuracy: 0.7969 - val_loss: 0.5345 - val_accuracy: 0.7708\n",
            "Epoch 1061/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.7986 - val_loss: 0.5343 - val_accuracy: 0.7708\n",
            "Epoch 1062/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4043 - accuracy: 0.7969 - val_loss: 0.5340 - val_accuracy: 0.7708\n",
            "Epoch 1063/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4042 - accuracy: 0.7951 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 1064/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.7951 - val_loss: 0.5348 - val_accuracy: 0.7708\n",
            "Epoch 1065/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4041 - accuracy: 0.7951 - val_loss: 0.5347 - val_accuracy: 0.7708\n",
            "Epoch 1066/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4040 - accuracy: 0.7951 - val_loss: 0.5347 - val_accuracy: 0.7708\n",
            "Epoch 1067/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4042 - accuracy: 0.7986 - val_loss: 0.5345 - val_accuracy: 0.7708\n",
            "Epoch 1068/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4039 - accuracy: 0.7969 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 1069/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4040 - accuracy: 0.7986 - val_loss: 0.5347 - val_accuracy: 0.7708\n",
            "Epoch 1070/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.7969 - val_loss: 0.5351 - val_accuracy: 0.7708\n",
            "Epoch 1071/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.7969 - val_loss: 0.5348 - val_accuracy: 0.7708\n",
            "Epoch 1072/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4041 - accuracy: 0.7951 - val_loss: 0.5347 - val_accuracy: 0.7708\n",
            "Epoch 1073/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4040 - accuracy: 0.7969 - val_loss: 0.5344 - val_accuracy: 0.7708\n",
            "Epoch 1074/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.7969 - val_loss: 0.5343 - val_accuracy: 0.7708\n",
            "Epoch 1075/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4037 - accuracy: 0.7969 - val_loss: 0.5348 - val_accuracy: 0.7708\n",
            "Epoch 1076/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4040 - accuracy: 0.7986 - val_loss: 0.5352 - val_accuracy: 0.7708\n",
            "Epoch 1077/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4037 - accuracy: 0.7986 - val_loss: 0.5351 - val_accuracy: 0.7708\n",
            "Epoch 1078/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4038 - accuracy: 0.7969 - val_loss: 0.5352 - val_accuracy: 0.7708\n",
            "Epoch 1079/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4037 - accuracy: 0.7951 - val_loss: 0.5355 - val_accuracy: 0.7708\n",
            "Epoch 1080/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4037 - accuracy: 0.7969 - val_loss: 0.5354 - val_accuracy: 0.7708\n",
            "Epoch 1081/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4037 - accuracy: 0.7969 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
            "Epoch 1082/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4037 - accuracy: 0.7951 - val_loss: 0.5351 - val_accuracy: 0.7708\n",
            "Epoch 1083/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4036 - accuracy: 0.7951 - val_loss: 0.5350 - val_accuracy: 0.7708\n",
            "Epoch 1084/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4037 - accuracy: 0.7969 - val_loss: 0.5349 - val_accuracy: 0.7708\n",
            "Epoch 1085/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4036 - accuracy: 0.7951 - val_loss: 0.5349 - val_accuracy: 0.7708\n",
            "Epoch 1086/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4036 - accuracy: 0.7986 - val_loss: 0.5350 - val_accuracy: 0.7708\n",
            "Epoch 1087/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4037 - accuracy: 0.7986 - val_loss: 0.5348 - val_accuracy: 0.7708\n",
            "Epoch 1088/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4036 - accuracy: 0.7969 - val_loss: 0.5345 - val_accuracy: 0.7708\n",
            "Epoch 1089/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4036 - accuracy: 0.7969 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 1090/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4034 - accuracy: 0.7934 - val_loss: 0.5349 - val_accuracy: 0.7708\n",
            "Epoch 1091/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4034 - accuracy: 0.7951 - val_loss: 0.5350 - val_accuracy: 0.7708\n",
            "Epoch 1092/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4036 - accuracy: 0.7969 - val_loss: 0.5345 - val_accuracy: 0.7708\n",
            "Epoch 1093/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4035 - accuracy: 0.7969 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 1094/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4033 - accuracy: 0.7969 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 1095/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4035 - accuracy: 0.7969 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 1096/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4034 - accuracy: 0.7969 - val_loss: 0.5344 - val_accuracy: 0.7708\n",
            "Epoch 1097/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4035 - accuracy: 0.7934 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 1098/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4033 - accuracy: 0.7951 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 1099/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4033 - accuracy: 0.7969 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 1100/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4033 - accuracy: 0.7934 - val_loss: 0.5347 - val_accuracy: 0.7708\n",
            "Epoch 1101/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4034 - accuracy: 0.7986 - val_loss: 0.5345 - val_accuracy: 0.7708\n",
            "Epoch 1102/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4033 - accuracy: 0.8021 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 1103/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.7951 - val_loss: 0.5347 - val_accuracy: 0.7708\n",
            "Epoch 1104/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4034 - accuracy: 0.7969 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 1105/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4031 - accuracy: 0.7969 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 1106/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4033 - accuracy: 0.7969 - val_loss: 0.5345 - val_accuracy: 0.7708\n",
            "Epoch 1107/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4031 - accuracy: 0.7969 - val_loss: 0.5343 - val_accuracy: 0.7708\n",
            "Epoch 1108/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4031 - accuracy: 0.7951 - val_loss: 0.5347 - val_accuracy: 0.7708\n",
            "Epoch 1109/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.7969 - val_loss: 0.5348 - val_accuracy: 0.7708\n",
            "Epoch 1110/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4031 - accuracy: 0.7934 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 1111/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4031 - accuracy: 0.8003 - val_loss: 0.5343 - val_accuracy: 0.7708\n",
            "Epoch 1112/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4032 - accuracy: 0.8003 - val_loss: 0.5344 - val_accuracy: 0.7708\n",
            "Epoch 1113/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4031 - accuracy: 0.8003 - val_loss: 0.5345 - val_accuracy: 0.7708\n",
            "Epoch 1114/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4033 - accuracy: 0.7969 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 1115/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4030 - accuracy: 0.7969 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 1116/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4031 - accuracy: 0.7986 - val_loss: 0.5344 - val_accuracy: 0.7708\n",
            "Epoch 1117/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4030 - accuracy: 0.7986 - val_loss: 0.5344 - val_accuracy: 0.7708\n",
            "Epoch 1118/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4029 - accuracy: 0.7969 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 1119/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4032 - accuracy: 0.7986 - val_loss: 0.5345 - val_accuracy: 0.7708\n",
            "Epoch 1120/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4030 - accuracy: 0.7986 - val_loss: 0.5345 - val_accuracy: 0.7708\n",
            "Epoch 1121/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4029 - accuracy: 0.8003 - val_loss: 0.5347 - val_accuracy: 0.7708\n",
            "Epoch 1122/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4031 - accuracy: 0.8003 - val_loss: 0.5347 - val_accuracy: 0.7760\n",
            "Epoch 1123/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4030 - accuracy: 0.7969 - val_loss: 0.5349 - val_accuracy: 0.7760\n",
            "Epoch 1124/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4029 - accuracy: 0.7986 - val_loss: 0.5349 - val_accuracy: 0.7760\n",
            "Epoch 1125/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4030 - accuracy: 0.7969 - val_loss: 0.5348 - val_accuracy: 0.7760\n",
            "Epoch 1126/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4029 - accuracy: 0.8003 - val_loss: 0.5349 - val_accuracy: 0.7760\n",
            "Epoch 1127/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4030 - accuracy: 0.7986 - val_loss: 0.5351 - val_accuracy: 0.7760\n",
            "Epoch 1128/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4028 - accuracy: 0.8003 - val_loss: 0.5349 - val_accuracy: 0.7760\n",
            "Epoch 1129/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4030 - accuracy: 0.7969 - val_loss: 0.5346 - val_accuracy: 0.7760\n",
            "Epoch 1130/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4031 - accuracy: 0.7986 - val_loss: 0.5347 - val_accuracy: 0.7760\n",
            "Epoch 1131/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4028 - accuracy: 0.8038 - val_loss: 0.5347 - val_accuracy: 0.7760\n",
            "Epoch 1132/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4027 - accuracy: 0.7969 - val_loss: 0.5345 - val_accuracy: 0.7760\n",
            "Epoch 1133/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4028 - accuracy: 0.8003 - val_loss: 0.5344 - val_accuracy: 0.7760\n",
            "Epoch 1134/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4028 - accuracy: 0.8003 - val_loss: 0.5343 - val_accuracy: 0.7760\n",
            "Epoch 1135/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4026 - accuracy: 0.8003 - val_loss: 0.5345 - val_accuracy: 0.7760\n",
            "Epoch 1136/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4029 - accuracy: 0.8003 - val_loss: 0.5346 - val_accuracy: 0.7760\n",
            "Epoch 1137/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4027 - accuracy: 0.8038 - val_loss: 0.5344 - val_accuracy: 0.7760\n",
            "Epoch 1138/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.8021 - val_loss: 0.5344 - val_accuracy: 0.7760\n",
            "Epoch 1139/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4028 - accuracy: 0.8003 - val_loss: 0.5344 - val_accuracy: 0.7760\n",
            "Epoch 1140/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4024 - accuracy: 0.8003 - val_loss: 0.5347 - val_accuracy: 0.7760\n",
            "Epoch 1141/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4026 - accuracy: 0.8003 - val_loss: 0.5345 - val_accuracy: 0.7760\n",
            "Epoch 1142/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4027 - accuracy: 0.7969 - val_loss: 0.5344 - val_accuracy: 0.7760\n",
            "Epoch 1143/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4024 - accuracy: 0.8003 - val_loss: 0.5341 - val_accuracy: 0.7760\n",
            "Epoch 1144/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4023 - accuracy: 0.8003 - val_loss: 0.5342 - val_accuracy: 0.7760\n",
            "Epoch 1145/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.8021 - val_loss: 0.5342 - val_accuracy: 0.7760\n",
            "Epoch 1146/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4024 - accuracy: 0.8003 - val_loss: 0.5340 - val_accuracy: 0.7760\n",
            "Epoch 1147/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4025 - accuracy: 0.7986 - val_loss: 0.5341 - val_accuracy: 0.7760\n",
            "Epoch 1148/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4023 - accuracy: 0.7986 - val_loss: 0.5342 - val_accuracy: 0.7760\n",
            "Epoch 1149/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4024 - accuracy: 0.8003 - val_loss: 0.5342 - val_accuracy: 0.7760\n",
            "Epoch 1150/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4023 - accuracy: 0.7969 - val_loss: 0.5344 - val_accuracy: 0.7760\n",
            "Epoch 1151/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4021 - accuracy: 0.7986 - val_loss: 0.5343 - val_accuracy: 0.7760\n",
            "Epoch 1152/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4024 - accuracy: 0.7986 - val_loss: 0.5342 - val_accuracy: 0.7760\n",
            "Epoch 1153/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4025 - accuracy: 0.7986 - val_loss: 0.5340 - val_accuracy: 0.7760\n",
            "Epoch 1154/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8003 - val_loss: 0.5341 - val_accuracy: 0.7760\n",
            "Epoch 1155/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.7986 - val_loss: 0.5339 - val_accuracy: 0.7760\n",
            "Epoch 1156/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4022 - accuracy: 0.8003 - val_loss: 0.5342 - val_accuracy: 0.7708\n",
            "Epoch 1157/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4022 - accuracy: 0.7986 - val_loss: 0.5341 - val_accuracy: 0.7760\n",
            "Epoch 1158/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4022 - accuracy: 0.7986 - val_loss: 0.5341 - val_accuracy: 0.7708\n",
            "Epoch 1159/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4020 - accuracy: 0.7986 - val_loss: 0.5342 - val_accuracy: 0.7760\n",
            "Epoch 1160/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.8003 - val_loss: 0.5339 - val_accuracy: 0.7812\n",
            "Epoch 1161/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8003 - val_loss: 0.5342 - val_accuracy: 0.7760\n",
            "Epoch 1162/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.7986 - val_loss: 0.5341 - val_accuracy: 0.7760\n",
            "Epoch 1163/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.8003 - val_loss: 0.5341 - val_accuracy: 0.7760\n",
            "Epoch 1164/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4022 - accuracy: 0.8021 - val_loss: 0.5341 - val_accuracy: 0.7760\n",
            "Epoch 1165/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4020 - accuracy: 0.7986 - val_loss: 0.5342 - val_accuracy: 0.7760\n",
            "Epoch 1166/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.8003 - val_loss: 0.5338 - val_accuracy: 0.7812\n",
            "Epoch 1167/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4020 - accuracy: 0.7969 - val_loss: 0.5339 - val_accuracy: 0.7760\n",
            "Epoch 1168/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4021 - accuracy: 0.7986 - val_loss: 0.5340 - val_accuracy: 0.7760\n",
            "Epoch 1169/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4020 - accuracy: 0.7986 - val_loss: 0.5341 - val_accuracy: 0.7760\n",
            "Epoch 1170/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4020 - accuracy: 0.8003 - val_loss: 0.5344 - val_accuracy: 0.7760\n",
            "Epoch 1171/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4020 - accuracy: 0.7986 - val_loss: 0.5338 - val_accuracy: 0.7760\n",
            "Epoch 1172/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4018 - accuracy: 0.7986 - val_loss: 0.5339 - val_accuracy: 0.7760\n",
            "Epoch 1173/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4020 - accuracy: 0.7969 - val_loss: 0.5340 - val_accuracy: 0.7760\n",
            "Epoch 1174/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.7986 - val_loss: 0.5341 - val_accuracy: 0.7760\n",
            "Epoch 1175/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4017 - accuracy: 0.7986 - val_loss: 0.5343 - val_accuracy: 0.7760\n",
            "Epoch 1176/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4015 - accuracy: 0.7986 - val_loss: 0.5342 - val_accuracy: 0.7760\n",
            "Epoch 1177/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4017 - accuracy: 0.8003 - val_loss: 0.5343 - val_accuracy: 0.7760\n",
            "Epoch 1178/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4018 - accuracy: 0.7986 - val_loss: 0.5340 - val_accuracy: 0.7760\n",
            "Epoch 1179/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4018 - accuracy: 0.7986 - val_loss: 0.5341 - val_accuracy: 0.7760\n",
            "Epoch 1180/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4016 - accuracy: 0.8003 - val_loss: 0.5341 - val_accuracy: 0.7760\n",
            "Epoch 1181/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4018 - accuracy: 0.7986 - val_loss: 0.5342 - val_accuracy: 0.7760\n",
            "Epoch 1182/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4018 - accuracy: 0.7986 - val_loss: 0.5343 - val_accuracy: 0.7760\n",
            "Epoch 1183/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4020 - accuracy: 0.8003 - val_loss: 0.5341 - val_accuracy: 0.7760\n",
            "Epoch 1184/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4016 - accuracy: 0.8003 - val_loss: 0.5345 - val_accuracy: 0.7760\n",
            "Epoch 1185/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4016 - accuracy: 0.7969 - val_loss: 0.5348 - val_accuracy: 0.7760\n",
            "Epoch 1186/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4017 - accuracy: 0.7986 - val_loss: 0.5344 - val_accuracy: 0.7760\n",
            "Epoch 1187/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4016 - accuracy: 0.8003 - val_loss: 0.5343 - val_accuracy: 0.7760\n",
            "Epoch 1188/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4017 - accuracy: 0.7986 - val_loss: 0.5343 - val_accuracy: 0.7760\n",
            "Epoch 1189/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4018 - accuracy: 0.7986 - val_loss: 0.5342 - val_accuracy: 0.7760\n",
            "Epoch 1190/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4016 - accuracy: 0.7986 - val_loss: 0.5343 - val_accuracy: 0.7760\n",
            "Epoch 1191/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4016 - accuracy: 0.8003 - val_loss: 0.5343 - val_accuracy: 0.7760\n",
            "Epoch 1192/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4014 - accuracy: 0.8003 - val_loss: 0.5342 - val_accuracy: 0.7760\n",
            "Epoch 1193/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4015 - accuracy: 0.7986 - val_loss: 0.5341 - val_accuracy: 0.7760\n",
            "Epoch 1194/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4015 - accuracy: 0.7986 - val_loss: 0.5343 - val_accuracy: 0.7760\n",
            "Epoch 1195/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4015 - accuracy: 0.8003 - val_loss: 0.5343 - val_accuracy: 0.7760\n",
            "Epoch 1196/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4014 - accuracy: 0.7969 - val_loss: 0.5344 - val_accuracy: 0.7760\n",
            "Epoch 1197/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4015 - accuracy: 0.7969 - val_loss: 0.5343 - val_accuracy: 0.7760\n",
            "Epoch 1198/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4014 - accuracy: 0.7986 - val_loss: 0.5344 - val_accuracy: 0.7760\n",
            "Epoch 1199/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4016 - accuracy: 0.7986 - val_loss: 0.5342 - val_accuracy: 0.7760\n",
            "Epoch 1200/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4016 - accuracy: 0.8003 - val_loss: 0.5346 - val_accuracy: 0.7760\n",
            "Epoch 1201/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4014 - accuracy: 0.7986 - val_loss: 0.5350 - val_accuracy: 0.7760\n",
            "Epoch 1202/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4014 - accuracy: 0.8003 - val_loss: 0.5347 - val_accuracy: 0.7760\n",
            "Epoch 1203/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4013 - accuracy: 0.7986 - val_loss: 0.5344 - val_accuracy: 0.7760\n",
            "Epoch 1204/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4013 - accuracy: 0.7986 - val_loss: 0.5341 - val_accuracy: 0.7760\n",
            "Epoch 1205/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4014 - accuracy: 0.7969 - val_loss: 0.5345 - val_accuracy: 0.7760\n",
            "Epoch 1206/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4015 - accuracy: 0.8003 - val_loss: 0.5344 - val_accuracy: 0.7760\n",
            "Epoch 1207/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.7969 - val_loss: 0.5342 - val_accuracy: 0.7760\n",
            "Epoch 1208/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4014 - accuracy: 0.7986 - val_loss: 0.5344 - val_accuracy: 0.7760\n",
            "Epoch 1209/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4012 - accuracy: 0.8003 - val_loss: 0.5343 - val_accuracy: 0.7760\n",
            "Epoch 1210/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4014 - accuracy: 0.7986 - val_loss: 0.5345 - val_accuracy: 0.7760\n",
            "Epoch 1211/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4015 - accuracy: 0.7986 - val_loss: 0.5342 - val_accuracy: 0.7760\n",
            "Epoch 1212/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4014 - accuracy: 0.7986 - val_loss: 0.5342 - val_accuracy: 0.7760\n",
            "Epoch 1213/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4012 - accuracy: 0.7986 - val_loss: 0.5341 - val_accuracy: 0.7812\n",
            "Epoch 1214/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4012 - accuracy: 0.8003 - val_loss: 0.5342 - val_accuracy: 0.7760\n",
            "Epoch 1215/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4015 - accuracy: 0.8021 - val_loss: 0.5345 - val_accuracy: 0.7760\n",
            "Epoch 1216/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4013 - accuracy: 0.7986 - val_loss: 0.5346 - val_accuracy: 0.7760\n",
            "Epoch 1217/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4011 - accuracy: 0.7986 - val_loss: 0.5345 - val_accuracy: 0.7760\n",
            "Epoch 1218/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.7969 - val_loss: 0.5345 - val_accuracy: 0.7760\n",
            "Epoch 1219/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.8003 - val_loss: 0.5343 - val_accuracy: 0.7760\n",
            "Epoch 1220/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4010 - accuracy: 0.7986 - val_loss: 0.5345 - val_accuracy: 0.7812\n",
            "Epoch 1221/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4010 - accuracy: 0.7986 - val_loss: 0.5344 - val_accuracy: 0.7812\n",
            "Epoch 1222/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4011 - accuracy: 0.7986 - val_loss: 0.5343 - val_accuracy: 0.7812\n",
            "Epoch 1223/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4010 - accuracy: 0.8003 - val_loss: 0.5342 - val_accuracy: 0.7812\n",
            "Epoch 1224/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4012 - accuracy: 0.7986 - val_loss: 0.5341 - val_accuracy: 0.7812\n",
            "Epoch 1225/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4015 - accuracy: 0.8003 - val_loss: 0.5338 - val_accuracy: 0.7760\n",
            "Epoch 1226/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4009 - accuracy: 0.8003 - val_loss: 0.5339 - val_accuracy: 0.7812\n",
            "Epoch 1227/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4010 - accuracy: 0.8003 - val_loss: 0.5340 - val_accuracy: 0.7812\n",
            "Epoch 1228/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4011 - accuracy: 0.8003 - val_loss: 0.5340 - val_accuracy: 0.7760\n",
            "Epoch 1229/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4010 - accuracy: 0.8021 - val_loss: 0.5339 - val_accuracy: 0.7812\n",
            "Epoch 1230/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4008 - accuracy: 0.7986 - val_loss: 0.5339 - val_accuracy: 0.7760\n",
            "Epoch 1231/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4009 - accuracy: 0.8003 - val_loss: 0.5337 - val_accuracy: 0.7760\n",
            "Epoch 1232/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4012 - accuracy: 0.7969 - val_loss: 0.5338 - val_accuracy: 0.7760\n",
            "Epoch 1233/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4008 - accuracy: 0.8003 - val_loss: 0.5341 - val_accuracy: 0.7760\n",
            "Epoch 1234/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4010 - accuracy: 0.8038 - val_loss: 0.5343 - val_accuracy: 0.7812\n",
            "Epoch 1235/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4007 - accuracy: 0.8021 - val_loss: 0.5343 - val_accuracy: 0.7812\n",
            "Epoch 1236/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8003 - val_loss: 0.5341 - val_accuracy: 0.7812\n",
            "Epoch 1237/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4009 - accuracy: 0.8021 - val_loss: 0.5344 - val_accuracy: 0.7812\n",
            "Epoch 1238/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4008 - accuracy: 0.8003 - val_loss: 0.5342 - val_accuracy: 0.7812\n",
            "Epoch 1239/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4010 - accuracy: 0.8003 - val_loss: 0.5346 - val_accuracy: 0.7812\n",
            "Epoch 1240/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4007 - accuracy: 0.8003 - val_loss: 0.5345 - val_accuracy: 0.7812\n",
            "Epoch 1241/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4006 - accuracy: 0.8003 - val_loss: 0.5343 - val_accuracy: 0.7812\n",
            "Epoch 1242/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4007 - accuracy: 0.8021 - val_loss: 0.5341 - val_accuracy: 0.7812\n",
            "Epoch 1243/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8021 - val_loss: 0.5342 - val_accuracy: 0.7812\n",
            "Epoch 1244/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4008 - accuracy: 0.8021 - val_loss: 0.5343 - val_accuracy: 0.7812\n",
            "Epoch 1245/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4005 - accuracy: 0.8021 - val_loss: 0.5339 - val_accuracy: 0.7760\n",
            "Epoch 1246/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4005 - accuracy: 0.8021 - val_loss: 0.5339 - val_accuracy: 0.7812\n",
            "Epoch 1247/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4007 - accuracy: 0.8021 - val_loss: 0.5339 - val_accuracy: 0.7812\n",
            "Epoch 1248/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4004 - accuracy: 0.8003 - val_loss: 0.5343 - val_accuracy: 0.7812\n",
            "Epoch 1249/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4008 - accuracy: 0.8003 - val_loss: 0.5345 - val_accuracy: 0.7760\n",
            "Epoch 1250/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8021 - val_loss: 0.5341 - val_accuracy: 0.7760\n",
            "Epoch 1251/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4006 - accuracy: 0.8021 - val_loss: 0.5339 - val_accuracy: 0.7760\n",
            "Epoch 1252/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4006 - accuracy: 0.8021 - val_loss: 0.5339 - val_accuracy: 0.7760\n",
            "Epoch 1253/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4005 - accuracy: 0.8003 - val_loss: 0.5340 - val_accuracy: 0.7760\n",
            "Epoch 1254/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4004 - accuracy: 0.8003 - val_loss: 0.5340 - val_accuracy: 0.7812\n",
            "Epoch 1255/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4003 - accuracy: 0.8038 - val_loss: 0.5343 - val_accuracy: 0.7812\n",
            "Epoch 1256/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4004 - accuracy: 0.8021 - val_loss: 0.5342 - val_accuracy: 0.7812\n",
            "Epoch 1257/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4002 - accuracy: 0.8003 - val_loss: 0.5344 - val_accuracy: 0.7812\n",
            "Epoch 1258/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4006 - accuracy: 0.8003 - val_loss: 0.5341 - val_accuracy: 0.7812\n",
            "Epoch 1259/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4004 - accuracy: 0.8003 - val_loss: 0.5342 - val_accuracy: 0.7812\n",
            "Epoch 1260/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4004 - accuracy: 0.8003 - val_loss: 0.5346 - val_accuracy: 0.7812\n",
            "Epoch 1261/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4004 - accuracy: 0.8021 - val_loss: 0.5352 - val_accuracy: 0.7812\n",
            "Epoch 1262/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.8021 - val_loss: 0.5347 - val_accuracy: 0.7812\n",
            "Epoch 1263/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.8003 - val_loss: 0.5343 - val_accuracy: 0.7760\n",
            "Epoch 1264/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4003 - accuracy: 0.8021 - val_loss: 0.5342 - val_accuracy: 0.7760\n",
            "Epoch 1265/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4002 - accuracy: 0.8021 - val_loss: 0.5341 - val_accuracy: 0.7760\n",
            "Epoch 1266/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4003 - accuracy: 0.8021 - val_loss: 0.5338 - val_accuracy: 0.7760\n",
            "Epoch 1267/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4002 - accuracy: 0.8003 - val_loss: 0.5338 - val_accuracy: 0.7760\n",
            "Epoch 1268/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4002 - accuracy: 0.8021 - val_loss: 0.5336 - val_accuracy: 0.7760\n",
            "Epoch 1269/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4003 - accuracy: 0.8021 - val_loss: 0.5337 - val_accuracy: 0.7760\n",
            "Epoch 1270/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4002 - accuracy: 0.8003 - val_loss: 0.5339 - val_accuracy: 0.7760\n",
            "Epoch 1271/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.8038 - val_loss: 0.5343 - val_accuracy: 0.7812\n",
            "Epoch 1272/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4003 - accuracy: 0.8003 - val_loss: 0.5343 - val_accuracy: 0.7812\n",
            "Epoch 1273/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8021 - val_loss: 0.5341 - val_accuracy: 0.7760\n",
            "Epoch 1274/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4002 - accuracy: 0.8003 - val_loss: 0.5341 - val_accuracy: 0.7708\n",
            "Epoch 1275/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4002 - accuracy: 0.8021 - val_loss: 0.5342 - val_accuracy: 0.7708\n",
            "Epoch 1276/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8003 - val_loss: 0.5343 - val_accuracy: 0.7708\n",
            "Epoch 1277/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8003 - val_loss: 0.5343 - val_accuracy: 0.7708\n",
            "Epoch 1278/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4000 - accuracy: 0.8003 - val_loss: 0.5342 - val_accuracy: 0.7708\n",
            "Epoch 1279/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3999 - accuracy: 0.8003 - val_loss: 0.5343 - val_accuracy: 0.7708\n",
            "Epoch 1280/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4001 - accuracy: 0.8021 - val_loss: 0.5342 - val_accuracy: 0.7708\n",
            "Epoch 1281/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4000 - accuracy: 0.8038 - val_loss: 0.5344 - val_accuracy: 0.7812\n",
            "Epoch 1282/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4002 - accuracy: 0.8003 - val_loss: 0.5350 - val_accuracy: 0.7812\n",
            "Epoch 1283/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4000 - accuracy: 0.7986 - val_loss: 0.5346 - val_accuracy: 0.7760\n",
            "Epoch 1284/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3998 - accuracy: 0.8003 - val_loss: 0.5346 - val_accuracy: 0.7760\n",
            "Epoch 1285/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3998 - accuracy: 0.8021 - val_loss: 0.5351 - val_accuracy: 0.7812\n",
            "Epoch 1286/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3999 - accuracy: 0.8003 - val_loss: 0.5351 - val_accuracy: 0.7812\n",
            "Epoch 1287/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3998 - accuracy: 0.8003 - val_loss: 0.5351 - val_accuracy: 0.7708\n",
            "Epoch 1288/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8021 - val_loss: 0.5347 - val_accuracy: 0.7708\n",
            "Epoch 1289/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8021 - val_loss: 0.5345 - val_accuracy: 0.7708\n",
            "Epoch 1290/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8003 - val_loss: 0.5347 - val_accuracy: 0.7708\n",
            "Epoch 1291/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3998 - accuracy: 0.8038 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 1292/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3997 - accuracy: 0.8003 - val_loss: 0.5347 - val_accuracy: 0.7708\n",
            "Epoch 1293/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3997 - accuracy: 0.8003 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 1294/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3998 - accuracy: 0.8003 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 1295/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3997 - accuracy: 0.7986 - val_loss: 0.5347 - val_accuracy: 0.7708\n",
            "Epoch 1296/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3999 - accuracy: 0.8038 - val_loss: 0.5349 - val_accuracy: 0.7760\n",
            "Epoch 1297/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3995 - accuracy: 0.8021 - val_loss: 0.5345 - val_accuracy: 0.7708\n",
            "Epoch 1298/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3999 - accuracy: 0.8021 - val_loss: 0.5342 - val_accuracy: 0.7708\n",
            "Epoch 1299/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3995 - accuracy: 0.8038 - val_loss: 0.5340 - val_accuracy: 0.7708\n",
            "Epoch 1300/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3997 - accuracy: 0.8003 - val_loss: 0.5343 - val_accuracy: 0.7708\n",
            "Epoch 1301/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3995 - accuracy: 0.8003 - val_loss: 0.5343 - val_accuracy: 0.7708\n",
            "Epoch 1302/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3997 - accuracy: 0.8021 - val_loss: 0.5341 - val_accuracy: 0.7708\n",
            "Epoch 1303/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3995 - accuracy: 0.8038 - val_loss: 0.5344 - val_accuracy: 0.7708\n",
            "Epoch 1304/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3996 - accuracy: 0.8003 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 1305/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3996 - accuracy: 0.8021 - val_loss: 0.5345 - val_accuracy: 0.7708\n",
            "Epoch 1306/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3996 - accuracy: 0.8003 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 1307/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3995 - accuracy: 0.8003 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 1308/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3995 - accuracy: 0.8021 - val_loss: 0.5344 - val_accuracy: 0.7708\n",
            "Epoch 1309/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3995 - accuracy: 0.8021 - val_loss: 0.5343 - val_accuracy: 0.7708\n",
            "Epoch 1310/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3996 - accuracy: 0.8021 - val_loss: 0.5350 - val_accuracy: 0.7708\n",
            "Epoch 1311/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3995 - accuracy: 0.8021 - val_loss: 0.5350 - val_accuracy: 0.7708\n",
            "Epoch 1312/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3996 - accuracy: 0.8021 - val_loss: 0.5349 - val_accuracy: 0.7708\n",
            "Epoch 1313/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3995 - accuracy: 0.8021 - val_loss: 0.5345 - val_accuracy: 0.7708\n",
            "Epoch 1314/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3995 - accuracy: 0.8021 - val_loss: 0.5347 - val_accuracy: 0.7708\n",
            "Epoch 1315/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3993 - accuracy: 0.8003 - val_loss: 0.5343 - val_accuracy: 0.7708\n",
            "Epoch 1316/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3993 - accuracy: 0.8003 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 1317/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3993 - accuracy: 0.8038 - val_loss: 0.5350 - val_accuracy: 0.7708\n",
            "Epoch 1318/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3995 - accuracy: 0.8003 - val_loss: 0.5351 - val_accuracy: 0.7708\n",
            "Epoch 1319/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3993 - accuracy: 0.8021 - val_loss: 0.5348 - val_accuracy: 0.7708\n",
            "Epoch 1320/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3994 - accuracy: 0.8021 - val_loss: 0.5350 - val_accuracy: 0.7708\n",
            "Epoch 1321/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3991 - accuracy: 0.8021 - val_loss: 0.5348 - val_accuracy: 0.7708\n",
            "Epoch 1322/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3994 - accuracy: 0.8021 - val_loss: 0.5349 - val_accuracy: 0.7708\n",
            "Epoch 1323/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3994 - accuracy: 0.8021 - val_loss: 0.5350 - val_accuracy: 0.7708\n",
            "Epoch 1324/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8038 - val_loss: 0.5351 - val_accuracy: 0.7708\n",
            "Epoch 1325/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8056 - val_loss: 0.5352 - val_accuracy: 0.7708\n",
            "Epoch 1326/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3993 - accuracy: 0.8003 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
            "Epoch 1327/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3993 - accuracy: 0.8038 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
            "Epoch 1328/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3994 - accuracy: 0.8021 - val_loss: 0.5354 - val_accuracy: 0.7708\n",
            "Epoch 1329/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3990 - accuracy: 0.8038 - val_loss: 0.5352 - val_accuracy: 0.7708\n",
            "Epoch 1330/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3990 - accuracy: 0.8021 - val_loss: 0.5352 - val_accuracy: 0.7708\n",
            "Epoch 1331/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3993 - accuracy: 0.8021 - val_loss: 0.5355 - val_accuracy: 0.7708\n",
            "Epoch 1332/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3988 - accuracy: 0.8021 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
            "Epoch 1333/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8021 - val_loss: 0.5352 - val_accuracy: 0.7656\n",
            "Epoch 1334/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8021 - val_loss: 0.5352 - val_accuracy: 0.7656\n",
            "Epoch 1335/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3990 - accuracy: 0.8021 - val_loss: 0.5354 - val_accuracy: 0.7656\n",
            "Epoch 1336/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8073 - val_loss: 0.5350 - val_accuracy: 0.7708\n",
            "Epoch 1337/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3992 - accuracy: 0.8021 - val_loss: 0.5347 - val_accuracy: 0.7708\n",
            "Epoch 1338/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3989 - accuracy: 0.8021 - val_loss: 0.5349 - val_accuracy: 0.7708\n",
            "Epoch 1339/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3989 - accuracy: 0.8038 - val_loss: 0.5352 - val_accuracy: 0.7708\n",
            "Epoch 1340/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3989 - accuracy: 0.8021 - val_loss: 0.5349 - val_accuracy: 0.7708\n",
            "Epoch 1341/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8056 - val_loss: 0.5348 - val_accuracy: 0.7708\n",
            "Epoch 1342/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8038 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
            "Epoch 1343/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8056 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
            "Epoch 1344/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8021 - val_loss: 0.5356 - val_accuracy: 0.7708\n",
            "Epoch 1345/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3987 - accuracy: 0.8056 - val_loss: 0.5352 - val_accuracy: 0.7708\n",
            "Epoch 1346/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8038 - val_loss: 0.5357 - val_accuracy: 0.7708\n",
            "Epoch 1347/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8038 - val_loss: 0.5356 - val_accuracy: 0.7708\n",
            "Epoch 1348/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8038 - val_loss: 0.5359 - val_accuracy: 0.7656\n",
            "Epoch 1349/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3989 - accuracy: 0.8038 - val_loss: 0.5358 - val_accuracy: 0.7656\n",
            "Epoch 1350/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3988 - accuracy: 0.8038 - val_loss: 0.5356 - val_accuracy: 0.7708\n",
            "Epoch 1351/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3986 - accuracy: 0.8038 - val_loss: 0.5357 - val_accuracy: 0.7708\n",
            "Epoch 1352/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3988 - accuracy: 0.8038 - val_loss: 0.5356 - val_accuracy: 0.7708\n",
            "Epoch 1353/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3986 - accuracy: 0.8056 - val_loss: 0.5359 - val_accuracy: 0.7708\n",
            "Epoch 1354/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8021 - val_loss: 0.5357 - val_accuracy: 0.7708\n",
            "Epoch 1355/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3986 - accuracy: 0.8056 - val_loss: 0.5355 - val_accuracy: 0.7708\n",
            "Epoch 1356/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8073 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
            "Epoch 1357/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3988 - accuracy: 0.8056 - val_loss: 0.5356 - val_accuracy: 0.7708\n",
            "Epoch 1358/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3986 - accuracy: 0.8038 - val_loss: 0.5355 - val_accuracy: 0.7708\n",
            "Epoch 1359/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3989 - accuracy: 0.8073 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
            "Epoch 1360/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3986 - accuracy: 0.8073 - val_loss: 0.5357 - val_accuracy: 0.7708\n",
            "Epoch 1361/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3985 - accuracy: 0.8038 - val_loss: 0.5354 - val_accuracy: 0.7708\n",
            "Epoch 1362/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3985 - accuracy: 0.8056 - val_loss: 0.5355 - val_accuracy: 0.7708\n",
            "Epoch 1363/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3986 - accuracy: 0.8038 - val_loss: 0.5357 - val_accuracy: 0.7656\n",
            "Epoch 1364/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3987 - accuracy: 0.8056 - val_loss: 0.5351 - val_accuracy: 0.7708\n",
            "Epoch 1365/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8056 - val_loss: 0.5350 - val_accuracy: 0.7708\n",
            "Epoch 1366/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8056 - val_loss: 0.5352 - val_accuracy: 0.7708\n",
            "Epoch 1367/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8073 - val_loss: 0.5354 - val_accuracy: 0.7708\n",
            "Epoch 1368/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3987 - accuracy: 0.8038 - val_loss: 0.5354 - val_accuracy: 0.7708\n",
            "Epoch 1369/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3986 - accuracy: 0.8038 - val_loss: 0.5352 - val_accuracy: 0.7708\n",
            "Epoch 1370/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3984 - accuracy: 0.8056 - val_loss: 0.5354 - val_accuracy: 0.7708\n",
            "Epoch 1371/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.8056 - val_loss: 0.5354 - val_accuracy: 0.7708\n",
            "Epoch 1372/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3982 - accuracy: 0.8056 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
            "Epoch 1373/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3984 - accuracy: 0.8021 - val_loss: 0.5352 - val_accuracy: 0.7708\n",
            "Epoch 1374/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.8073 - val_loss: 0.5352 - val_accuracy: 0.7708\n",
            "Epoch 1375/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.8090 - val_loss: 0.5350 - val_accuracy: 0.7708\n",
            "Epoch 1376/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8056 - val_loss: 0.5351 - val_accuracy: 0.7708\n",
            "Epoch 1377/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3984 - accuracy: 0.8038 - val_loss: 0.5350 - val_accuracy: 0.7708\n",
            "Epoch 1378/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3982 - accuracy: 0.8056 - val_loss: 0.5354 - val_accuracy: 0.7708\n",
            "Epoch 1379/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8056 - val_loss: 0.5351 - val_accuracy: 0.7708\n",
            "Epoch 1380/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3982 - accuracy: 0.8056 - val_loss: 0.5352 - val_accuracy: 0.7708\n",
            "Epoch 1381/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3981 - accuracy: 0.8038 - val_loss: 0.5354 - val_accuracy: 0.7708\n",
            "Epoch 1382/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3982 - accuracy: 0.8056 - val_loss: 0.5351 - val_accuracy: 0.7708\n",
            "Epoch 1383/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3981 - accuracy: 0.8073 - val_loss: 0.5355 - val_accuracy: 0.7708\n",
            "Epoch 1384/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3982 - accuracy: 0.8038 - val_loss: 0.5351 - val_accuracy: 0.7708\n",
            "Epoch 1385/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8056 - val_loss: 0.5352 - val_accuracy: 0.7708\n",
            "Epoch 1386/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3982 - accuracy: 0.8073 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
            "Epoch 1387/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3982 - accuracy: 0.8056 - val_loss: 0.5356 - val_accuracy: 0.7708\n",
            "Epoch 1388/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8090 - val_loss: 0.5356 - val_accuracy: 0.7708\n",
            "Epoch 1389/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8073 - val_loss: 0.5354 - val_accuracy: 0.7708\n",
            "Epoch 1390/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3980 - accuracy: 0.8056 - val_loss: 0.5355 - val_accuracy: 0.7708\n",
            "Epoch 1391/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3981 - accuracy: 0.8073 - val_loss: 0.5357 - val_accuracy: 0.7708\n",
            "Epoch 1392/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3981 - accuracy: 0.8108 - val_loss: 0.5355 - val_accuracy: 0.7708\n",
            "Epoch 1393/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8056 - val_loss: 0.5358 - val_accuracy: 0.7708\n",
            "Epoch 1394/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3977 - accuracy: 0.8090 - val_loss: 0.5361 - val_accuracy: 0.7708\n",
            "Epoch 1395/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3979 - accuracy: 0.8073 - val_loss: 0.5355 - val_accuracy: 0.7708\n",
            "Epoch 1396/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3980 - accuracy: 0.8073 - val_loss: 0.5357 - val_accuracy: 0.7708\n",
            "Epoch 1397/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8056 - val_loss: 0.5355 - val_accuracy: 0.7708\n",
            "Epoch 1398/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3977 - accuracy: 0.8073 - val_loss: 0.5362 - val_accuracy: 0.7708\n",
            "Epoch 1399/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3978 - accuracy: 0.8056 - val_loss: 0.5358 - val_accuracy: 0.7708\n",
            "Epoch 1400/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8073 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
            "Epoch 1401/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3978 - accuracy: 0.8073 - val_loss: 0.5355 - val_accuracy: 0.7708\n",
            "Epoch 1402/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3977 - accuracy: 0.8108 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
            "Epoch 1403/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3975 - accuracy: 0.8108 - val_loss: 0.5356 - val_accuracy: 0.7708\n",
            "Epoch 1404/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3977 - accuracy: 0.8090 - val_loss: 0.5357 - val_accuracy: 0.7708\n",
            "Epoch 1405/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3977 - accuracy: 0.8108 - val_loss: 0.5359 - val_accuracy: 0.7708\n",
            "Epoch 1406/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3977 - accuracy: 0.8090 - val_loss: 0.5361 - val_accuracy: 0.7656\n",
            "Epoch 1407/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3976 - accuracy: 0.8108 - val_loss: 0.5360 - val_accuracy: 0.7708\n",
            "Epoch 1408/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3977 - accuracy: 0.8090 - val_loss: 0.5358 - val_accuracy: 0.7708\n",
            "Epoch 1409/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3978 - accuracy: 0.8056 - val_loss: 0.5355 - val_accuracy: 0.7708\n",
            "Epoch 1410/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3976 - accuracy: 0.8056 - val_loss: 0.5356 - val_accuracy: 0.7708\n",
            "Epoch 1411/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3973 - accuracy: 0.8090 - val_loss: 0.5357 - val_accuracy: 0.7708\n",
            "Epoch 1412/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3975 - accuracy: 0.8090 - val_loss: 0.5362 - val_accuracy: 0.7708\n",
            "Epoch 1413/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3978 - accuracy: 0.8056 - val_loss: 0.5363 - val_accuracy: 0.7708\n",
            "Epoch 1414/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3976 - accuracy: 0.8108 - val_loss: 0.5365 - val_accuracy: 0.7708\n",
            "Epoch 1415/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8090 - val_loss: 0.5368 - val_accuracy: 0.7708\n",
            "Epoch 1416/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3975 - accuracy: 0.8038 - val_loss: 0.5367 - val_accuracy: 0.7656\n",
            "Epoch 1417/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3974 - accuracy: 0.8125 - val_loss: 0.5365 - val_accuracy: 0.7708\n",
            "Epoch 1418/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3973 - accuracy: 0.8125 - val_loss: 0.5366 - val_accuracy: 0.7656\n",
            "Epoch 1419/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3972 - accuracy: 0.8125 - val_loss: 0.5364 - val_accuracy: 0.7708\n",
            "Epoch 1420/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3972 - accuracy: 0.8125 - val_loss: 0.5361 - val_accuracy: 0.7708\n",
            "Epoch 1421/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3971 - accuracy: 0.8090 - val_loss: 0.5364 - val_accuracy: 0.7656\n",
            "Epoch 1422/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3972 - accuracy: 0.8108 - val_loss: 0.5365 - val_accuracy: 0.7656\n",
            "Epoch 1423/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3976 - accuracy: 0.8108 - val_loss: 0.5364 - val_accuracy: 0.7708\n",
            "Epoch 1424/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3973 - accuracy: 0.8125 - val_loss: 0.5364 - val_accuracy: 0.7708\n",
            "Epoch 1425/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3972 - accuracy: 0.8090 - val_loss: 0.5366 - val_accuracy: 0.7656\n",
            "Epoch 1426/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3972 - accuracy: 0.8108 - val_loss: 0.5365 - val_accuracy: 0.7656\n",
            "Epoch 1427/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3971 - accuracy: 0.8108 - val_loss: 0.5367 - val_accuracy: 0.7656\n",
            "Epoch 1428/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8108 - val_loss: 0.5362 - val_accuracy: 0.7656\n",
            "Epoch 1429/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3973 - accuracy: 0.8108 - val_loss: 0.5360 - val_accuracy: 0.7656\n",
            "Epoch 1430/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3970 - accuracy: 0.8108 - val_loss: 0.5364 - val_accuracy: 0.7656\n",
            "Epoch 1431/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3971 - accuracy: 0.8108 - val_loss: 0.5364 - val_accuracy: 0.7656\n",
            "Epoch 1432/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8108 - val_loss: 0.5363 - val_accuracy: 0.7604\n",
            "Epoch 1433/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8090 - val_loss: 0.5363 - val_accuracy: 0.7656\n",
            "Epoch 1434/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3972 - accuracy: 0.8090 - val_loss: 0.5364 - val_accuracy: 0.7604\n",
            "Epoch 1435/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3970 - accuracy: 0.8090 - val_loss: 0.5363 - val_accuracy: 0.7604\n",
            "Epoch 1436/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3968 - accuracy: 0.8108 - val_loss: 0.5364 - val_accuracy: 0.7604\n",
            "Epoch 1437/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3968 - accuracy: 0.8125 - val_loss: 0.5361 - val_accuracy: 0.7656\n",
            "Epoch 1438/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3971 - accuracy: 0.8090 - val_loss: 0.5365 - val_accuracy: 0.7656\n",
            "Epoch 1439/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8108 - val_loss: 0.5365 - val_accuracy: 0.7656\n",
            "Epoch 1440/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3970 - accuracy: 0.8090 - val_loss: 0.5365 - val_accuracy: 0.7656\n",
            "Epoch 1441/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3967 - accuracy: 0.8108 - val_loss: 0.5364 - val_accuracy: 0.7656\n",
            "Epoch 1442/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3970 - accuracy: 0.8125 - val_loss: 0.5362 - val_accuracy: 0.7656\n",
            "Epoch 1443/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3967 - accuracy: 0.8108 - val_loss: 0.5363 - val_accuracy: 0.7656\n",
            "Epoch 1444/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3970 - accuracy: 0.8090 - val_loss: 0.5363 - val_accuracy: 0.7656\n",
            "Epoch 1445/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8108 - val_loss: 0.5361 - val_accuracy: 0.7656\n",
            "Epoch 1446/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8108 - val_loss: 0.5366 - val_accuracy: 0.7656\n",
            "Epoch 1447/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3968 - accuracy: 0.8090 - val_loss: 0.5363 - val_accuracy: 0.7604\n",
            "Epoch 1448/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3964 - accuracy: 0.8090 - val_loss: 0.5362 - val_accuracy: 0.7656\n",
            "Epoch 1449/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3966 - accuracy: 0.8090 - val_loss: 0.5363 - val_accuracy: 0.7656\n",
            "Epoch 1450/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3967 - accuracy: 0.8108 - val_loss: 0.5365 - val_accuracy: 0.7656\n",
            "Epoch 1451/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3965 - accuracy: 0.8108 - val_loss: 0.5368 - val_accuracy: 0.7656\n",
            "Epoch 1452/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3966 - accuracy: 0.8108 - val_loss: 0.5366 - val_accuracy: 0.7604\n",
            "Epoch 1453/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3964 - accuracy: 0.8108 - val_loss: 0.5363 - val_accuracy: 0.7656\n",
            "Epoch 1454/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3966 - accuracy: 0.8108 - val_loss: 0.5365 - val_accuracy: 0.7656\n",
            "Epoch 1455/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3966 - accuracy: 0.8108 - val_loss: 0.5366 - val_accuracy: 0.7656\n",
            "Epoch 1456/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3964 - accuracy: 0.8142 - val_loss: 0.5367 - val_accuracy: 0.7656\n",
            "Epoch 1457/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3966 - accuracy: 0.8108 - val_loss: 0.5369 - val_accuracy: 0.7656\n",
            "Epoch 1458/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3966 - accuracy: 0.8090 - val_loss: 0.5369 - val_accuracy: 0.7656\n",
            "Epoch 1459/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3963 - accuracy: 0.8125 - val_loss: 0.5372 - val_accuracy: 0.7656\n",
            "Epoch 1460/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3964 - accuracy: 0.8125 - val_loss: 0.5371 - val_accuracy: 0.7656\n",
            "Epoch 1461/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3964 - accuracy: 0.8090 - val_loss: 0.5369 - val_accuracy: 0.7656\n",
            "Epoch 1462/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3965 - accuracy: 0.8073 - val_loss: 0.5372 - val_accuracy: 0.7604\n",
            "Epoch 1463/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3964 - accuracy: 0.8108 - val_loss: 0.5366 - val_accuracy: 0.7604\n",
            "Epoch 1464/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3960 - accuracy: 0.8108 - val_loss: 0.5363 - val_accuracy: 0.7604\n",
            "Epoch 1465/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3967 - accuracy: 0.8125 - val_loss: 0.5362 - val_accuracy: 0.7604\n",
            "Epoch 1466/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3964 - accuracy: 0.8125 - val_loss: 0.5359 - val_accuracy: 0.7604\n",
            "Epoch 1467/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3963 - accuracy: 0.8125 - val_loss: 0.5360 - val_accuracy: 0.7604\n",
            "Epoch 1468/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3960 - accuracy: 0.8125 - val_loss: 0.5361 - val_accuracy: 0.7604\n",
            "Epoch 1469/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3961 - accuracy: 0.8142 - val_loss: 0.5361 - val_accuracy: 0.7604\n",
            "Epoch 1470/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8108 - val_loss: 0.5363 - val_accuracy: 0.7604\n",
            "Epoch 1471/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3960 - accuracy: 0.8108 - val_loss: 0.5359 - val_accuracy: 0.7552\n",
            "Epoch 1472/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3966 - accuracy: 0.8108 - val_loss: 0.5357 - val_accuracy: 0.7604\n",
            "Epoch 1473/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3961 - accuracy: 0.8125 - val_loss: 0.5355 - val_accuracy: 0.7604\n",
            "Epoch 1474/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.8142 - val_loss: 0.5355 - val_accuracy: 0.7552\n",
            "Epoch 1475/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3963 - accuracy: 0.8108 - val_loss: 0.5358 - val_accuracy: 0.7552\n",
            "Epoch 1476/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3963 - accuracy: 0.8108 - val_loss: 0.5357 - val_accuracy: 0.7604\n",
            "Epoch 1477/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8108 - val_loss: 0.5357 - val_accuracy: 0.7552\n",
            "Epoch 1478/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3960 - accuracy: 0.8125 - val_loss: 0.5358 - val_accuracy: 0.7552\n",
            "Epoch 1479/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3963 - accuracy: 0.8108 - val_loss: 0.5359 - val_accuracy: 0.7552\n",
            "Epoch 1480/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3959 - accuracy: 0.8108 - val_loss: 0.5358 - val_accuracy: 0.7552\n",
            "Epoch 1481/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8108 - val_loss: 0.5358 - val_accuracy: 0.7552\n",
            "Epoch 1482/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3961 - accuracy: 0.8125 - val_loss: 0.5356 - val_accuracy: 0.7552\n",
            "Epoch 1483/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3959 - accuracy: 0.8125 - val_loss: 0.5361 - val_accuracy: 0.7552\n",
            "Epoch 1484/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8142 - val_loss: 0.5358 - val_accuracy: 0.7552\n",
            "Epoch 1485/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8108 - val_loss: 0.5358 - val_accuracy: 0.7552\n",
            "Epoch 1486/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3959 - accuracy: 0.8108 - val_loss: 0.5363 - val_accuracy: 0.7552\n",
            "Epoch 1487/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8090 - val_loss: 0.5360 - val_accuracy: 0.7552\n",
            "Epoch 1488/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3958 - accuracy: 0.8108 - val_loss: 0.5360 - val_accuracy: 0.7552\n",
            "Epoch 1489/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8125 - val_loss: 0.5362 - val_accuracy: 0.7552\n",
            "Epoch 1490/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8090 - val_loss: 0.5360 - val_accuracy: 0.7552\n",
            "Epoch 1491/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8108 - val_loss: 0.5361 - val_accuracy: 0.7552\n",
            "Epoch 1492/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8090 - val_loss: 0.5361 - val_accuracy: 0.7552\n",
            "Epoch 1493/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3959 - accuracy: 0.8108 - val_loss: 0.5366 - val_accuracy: 0.7552\n",
            "Epoch 1494/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3958 - accuracy: 0.8125 - val_loss: 0.5367 - val_accuracy: 0.7552\n",
            "Epoch 1495/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8125 - val_loss: 0.5361 - val_accuracy: 0.7552\n",
            "Epoch 1496/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3955 - accuracy: 0.8125 - val_loss: 0.5363 - val_accuracy: 0.7552\n",
            "Epoch 1497/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3959 - accuracy: 0.8108 - val_loss: 0.5365 - val_accuracy: 0.7552\n",
            "Epoch 1498/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3957 - accuracy: 0.8108 - val_loss: 0.5358 - val_accuracy: 0.7552\n",
            "Epoch 1499/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3959 - accuracy: 0.8090 - val_loss: 0.5361 - val_accuracy: 0.7552\n",
            "Epoch 1500/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8108 - val_loss: 0.5360 - val_accuracy: 0.7552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#graph the trajectory\n",
        "\n",
        "run_hist_2.history.keys()\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_2.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_2.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "KZZ-D106h_ZK",
        "outputId": "3bcd02aa-73c1-4aa4-8837-4a50ab11fa68"
      },
      "id": "KZZ-D106h_ZK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x78fe88a8d600>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "- In the given figure we can see that the validation_loss and loss decreases with each passing epoch. However, further analyzing the graph we can notice that the validation_loss slowly starts to increase as the epoch continues, this could signify that the model is too complex for the number of data available and the model is memorizing the training data to well to the point that it does not perform well on unseen data."
      ],
      "metadata": {
        "id": "T19_vfwx_jkT"
      },
      "id": "T19_vfwx_jkT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Alternative Network: Using 2 Hidden Layers and 2 Nodes in the Output Layer"
      ],
      "metadata": {
        "id": "6I4lGVP946vl"
      },
      "id": "6I4lGVP946vl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Network Summary\n",
        "\n",
        "- In this alternative network, we've split the output to two categories using the get dummies function in pandas. We've also changed the activation function of the output layer to softmax, as it is usually used for mutually exclusive categories where an instance can only possess one class at a time."
      ],
      "metadata": {
        "id": "zQ1oayIKAlqJ"
      },
      "id": "zQ1oayIKAlqJ"
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding column names to the dataset.\n",
        "\n",
        "databaseDiabetes = pd.read_csv('pima-indians-diabetes.csv', header=None)\n",
        "databaseDiabetes.rename(columns = {0: 'Pregnancies', 1: 'Glucose', 2: 'BloodPressure', 3: 'SkinThickness', 4: 'Insulin', 5: 'BMI', 6: 'DiabetesPedigree', 7: 'Age', 8: 'Outcome'},\n",
        "                        inplace = True)\n",
        "databaseDiabetes.to_csv('diabetesFrame.csv', index = False)\n",
        "\n",
        "#Verify changes\n",
        "\n",
        "finalDatabase = pd.read_csv('diabetesFrame.csv')\n",
        "finalDatabase.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iUIjhvwWCETv",
        "outputId": "ea68c347-662c-4d00-9b24-02545e175896"
      },
      "id": "iUIjhvwWCETv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "\n",
              "   DiabetesPedigree  Age  Outcome  \n",
              "0             0.627   50        1  \n",
              "1             0.351   31        0  \n",
              "2             0.672   32        1  \n",
              "3             0.167   21        0  \n",
              "4             2.288   33        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fdb41c7b-e638-4dbe-b682-0c7963aaa77b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigree</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fdb41c7b-e638-4dbe-b682-0c7963aaa77b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fdb41c7b-e638-4dbe-b682-0c7963aaa77b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fdb41c7b-e638-4dbe-b682-0c7963aaa77b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-70484ee5-93e1-47b1-a2ef-9b1bfc4fd92c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-70484ee5-93e1-47b1-a2ef-9b1bfc4fd92c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-70484ee5-93e1-47b1-a2ef-9b1bfc4fd92c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "finalDatabase",
              "summary": "{\n  \"name\": \"finalDatabase\",\n  \"rows\": 768,\n  \"fields\": [\n    {\n      \"column\": \"Pregnancies\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 17,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          6,\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Glucose\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31,\n        \"min\": 0,\n        \"max\": 199,\n        \"num_unique_values\": 136,\n        \"samples\": [\n          151,\n          101,\n          112\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BloodPressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19,\n        \"min\": 0,\n        \"max\": 122,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          86,\n          46,\n          85\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SkinThickness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 0,\n        \"max\": 99,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          7,\n          12,\n          48\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Insulin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 115,\n        \"min\": 0,\n        \"max\": 846,\n        \"num_unique_values\": 186,\n        \"samples\": [\n          52,\n          41,\n          183\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BMI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.884160320375446,\n        \"min\": 0.0,\n        \"max\": 67.1,\n        \"num_unique_values\": 248,\n        \"samples\": [\n          19.9,\n          31.0,\n          38.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DiabetesPedigree\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3313285950127749,\n        \"min\": 0.078,\n        \"max\": 2.42,\n        \"num_unique_values\": 517,\n        \"samples\": [\n          1.731,\n          0.426,\n          0.138\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 21,\n        \"max\": 81,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          60,\n          47,\n          72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Outcome\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting the output to positivea and negative classes\n",
        "\n",
        "y2 = pd.get_dummies(finalDatabase['Outcome'].map({1: 'Positive', 0: 'Negative'}))\n",
        "finalDatabase = pd.concat([finalDatabase, y2], axis=1)\n",
        "finalDatabase = finalDatabase.drop('Outcome', axis=1)\n"
      ],
      "metadata": {
        "id": "erpAHwjoFjpe"
      },
      "id": "erpAHwjoFjpe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finalDatabase.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "EoQSmvOiJNLv",
        "outputId": "315c3be0-b084-48fe-ad2b-0fdd53a32ddb"
      },
      "id": "EoQSmvOiJNLv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "\n",
              "   DiabetesPedigree  Age  Negative  Positive  \n",
              "0             0.627   50         0         1  \n",
              "1             0.351   31         1         0  \n",
              "2             0.672   32         0         1  \n",
              "3             0.167   21         1         0  \n",
              "4             2.288   33         0         1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f458b411-e4d3-44d2-9279-3c576fdfde46\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigree</th>\n",
              "      <th>Age</th>\n",
              "      <th>Negative</th>\n",
              "      <th>Positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f458b411-e4d3-44d2-9279-3c576fdfde46')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f458b411-e4d3-44d2-9279-3c576fdfde46 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f458b411-e4d3-44d2-9279-3c576fdfde46');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-084b73eb-4b97-4f8a-aba3-dcaa254848a2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-084b73eb-4b97-4f8a-aba3-dcaa254848a2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-084b73eb-4b97-4f8a-aba3-dcaa254848a2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "finalDatabase",
              "summary": "{\n  \"name\": \"finalDatabase\",\n  \"rows\": 768,\n  \"fields\": [\n    {\n      \"column\": \"Pregnancies\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 17,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          6,\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Glucose\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31,\n        \"min\": 0,\n        \"max\": 199,\n        \"num_unique_values\": 136,\n        \"samples\": [\n          151,\n          101,\n          112\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BloodPressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19,\n        \"min\": 0,\n        \"max\": 122,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          86,\n          46,\n          85\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SkinThickness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 0,\n        \"max\": 99,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          7,\n          12,\n          48\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Insulin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 115,\n        \"min\": 0,\n        \"max\": 846,\n        \"num_unique_values\": 186,\n        \"samples\": [\n          52,\n          41,\n          183\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BMI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.884160320375446,\n        \"min\": 0.0,\n        \"max\": 67.1,\n        \"num_unique_values\": 248,\n        \"samples\": [\n          19.9,\n          31.0,\n          38.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DiabetesPedigree\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3313285950127749,\n        \"min\": 0.078,\n        \"max\": 2.42,\n        \"num_unique_values\": 517,\n        \"samples\": [\n          1.731,\n          0.426,\n          0.138\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 21,\n        \"max\": 81,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          60,\n          47,\n          72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Negative\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Positive\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting the dataset into test and train\n",
        "\n",
        "columnsdata = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI',\n",
        "               'DiabetesPedigree', 'Age']\n",
        "x2 = finalDatabase[list(columnsdata)].values\n",
        "\n",
        "x2_train, x2_test, y2_train, y2_test = train_test_split(x2,y2, test_size = 0.3)"
      ],
      "metadata": {
        "id": "_ZoZoIKSJls6"
      },
      "id": "_ZoZoIKSJls6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#use different learning rates and epochs\n",
        "\n",
        "model3 = Sequential()\n",
        "model4 = Sequential()\n",
        "model5 = Sequential()\n",
        "\n",
        "#alternative epoch model (200 epochs)\n",
        "\n",
        "model3.add(Dense(6, activation = 'relu'))\n",
        "model3.add(Dense(3, activation = 'relu'))\n",
        "model3.add(Dense(2, activation = 'softmax'))\n",
        "\n",
        "#for 500 epochs\n",
        "\n",
        "model4.add(Dense(6, activation = 'relu'))\n",
        "model4.add(Dense(3, activation = 'relu'))\n",
        "model4.add(Dense(2, activation = 'softmax'))\n",
        "\n",
        "#for 1500 epochs\n",
        "\n",
        "model5.add(Dense(6, activation = 'relu'))\n",
        "model5.add(Dense(3, activation = 'relu'))\n",
        "model5.add(Dense(2, activation = 'softmax'))\n",
        "\n",
        "normalizer = StandardScaler()\n",
        "x2_train_norm = normalizer.fit_transform(x2_train)\n",
        "x2_test_norm = normalizer.transform(x2_test)\n"
      ],
      "metadata": {
        "id": "eEhcaI-BitVA"
      },
      "id": "eEhcaI-BitVA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#200 epochs\n",
        "\n",
        "model3.compile(SGD(lr = .005), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_3 = model3.fit(x2_train_norm, y2_train, validation_data=(x2_test_norm, y2_test), epochs=200)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNDRZ1Q0i8Bz",
        "outputId": "7d80cde9-9c4e-4d5a-bb05-0f850583c8b7"
      },
      "id": "aNDRZ1Q0i8Bz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "17/17 [==============================] - 1s 16ms/step - loss: 0.7461 - accuracy: 0.6667 - val_loss: 0.7751 - val_accuracy: 0.6147\n",
            "Epoch 2/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.7293 - accuracy: 0.6667 - val_loss: 0.7564 - val_accuracy: 0.6147\n",
            "Epoch 3/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.7153 - accuracy: 0.6685 - val_loss: 0.7407 - val_accuracy: 0.6147\n",
            "Epoch 4/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.7033 - accuracy: 0.6667 - val_loss: 0.7270 - val_accuracy: 0.6190\n",
            "Epoch 5/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.6667 - val_loss: 0.7152 - val_accuracy: 0.6190\n",
            "Epoch 6/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6839 - accuracy: 0.6667 - val_loss: 0.7048 - val_accuracy: 0.6190\n",
            "Epoch 7/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6759 - accuracy: 0.6667 - val_loss: 0.6956 - val_accuracy: 0.6190\n",
            "Epoch 8/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6686 - accuracy: 0.6667 - val_loss: 0.6873 - val_accuracy: 0.6190\n",
            "Epoch 9/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6620 - accuracy: 0.6667 - val_loss: 0.6797 - val_accuracy: 0.6190\n",
            "Epoch 10/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6558 - accuracy: 0.6667 - val_loss: 0.6726 - val_accuracy: 0.6190\n",
            "Epoch 11/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6500 - accuracy: 0.6685 - val_loss: 0.6659 - val_accuracy: 0.6190\n",
            "Epoch 12/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6444 - accuracy: 0.6685 - val_loss: 0.6597 - val_accuracy: 0.6190\n",
            "Epoch 13/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6392 - accuracy: 0.6685 - val_loss: 0.6540 - val_accuracy: 0.6190\n",
            "Epoch 14/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6344 - accuracy: 0.6685 - val_loss: 0.6486 - val_accuracy: 0.6190\n",
            "Epoch 15/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6297 - accuracy: 0.6685 - val_loss: 0.6435 - val_accuracy: 0.6190\n",
            "Epoch 16/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6253 - accuracy: 0.6704 - val_loss: 0.6388 - val_accuracy: 0.6190\n",
            "Epoch 17/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.6211 - accuracy: 0.6704 - val_loss: 0.6343 - val_accuracy: 0.6190\n",
            "Epoch 18/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6170 - accuracy: 0.6667 - val_loss: 0.6299 - val_accuracy: 0.6190\n",
            "Epoch 19/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6131 - accuracy: 0.6667 - val_loss: 0.6258 - val_accuracy: 0.6190\n",
            "Epoch 20/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6093 - accuracy: 0.6667 - val_loss: 0.6217 - val_accuracy: 0.6234\n",
            "Epoch 21/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6055 - accuracy: 0.6685 - val_loss: 0.6180 - val_accuracy: 0.6234\n",
            "Epoch 22/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6019 - accuracy: 0.6667 - val_loss: 0.6143 - val_accuracy: 0.6234\n",
            "Epoch 23/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5983 - accuracy: 0.6741 - val_loss: 0.6108 - val_accuracy: 0.6234\n",
            "Epoch 24/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5948 - accuracy: 0.6723 - val_loss: 0.6073 - val_accuracy: 0.6234\n",
            "Epoch 25/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5915 - accuracy: 0.6685 - val_loss: 0.6038 - val_accuracy: 0.6234\n",
            "Epoch 26/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5881 - accuracy: 0.6741 - val_loss: 0.6005 - val_accuracy: 0.6234\n",
            "Epoch 27/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.5850 - accuracy: 0.6723 - val_loss: 0.5975 - val_accuracy: 0.6234\n",
            "Epoch 28/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5820 - accuracy: 0.6741 - val_loss: 0.5945 - val_accuracy: 0.6320\n",
            "Epoch 29/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5790 - accuracy: 0.6741 - val_loss: 0.5916 - val_accuracy: 0.6364\n",
            "Epoch 30/200\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.5761 - accuracy: 0.6741 - val_loss: 0.5887 - val_accuracy: 0.6364\n",
            "Epoch 31/200\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.5732 - accuracy: 0.6741 - val_loss: 0.5860 - val_accuracy: 0.6364\n",
            "Epoch 32/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5704 - accuracy: 0.6741 - val_loss: 0.5833 - val_accuracy: 0.6407\n",
            "Epoch 33/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.5676 - accuracy: 0.6741 - val_loss: 0.5807 - val_accuracy: 0.6407\n",
            "Epoch 34/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.5649 - accuracy: 0.6760 - val_loss: 0.5781 - val_accuracy: 0.6407\n",
            "Epoch 35/200\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.5624 - accuracy: 0.6741 - val_loss: 0.5757 - val_accuracy: 0.6407\n",
            "Epoch 36/200\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.5598 - accuracy: 0.6760 - val_loss: 0.5734 - val_accuracy: 0.6364\n",
            "Epoch 37/200\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.5574 - accuracy: 0.6797 - val_loss: 0.5711 - val_accuracy: 0.6364\n",
            "Epoch 38/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.5550 - accuracy: 0.6797 - val_loss: 0.5688 - val_accuracy: 0.6320\n",
            "Epoch 39/200\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.5527 - accuracy: 0.6797 - val_loss: 0.5666 - val_accuracy: 0.6320\n",
            "Epoch 40/200\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.5505 - accuracy: 0.6816 - val_loss: 0.5644 - val_accuracy: 0.6320\n",
            "Epoch 41/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5483 - accuracy: 0.6853 - val_loss: 0.5622 - val_accuracy: 0.6364\n",
            "Epoch 42/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5461 - accuracy: 0.6853 - val_loss: 0.5602 - val_accuracy: 0.6494\n",
            "Epoch 43/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5441 - accuracy: 0.6890 - val_loss: 0.5582 - val_accuracy: 0.6494\n",
            "Epoch 44/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5421 - accuracy: 0.6890 - val_loss: 0.5563 - val_accuracy: 0.6494\n",
            "Epoch 45/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5402 - accuracy: 0.6983 - val_loss: 0.5544 - val_accuracy: 0.6494\n",
            "Epoch 46/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5384 - accuracy: 0.6946 - val_loss: 0.5526 - val_accuracy: 0.6494\n",
            "Epoch 47/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5366 - accuracy: 0.6965 - val_loss: 0.5509 - val_accuracy: 0.6537\n",
            "Epoch 48/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5350 - accuracy: 0.7002 - val_loss: 0.5492 - val_accuracy: 0.6580\n",
            "Epoch 49/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5334 - accuracy: 0.7020 - val_loss: 0.5477 - val_accuracy: 0.6623\n",
            "Epoch 50/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5318 - accuracy: 0.7002 - val_loss: 0.5461 - val_accuracy: 0.6623\n",
            "Epoch 51/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5303 - accuracy: 0.7095 - val_loss: 0.5445 - val_accuracy: 0.6623\n",
            "Epoch 52/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5288 - accuracy: 0.7076 - val_loss: 0.5430 - val_accuracy: 0.6667\n",
            "Epoch 53/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5274 - accuracy: 0.7076 - val_loss: 0.5416 - val_accuracy: 0.6753\n",
            "Epoch 54/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5262 - accuracy: 0.7151 - val_loss: 0.5403 - val_accuracy: 0.6840\n",
            "Epoch 55/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5248 - accuracy: 0.7151 - val_loss: 0.5390 - val_accuracy: 0.6840\n",
            "Epoch 56/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5237 - accuracy: 0.7151 - val_loss: 0.5378 - val_accuracy: 0.6926\n",
            "Epoch 57/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5226 - accuracy: 0.7188 - val_loss: 0.5365 - val_accuracy: 0.6970\n",
            "Epoch 58/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5214 - accuracy: 0.7207 - val_loss: 0.5354 - val_accuracy: 0.7229\n",
            "Epoch 59/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5204 - accuracy: 0.7263 - val_loss: 0.5343 - val_accuracy: 0.7143\n",
            "Epoch 60/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5193 - accuracy: 0.7263 - val_loss: 0.5332 - val_accuracy: 0.7273\n",
            "Epoch 61/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5184 - accuracy: 0.7207 - val_loss: 0.5322 - val_accuracy: 0.7359\n",
            "Epoch 62/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5174 - accuracy: 0.7225 - val_loss: 0.5311 - val_accuracy: 0.7403\n",
            "Epoch 63/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5165 - accuracy: 0.7188 - val_loss: 0.5301 - val_accuracy: 0.7359\n",
            "Epoch 64/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5157 - accuracy: 0.7207 - val_loss: 0.5291 - val_accuracy: 0.7446\n",
            "Epoch 65/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5149 - accuracy: 0.7151 - val_loss: 0.5281 - val_accuracy: 0.7489\n",
            "Epoch 66/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5141 - accuracy: 0.7151 - val_loss: 0.5272 - val_accuracy: 0.7489\n",
            "Epoch 67/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5134 - accuracy: 0.7169 - val_loss: 0.5263 - val_accuracy: 0.7576\n",
            "Epoch 68/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5127 - accuracy: 0.7169 - val_loss: 0.5254 - val_accuracy: 0.7489\n",
            "Epoch 69/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5120 - accuracy: 0.7132 - val_loss: 0.5246 - val_accuracy: 0.7532\n",
            "Epoch 70/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5113 - accuracy: 0.7151 - val_loss: 0.5238 - val_accuracy: 0.7576\n",
            "Epoch 71/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5107 - accuracy: 0.7132 - val_loss: 0.5230 - val_accuracy: 0.7576\n",
            "Epoch 72/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5100 - accuracy: 0.7132 - val_loss: 0.5222 - val_accuracy: 0.7619\n",
            "Epoch 73/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5095 - accuracy: 0.7151 - val_loss: 0.5215 - val_accuracy: 0.7662\n",
            "Epoch 74/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5088 - accuracy: 0.7169 - val_loss: 0.5207 - val_accuracy: 0.7706\n",
            "Epoch 75/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5083 - accuracy: 0.7188 - val_loss: 0.5201 - val_accuracy: 0.7706\n",
            "Epoch 76/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5077 - accuracy: 0.7188 - val_loss: 0.5194 - val_accuracy: 0.7706\n",
            "Epoch 77/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5072 - accuracy: 0.7263 - val_loss: 0.5187 - val_accuracy: 0.7749\n",
            "Epoch 78/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5067 - accuracy: 0.7300 - val_loss: 0.5181 - val_accuracy: 0.7706\n",
            "Epoch 79/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5062 - accuracy: 0.7300 - val_loss: 0.5175 - val_accuracy: 0.7749\n",
            "Epoch 80/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5057 - accuracy: 0.7318 - val_loss: 0.5168 - val_accuracy: 0.7835\n",
            "Epoch 81/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7318 - val_loss: 0.5163 - val_accuracy: 0.7879\n",
            "Epoch 82/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5048 - accuracy: 0.7356 - val_loss: 0.5156 - val_accuracy: 0.7879\n",
            "Epoch 83/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5043 - accuracy: 0.7337 - val_loss: 0.5151 - val_accuracy: 0.7835\n",
            "Epoch 84/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7337 - val_loss: 0.5145 - val_accuracy: 0.7835\n",
            "Epoch 85/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5034 - accuracy: 0.7356 - val_loss: 0.5140 - val_accuracy: 0.7835\n",
            "Epoch 86/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5030 - accuracy: 0.7374 - val_loss: 0.5135 - val_accuracy: 0.7835\n",
            "Epoch 87/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5025 - accuracy: 0.7374 - val_loss: 0.5130 - val_accuracy: 0.7835\n",
            "Epoch 88/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5021 - accuracy: 0.7374 - val_loss: 0.5125 - val_accuracy: 0.7792\n",
            "Epoch 89/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5016 - accuracy: 0.7374 - val_loss: 0.5120 - val_accuracy: 0.7835\n",
            "Epoch 90/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5011 - accuracy: 0.7412 - val_loss: 0.5115 - val_accuracy: 0.7792\n",
            "Epoch 91/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5008 - accuracy: 0.7412 - val_loss: 0.5111 - val_accuracy: 0.7879\n",
            "Epoch 92/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5003 - accuracy: 0.7412 - val_loss: 0.5106 - val_accuracy: 0.7879\n",
            "Epoch 93/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4999 - accuracy: 0.7393 - val_loss: 0.5102 - val_accuracy: 0.7879\n",
            "Epoch 94/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4996 - accuracy: 0.7412 - val_loss: 0.5098 - val_accuracy: 0.7879\n",
            "Epoch 95/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4991 - accuracy: 0.7374 - val_loss: 0.5093 - val_accuracy: 0.7879\n",
            "Epoch 96/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4987 - accuracy: 0.7374 - val_loss: 0.5089 - val_accuracy: 0.7879\n",
            "Epoch 97/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4983 - accuracy: 0.7374 - val_loss: 0.5085 - val_accuracy: 0.7879\n",
            "Epoch 98/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4979 - accuracy: 0.7412 - val_loss: 0.5080 - val_accuracy: 0.7879\n",
            "Epoch 99/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4975 - accuracy: 0.7393 - val_loss: 0.5076 - val_accuracy: 0.7922\n",
            "Epoch 100/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4972 - accuracy: 0.7393 - val_loss: 0.5073 - val_accuracy: 0.7922\n",
            "Epoch 101/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4969 - accuracy: 0.7393 - val_loss: 0.5069 - val_accuracy: 0.7922\n",
            "Epoch 102/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4966 - accuracy: 0.7393 - val_loss: 0.5066 - val_accuracy: 0.7922\n",
            "Epoch 103/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4963 - accuracy: 0.7374 - val_loss: 0.5063 - val_accuracy: 0.7922\n",
            "Epoch 104/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4961 - accuracy: 0.7374 - val_loss: 0.5059 - val_accuracy: 0.7922\n",
            "Epoch 105/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4957 - accuracy: 0.7374 - val_loss: 0.5056 - val_accuracy: 0.7922\n",
            "Epoch 106/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4954 - accuracy: 0.7393 - val_loss: 0.5054 - val_accuracy: 0.7922\n",
            "Epoch 107/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4952 - accuracy: 0.7393 - val_loss: 0.5051 - val_accuracy: 0.7922\n",
            "Epoch 108/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4950 - accuracy: 0.7412 - val_loss: 0.5048 - val_accuracy: 0.7879\n",
            "Epoch 109/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4948 - accuracy: 0.7412 - val_loss: 0.5046 - val_accuracy: 0.7879\n",
            "Epoch 110/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4946 - accuracy: 0.7412 - val_loss: 0.5043 - val_accuracy: 0.7835\n",
            "Epoch 111/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4943 - accuracy: 0.7430 - val_loss: 0.5041 - val_accuracy: 0.7835\n",
            "Epoch 112/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4942 - accuracy: 0.7486 - val_loss: 0.5039 - val_accuracy: 0.7835\n",
            "Epoch 113/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4940 - accuracy: 0.7467 - val_loss: 0.5037 - val_accuracy: 0.7835\n",
            "Epoch 114/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4937 - accuracy: 0.7505 - val_loss: 0.5035 - val_accuracy: 0.7835\n",
            "Epoch 115/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4935 - accuracy: 0.7523 - val_loss: 0.5033 - val_accuracy: 0.7835\n",
            "Epoch 116/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4932 - accuracy: 0.7505 - val_loss: 0.5031 - val_accuracy: 0.7879\n",
            "Epoch 117/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4931 - accuracy: 0.7542 - val_loss: 0.5029 - val_accuracy: 0.7879\n",
            "Epoch 118/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4929 - accuracy: 0.7542 - val_loss: 0.5027 - val_accuracy: 0.7879\n",
            "Epoch 119/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4927 - accuracy: 0.7542 - val_loss: 0.5025 - val_accuracy: 0.7879\n",
            "Epoch 120/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4925 - accuracy: 0.7542 - val_loss: 0.5023 - val_accuracy: 0.7922\n",
            "Epoch 121/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4924 - accuracy: 0.7523 - val_loss: 0.5021 - val_accuracy: 0.7922\n",
            "Epoch 122/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4922 - accuracy: 0.7505 - val_loss: 0.5019 - val_accuracy: 0.7922\n",
            "Epoch 123/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4920 - accuracy: 0.7505 - val_loss: 0.5018 - val_accuracy: 0.7922\n",
            "Epoch 124/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4918 - accuracy: 0.7486 - val_loss: 0.5016 - val_accuracy: 0.7922\n",
            "Epoch 125/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4916 - accuracy: 0.7505 - val_loss: 0.5014 - val_accuracy: 0.7922\n",
            "Epoch 126/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4915 - accuracy: 0.7505 - val_loss: 0.5013 - val_accuracy: 0.7922\n",
            "Epoch 127/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4913 - accuracy: 0.7505 - val_loss: 0.5011 - val_accuracy: 0.7922\n",
            "Epoch 128/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4912 - accuracy: 0.7486 - val_loss: 0.5009 - val_accuracy: 0.7922\n",
            "Epoch 129/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4910 - accuracy: 0.7486 - val_loss: 0.5007 - val_accuracy: 0.7879\n",
            "Epoch 130/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4908 - accuracy: 0.7505 - val_loss: 0.5006 - val_accuracy: 0.7879\n",
            "Epoch 131/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4908 - accuracy: 0.7505 - val_loss: 0.5004 - val_accuracy: 0.7879\n",
            "Epoch 132/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4906 - accuracy: 0.7505 - val_loss: 0.5002 - val_accuracy: 0.7879\n",
            "Epoch 133/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4905 - accuracy: 0.7505 - val_loss: 0.5001 - val_accuracy: 0.7879\n",
            "Epoch 134/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4903 - accuracy: 0.7505 - val_loss: 0.4999 - val_accuracy: 0.7879\n",
            "Epoch 135/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4901 - accuracy: 0.7505 - val_loss: 0.4997 - val_accuracy: 0.7879\n",
            "Epoch 136/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4900 - accuracy: 0.7542 - val_loss: 0.4995 - val_accuracy: 0.7879\n",
            "Epoch 137/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4898 - accuracy: 0.7523 - val_loss: 0.4994 - val_accuracy: 0.7879\n",
            "Epoch 138/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4897 - accuracy: 0.7561 - val_loss: 0.4992 - val_accuracy: 0.7879\n",
            "Epoch 139/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4896 - accuracy: 0.7505 - val_loss: 0.4990 - val_accuracy: 0.7879\n",
            "Epoch 140/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4895 - accuracy: 0.7561 - val_loss: 0.4988 - val_accuracy: 0.7879\n",
            "Epoch 141/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4894 - accuracy: 0.7561 - val_loss: 0.4986 - val_accuracy: 0.7879\n",
            "Epoch 142/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4893 - accuracy: 0.7561 - val_loss: 0.4984 - val_accuracy: 0.7879\n",
            "Epoch 143/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4891 - accuracy: 0.7561 - val_loss: 0.4983 - val_accuracy: 0.7879\n",
            "Epoch 144/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4890 - accuracy: 0.7561 - val_loss: 0.4981 - val_accuracy: 0.7879\n",
            "Epoch 145/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4888 - accuracy: 0.7542 - val_loss: 0.4979 - val_accuracy: 0.7879\n",
            "Epoch 146/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4887 - accuracy: 0.7523 - val_loss: 0.4977 - val_accuracy: 0.7835\n",
            "Epoch 147/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4886 - accuracy: 0.7561 - val_loss: 0.4975 - val_accuracy: 0.7879\n",
            "Epoch 148/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4884 - accuracy: 0.7542 - val_loss: 0.4973 - val_accuracy: 0.7879\n",
            "Epoch 149/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4883 - accuracy: 0.7523 - val_loss: 0.4971 - val_accuracy: 0.7879\n",
            "Epoch 150/200\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4882 - accuracy: 0.7523 - val_loss: 0.4969 - val_accuracy: 0.7879\n",
            "Epoch 151/200\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.4880 - accuracy: 0.7542 - val_loss: 0.4967 - val_accuracy: 0.7879\n",
            "Epoch 152/200\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4879 - accuracy: 0.7542 - val_loss: 0.4966 - val_accuracy: 0.7879\n",
            "Epoch 153/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4877 - accuracy: 0.7523 - val_loss: 0.4964 - val_accuracy: 0.7879\n",
            "Epoch 154/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4876 - accuracy: 0.7542 - val_loss: 0.4961 - val_accuracy: 0.7879\n",
            "Epoch 155/200\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4874 - accuracy: 0.7523 - val_loss: 0.4960 - val_accuracy: 0.7879\n",
            "Epoch 156/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4874 - accuracy: 0.7523 - val_loss: 0.4958 - val_accuracy: 0.7879\n",
            "Epoch 157/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4872 - accuracy: 0.7542 - val_loss: 0.4956 - val_accuracy: 0.7879\n",
            "Epoch 158/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4871 - accuracy: 0.7523 - val_loss: 0.4955 - val_accuracy: 0.7879\n",
            "Epoch 159/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4869 - accuracy: 0.7523 - val_loss: 0.4953 - val_accuracy: 0.7879\n",
            "Epoch 160/200\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4868 - accuracy: 0.7523 - val_loss: 0.4951 - val_accuracy: 0.7879\n",
            "Epoch 161/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4866 - accuracy: 0.7523 - val_loss: 0.4949 - val_accuracy: 0.7879\n",
            "Epoch 162/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4866 - accuracy: 0.7542 - val_loss: 0.4947 - val_accuracy: 0.7879\n",
            "Epoch 163/200\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4863 - accuracy: 0.7523 - val_loss: 0.4946 - val_accuracy: 0.7879\n",
            "Epoch 164/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4863 - accuracy: 0.7523 - val_loss: 0.4944 - val_accuracy: 0.7879\n",
            "Epoch 165/200\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4862 - accuracy: 0.7542 - val_loss: 0.4942 - val_accuracy: 0.7879\n",
            "Epoch 166/200\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.4861 - accuracy: 0.7542 - val_loss: 0.4940 - val_accuracy: 0.7879\n",
            "Epoch 167/200\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4859 - accuracy: 0.7561 - val_loss: 0.4938 - val_accuracy: 0.7879\n",
            "Epoch 168/200\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.4859 - accuracy: 0.7523 - val_loss: 0.4936 - val_accuracy: 0.7879\n",
            "Epoch 169/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4857 - accuracy: 0.7542 - val_loss: 0.4934 - val_accuracy: 0.7879\n",
            "Epoch 170/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4855 - accuracy: 0.7542 - val_loss: 0.4933 - val_accuracy: 0.7879\n",
            "Epoch 171/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4855 - accuracy: 0.7579 - val_loss: 0.4931 - val_accuracy: 0.7879\n",
            "Epoch 172/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4854 - accuracy: 0.7505 - val_loss: 0.4930 - val_accuracy: 0.7879\n",
            "Epoch 173/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4854 - accuracy: 0.7616 - val_loss: 0.4928 - val_accuracy: 0.7879\n",
            "Epoch 174/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7579 - val_loss: 0.4926 - val_accuracy: 0.7879\n",
            "Epoch 175/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4850 - accuracy: 0.7598 - val_loss: 0.4925 - val_accuracy: 0.7879\n",
            "Epoch 176/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4849 - accuracy: 0.7542 - val_loss: 0.4923 - val_accuracy: 0.7879\n",
            "Epoch 177/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4848 - accuracy: 0.7598 - val_loss: 0.4922 - val_accuracy: 0.7879\n",
            "Epoch 178/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4847 - accuracy: 0.7579 - val_loss: 0.4920 - val_accuracy: 0.7879\n",
            "Epoch 179/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.7579 - val_loss: 0.4918 - val_accuracy: 0.7879\n",
            "Epoch 180/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7542 - val_loss: 0.4917 - val_accuracy: 0.7879\n",
            "Epoch 181/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7561 - val_loss: 0.4915 - val_accuracy: 0.7879\n",
            "Epoch 182/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7579 - val_loss: 0.4912 - val_accuracy: 0.7879\n",
            "Epoch 183/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7579 - val_loss: 0.4910 - val_accuracy: 0.7879\n",
            "Epoch 184/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4839 - accuracy: 0.7542 - val_loss: 0.4909 - val_accuracy: 0.7879\n",
            "Epoch 185/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4838 - accuracy: 0.7561 - val_loss: 0.4907 - val_accuracy: 0.7879\n",
            "Epoch 186/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4836 - accuracy: 0.7561 - val_loss: 0.4905 - val_accuracy: 0.7879\n",
            "Epoch 187/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4835 - accuracy: 0.7542 - val_loss: 0.4904 - val_accuracy: 0.7879\n",
            "Epoch 188/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4834 - accuracy: 0.7561 - val_loss: 0.4902 - val_accuracy: 0.7879\n",
            "Epoch 189/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4832 - accuracy: 0.7561 - val_loss: 0.4901 - val_accuracy: 0.7879\n",
            "Epoch 190/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4831 - accuracy: 0.7561 - val_loss: 0.4899 - val_accuracy: 0.7879\n",
            "Epoch 191/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4829 - accuracy: 0.7542 - val_loss: 0.4897 - val_accuracy: 0.7879\n",
            "Epoch 192/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4828 - accuracy: 0.7523 - val_loss: 0.4896 - val_accuracy: 0.7835\n",
            "Epoch 193/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4826 - accuracy: 0.7505 - val_loss: 0.4894 - val_accuracy: 0.7835\n",
            "Epoch 194/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4824 - accuracy: 0.7505 - val_loss: 0.4892 - val_accuracy: 0.7835\n",
            "Epoch 195/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4822 - accuracy: 0.7505 - val_loss: 0.4890 - val_accuracy: 0.7835\n",
            "Epoch 196/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4822 - accuracy: 0.7505 - val_loss: 0.4888 - val_accuracy: 0.7792\n",
            "Epoch 197/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4819 - accuracy: 0.7505 - val_loss: 0.4886 - val_accuracy: 0.7792\n",
            "Epoch 198/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4817 - accuracy: 0.7523 - val_loss: 0.4884 - val_accuracy: 0.7792\n",
            "Epoch 199/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4817 - accuracy: 0.7523 - val_loss: 0.4883 - val_accuracy: 0.7792\n",
            "Epoch 200/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4815 - accuracy: 0.7542 - val_loss: 0.4881 - val_accuracy: 0.7792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#500 epochs\n",
        "\n",
        "model4.compile(SGD(lr = .005), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_4= model4.fit(x2_train_norm, y2_train, validation_data=(x2_test_norm, y2_test), epochs=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACzYAcG-PKKQ",
        "outputId": "314131c4-2477-4eb9-86c9-117832bf2394"
      },
      "id": "ACzYAcG-PKKQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "17/17 [==============================] - 1s 14ms/step - loss: 0.7383 - accuracy: 0.6276 - val_loss: 0.7222 - val_accuracy: 0.6667\n",
            "Epoch 2/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.7289 - accuracy: 0.6387 - val_loss: 0.7137 - val_accuracy: 0.6710\n",
            "Epoch 3/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.7210 - accuracy: 0.6425 - val_loss: 0.7064 - val_accuracy: 0.6797\n",
            "Epoch 4/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.7141 - accuracy: 0.6406 - val_loss: 0.7002 - val_accuracy: 0.6753\n",
            "Epoch 5/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.7083 - accuracy: 0.6406 - val_loss: 0.6946 - val_accuracy: 0.6753\n",
            "Epoch 6/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.7030 - accuracy: 0.6406 - val_loss: 0.6897 - val_accuracy: 0.6753\n",
            "Epoch 7/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6984 - accuracy: 0.6406 - val_loss: 0.6853 - val_accuracy: 0.6753\n",
            "Epoch 8/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6942 - accuracy: 0.6406 - val_loss: 0.6813 - val_accuracy: 0.6753\n",
            "Epoch 9/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6904 - accuracy: 0.6406 - val_loss: 0.6776 - val_accuracy: 0.6753\n",
            "Epoch 10/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6868 - accuracy: 0.6406 - val_loss: 0.6742 - val_accuracy: 0.6753\n",
            "Epoch 11/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6835 - accuracy: 0.6406 - val_loss: 0.6710 - val_accuracy: 0.6753\n",
            "Epoch 12/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6804 - accuracy: 0.6406 - val_loss: 0.6680 - val_accuracy: 0.6753\n",
            "Epoch 13/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6775 - accuracy: 0.6406 - val_loss: 0.6651 - val_accuracy: 0.6753\n",
            "Epoch 14/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6747 - accuracy: 0.6406 - val_loss: 0.6624 - val_accuracy: 0.6753\n",
            "Epoch 15/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6721 - accuracy: 0.6406 - val_loss: 0.6598 - val_accuracy: 0.6753\n",
            "Epoch 16/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6695 - accuracy: 0.6406 - val_loss: 0.6572 - val_accuracy: 0.6753\n",
            "Epoch 17/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6670 - accuracy: 0.6406 - val_loss: 0.6547 - val_accuracy: 0.6753\n",
            "Epoch 18/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6647 - accuracy: 0.6406 - val_loss: 0.6524 - val_accuracy: 0.6753\n",
            "Epoch 19/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6625 - accuracy: 0.6406 - val_loss: 0.6500 - val_accuracy: 0.6753\n",
            "Epoch 20/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6602 - accuracy: 0.6406 - val_loss: 0.6477 - val_accuracy: 0.6753\n",
            "Epoch 21/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6581 - accuracy: 0.6406 - val_loss: 0.6454 - val_accuracy: 0.6753\n",
            "Epoch 22/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6559 - accuracy: 0.6406 - val_loss: 0.6432 - val_accuracy: 0.6753\n",
            "Epoch 23/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6537 - accuracy: 0.6406 - val_loss: 0.6409 - val_accuracy: 0.6753\n",
            "Epoch 24/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6516 - accuracy: 0.6406 - val_loss: 0.6387 - val_accuracy: 0.6753\n",
            "Epoch 25/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6495 - accuracy: 0.6406 - val_loss: 0.6364 - val_accuracy: 0.6753\n",
            "Epoch 26/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6474 - accuracy: 0.6406 - val_loss: 0.6342 - val_accuracy: 0.6753\n",
            "Epoch 27/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6453 - accuracy: 0.6406 - val_loss: 0.6319 - val_accuracy: 0.6753\n",
            "Epoch 28/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6432 - accuracy: 0.6406 - val_loss: 0.6297 - val_accuracy: 0.6753\n",
            "Epoch 29/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6411 - accuracy: 0.6406 - val_loss: 0.6274 - val_accuracy: 0.6753\n",
            "Epoch 30/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6391 - accuracy: 0.6406 - val_loss: 0.6252 - val_accuracy: 0.6753\n",
            "Epoch 31/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6370 - accuracy: 0.6406 - val_loss: 0.6229 - val_accuracy: 0.6753\n",
            "Epoch 32/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6349 - accuracy: 0.6406 - val_loss: 0.6206 - val_accuracy: 0.6753\n",
            "Epoch 33/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6329 - accuracy: 0.6406 - val_loss: 0.6182 - val_accuracy: 0.6753\n",
            "Epoch 34/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6309 - accuracy: 0.6406 - val_loss: 0.6159 - val_accuracy: 0.6753\n",
            "Epoch 35/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6288 - accuracy: 0.6406 - val_loss: 0.6135 - val_accuracy: 0.6753\n",
            "Epoch 36/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6268 - accuracy: 0.6406 - val_loss: 0.6111 - val_accuracy: 0.6753\n",
            "Epoch 37/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6248 - accuracy: 0.6406 - val_loss: 0.6088 - val_accuracy: 0.6753\n",
            "Epoch 38/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6229 - accuracy: 0.6406 - val_loss: 0.6064 - val_accuracy: 0.6753\n",
            "Epoch 39/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6209 - accuracy: 0.6406 - val_loss: 0.6040 - val_accuracy: 0.6753\n",
            "Epoch 40/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6189 - accuracy: 0.6406 - val_loss: 0.6016 - val_accuracy: 0.6753\n",
            "Epoch 41/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6169 - accuracy: 0.6406 - val_loss: 0.5992 - val_accuracy: 0.6753\n",
            "Epoch 42/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6148 - accuracy: 0.6406 - val_loss: 0.5968 - val_accuracy: 0.6753\n",
            "Epoch 43/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6128 - accuracy: 0.6406 - val_loss: 0.5943 - val_accuracy: 0.6753\n",
            "Epoch 44/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6108 - accuracy: 0.6406 - val_loss: 0.5919 - val_accuracy: 0.6753\n",
            "Epoch 45/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6088 - accuracy: 0.6406 - val_loss: 0.5895 - val_accuracy: 0.6753\n",
            "Epoch 46/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6068 - accuracy: 0.6406 - val_loss: 0.5871 - val_accuracy: 0.6753\n",
            "Epoch 47/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6048 - accuracy: 0.6406 - val_loss: 0.5847 - val_accuracy: 0.6753\n",
            "Epoch 48/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6028 - accuracy: 0.6406 - val_loss: 0.5823 - val_accuracy: 0.6753\n",
            "Epoch 49/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6008 - accuracy: 0.6406 - val_loss: 0.5799 - val_accuracy: 0.6753\n",
            "Epoch 50/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5989 - accuracy: 0.6406 - val_loss: 0.5776 - val_accuracy: 0.6753\n",
            "Epoch 51/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5970 - accuracy: 0.6406 - val_loss: 0.5752 - val_accuracy: 0.6753\n",
            "Epoch 52/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5950 - accuracy: 0.6406 - val_loss: 0.5727 - val_accuracy: 0.6753\n",
            "Epoch 53/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5931 - accuracy: 0.6406 - val_loss: 0.5703 - val_accuracy: 0.6753\n",
            "Epoch 54/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5912 - accuracy: 0.6406 - val_loss: 0.5679 - val_accuracy: 0.6753\n",
            "Epoch 55/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5893 - accuracy: 0.6406 - val_loss: 0.5655 - val_accuracy: 0.6753\n",
            "Epoch 56/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5874 - accuracy: 0.6406 - val_loss: 0.5632 - val_accuracy: 0.6753\n",
            "Epoch 57/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5856 - accuracy: 0.6406 - val_loss: 0.5609 - val_accuracy: 0.6753\n",
            "Epoch 58/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5838 - accuracy: 0.6406 - val_loss: 0.5585 - val_accuracy: 0.6753\n",
            "Epoch 59/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5820 - accuracy: 0.6406 - val_loss: 0.5563 - val_accuracy: 0.6753\n",
            "Epoch 60/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5801 - accuracy: 0.6406 - val_loss: 0.5540 - val_accuracy: 0.6753\n",
            "Epoch 61/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5784 - accuracy: 0.6406 - val_loss: 0.5518 - val_accuracy: 0.6753\n",
            "Epoch 62/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5766 - accuracy: 0.6406 - val_loss: 0.5495 - val_accuracy: 0.6753\n",
            "Epoch 63/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5750 - accuracy: 0.6406 - val_loss: 0.5474 - val_accuracy: 0.6753\n",
            "Epoch 64/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5733 - accuracy: 0.6406 - val_loss: 0.5453 - val_accuracy: 0.6753\n",
            "Epoch 65/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5717 - accuracy: 0.6406 - val_loss: 0.5431 - val_accuracy: 0.6753\n",
            "Epoch 66/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5701 - accuracy: 0.6406 - val_loss: 0.5411 - val_accuracy: 0.6753\n",
            "Epoch 67/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5685 - accuracy: 0.6406 - val_loss: 0.5391 - val_accuracy: 0.6753\n",
            "Epoch 68/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5670 - accuracy: 0.6406 - val_loss: 0.5371 - val_accuracy: 0.6753\n",
            "Epoch 69/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5655 - accuracy: 0.6406 - val_loss: 0.5351 - val_accuracy: 0.6753\n",
            "Epoch 70/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5639 - accuracy: 0.6406 - val_loss: 0.5332 - val_accuracy: 0.6753\n",
            "Epoch 71/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5625 - accuracy: 0.6406 - val_loss: 0.5313 - val_accuracy: 0.6753\n",
            "Epoch 72/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5610 - accuracy: 0.6406 - val_loss: 0.5295 - val_accuracy: 0.6753\n",
            "Epoch 73/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5596 - accuracy: 0.6406 - val_loss: 0.5276 - val_accuracy: 0.6753\n",
            "Epoch 74/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5582 - accuracy: 0.6406 - val_loss: 0.5259 - val_accuracy: 0.6753\n",
            "Epoch 75/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5569 - accuracy: 0.6406 - val_loss: 0.5242 - val_accuracy: 0.6753\n",
            "Epoch 76/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5556 - accuracy: 0.6406 - val_loss: 0.5225 - val_accuracy: 0.6753\n",
            "Epoch 77/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5543 - accuracy: 0.6406 - val_loss: 0.5209 - val_accuracy: 0.6753\n",
            "Epoch 78/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5530 - accuracy: 0.6406 - val_loss: 0.5193 - val_accuracy: 0.6753\n",
            "Epoch 79/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5518 - accuracy: 0.6406 - val_loss: 0.5177 - val_accuracy: 0.6753\n",
            "Epoch 80/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5505 - accuracy: 0.6406 - val_loss: 0.5162 - val_accuracy: 0.6753\n",
            "Epoch 81/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5493 - accuracy: 0.6406 - val_loss: 0.5147 - val_accuracy: 0.6753\n",
            "Epoch 82/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5480 - accuracy: 0.6406 - val_loss: 0.5131 - val_accuracy: 0.6753\n",
            "Epoch 83/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5468 - accuracy: 0.6406 - val_loss: 0.5116 - val_accuracy: 0.6753\n",
            "Epoch 84/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5457 - accuracy: 0.6406 - val_loss: 0.5102 - val_accuracy: 0.6753\n",
            "Epoch 85/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5445 - accuracy: 0.6406 - val_loss: 0.5088 - val_accuracy: 0.6753\n",
            "Epoch 86/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5435 - accuracy: 0.6406 - val_loss: 0.5074 - val_accuracy: 0.6753\n",
            "Epoch 87/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5424 - accuracy: 0.6406 - val_loss: 0.5060 - val_accuracy: 0.6753\n",
            "Epoch 88/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5413 - accuracy: 0.6406 - val_loss: 0.5047 - val_accuracy: 0.6753\n",
            "Epoch 89/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5403 - accuracy: 0.6406 - val_loss: 0.5035 - val_accuracy: 0.6753\n",
            "Epoch 90/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5392 - accuracy: 0.6406 - val_loss: 0.5023 - val_accuracy: 0.6753\n",
            "Epoch 91/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.6406 - val_loss: 0.5011 - val_accuracy: 0.6753\n",
            "Epoch 92/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5373 - accuracy: 0.6406 - val_loss: 0.4999 - val_accuracy: 0.6753\n",
            "Epoch 93/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5364 - accuracy: 0.6406 - val_loss: 0.4987 - val_accuracy: 0.6753\n",
            "Epoch 94/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5355 - accuracy: 0.6406 - val_loss: 0.4976 - val_accuracy: 0.6753\n",
            "Epoch 95/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5346 - accuracy: 0.6406 - val_loss: 0.4964 - val_accuracy: 0.6753\n",
            "Epoch 96/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5336 - accuracy: 0.6406 - val_loss: 0.4953 - val_accuracy: 0.6753\n",
            "Epoch 97/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5328 - accuracy: 0.6406 - val_loss: 0.4943 - val_accuracy: 0.6753\n",
            "Epoch 98/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5319 - accuracy: 0.6443 - val_loss: 0.4933 - val_accuracy: 0.6753\n",
            "Epoch 99/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.6443 - val_loss: 0.4923 - val_accuracy: 0.6753\n",
            "Epoch 100/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5302 - accuracy: 0.6518 - val_loss: 0.4914 - val_accuracy: 0.6753\n",
            "Epoch 101/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5294 - accuracy: 0.6741 - val_loss: 0.4904 - val_accuracy: 0.7489\n",
            "Epoch 102/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.7169 - val_loss: 0.4895 - val_accuracy: 0.7662\n",
            "Epoch 103/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5278 - accuracy: 0.7188 - val_loss: 0.4886 - val_accuracy: 0.7619\n",
            "Epoch 104/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5271 - accuracy: 0.7225 - val_loss: 0.4877 - val_accuracy: 0.7576\n",
            "Epoch 105/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5263 - accuracy: 0.7225 - val_loss: 0.4869 - val_accuracy: 0.7576\n",
            "Epoch 106/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5255 - accuracy: 0.7188 - val_loss: 0.4860 - val_accuracy: 0.7576\n",
            "Epoch 107/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5248 - accuracy: 0.7244 - val_loss: 0.4852 - val_accuracy: 0.7576\n",
            "Epoch 108/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5241 - accuracy: 0.7263 - val_loss: 0.4844 - val_accuracy: 0.7576\n",
            "Epoch 109/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5233 - accuracy: 0.7244 - val_loss: 0.4836 - val_accuracy: 0.7749\n",
            "Epoch 110/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5227 - accuracy: 0.7281 - val_loss: 0.4829 - val_accuracy: 0.7792\n",
            "Epoch 111/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5219 - accuracy: 0.7318 - val_loss: 0.4822 - val_accuracy: 0.7792\n",
            "Epoch 112/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5213 - accuracy: 0.7318 - val_loss: 0.4815 - val_accuracy: 0.7792\n",
            "Epoch 113/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5207 - accuracy: 0.7393 - val_loss: 0.4808 - val_accuracy: 0.7879\n",
            "Epoch 114/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5200 - accuracy: 0.7412 - val_loss: 0.4802 - val_accuracy: 0.7922\n",
            "Epoch 115/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5194 - accuracy: 0.7449 - val_loss: 0.4796 - val_accuracy: 0.7922\n",
            "Epoch 116/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5188 - accuracy: 0.7430 - val_loss: 0.4790 - val_accuracy: 0.7922\n",
            "Epoch 117/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5182 - accuracy: 0.7486 - val_loss: 0.4784 - val_accuracy: 0.7879\n",
            "Epoch 118/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5177 - accuracy: 0.7467 - val_loss: 0.4778 - val_accuracy: 0.7835\n",
            "Epoch 119/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5172 - accuracy: 0.7505 - val_loss: 0.4773 - val_accuracy: 0.7879\n",
            "Epoch 120/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5166 - accuracy: 0.7486 - val_loss: 0.4767 - val_accuracy: 0.7879\n",
            "Epoch 121/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5160 - accuracy: 0.7505 - val_loss: 0.4762 - val_accuracy: 0.7835\n",
            "Epoch 122/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5155 - accuracy: 0.7505 - val_loss: 0.4758 - val_accuracy: 0.7835\n",
            "Epoch 123/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5150 - accuracy: 0.7523 - val_loss: 0.4752 - val_accuracy: 0.7792\n",
            "Epoch 124/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.5145 - accuracy: 0.7523 - val_loss: 0.4747 - val_accuracy: 0.7792\n",
            "Epoch 125/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.5140 - accuracy: 0.7542 - val_loss: 0.4742 - val_accuracy: 0.7792\n",
            "Epoch 126/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5135 - accuracy: 0.7542 - val_loss: 0.4737 - val_accuracy: 0.7749\n",
            "Epoch 127/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5131 - accuracy: 0.7523 - val_loss: 0.4733 - val_accuracy: 0.7749\n",
            "Epoch 128/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5127 - accuracy: 0.7542 - val_loss: 0.4729 - val_accuracy: 0.7749\n",
            "Epoch 129/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5122 - accuracy: 0.7542 - val_loss: 0.4725 - val_accuracy: 0.7749\n",
            "Epoch 130/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.7579 - val_loss: 0.4720 - val_accuracy: 0.7749\n",
            "Epoch 131/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.7561 - val_loss: 0.4716 - val_accuracy: 0.7749\n",
            "Epoch 132/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5109 - accuracy: 0.7561 - val_loss: 0.4712 - val_accuracy: 0.7792\n",
            "Epoch 133/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5105 - accuracy: 0.7561 - val_loss: 0.4709 - val_accuracy: 0.7792\n",
            "Epoch 134/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.7523 - val_loss: 0.4705 - val_accuracy: 0.7835\n",
            "Epoch 135/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.7542 - val_loss: 0.4702 - val_accuracy: 0.7879\n",
            "Epoch 136/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5093 - accuracy: 0.7542 - val_loss: 0.4698 - val_accuracy: 0.7879\n",
            "Epoch 137/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5089 - accuracy: 0.7542 - val_loss: 0.4695 - val_accuracy: 0.7879\n",
            "Epoch 138/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5086 - accuracy: 0.7561 - val_loss: 0.4692 - val_accuracy: 0.7879\n",
            "Epoch 139/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5081 - accuracy: 0.7579 - val_loss: 0.4689 - val_accuracy: 0.7879\n",
            "Epoch 140/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.7579 - val_loss: 0.4686 - val_accuracy: 0.7879\n",
            "Epoch 141/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5075 - accuracy: 0.7579 - val_loss: 0.4683 - val_accuracy: 0.7879\n",
            "Epoch 142/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7598 - val_loss: 0.4680 - val_accuracy: 0.7922\n",
            "Epoch 143/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5068 - accuracy: 0.7598 - val_loss: 0.4678 - val_accuracy: 0.7922\n",
            "Epoch 144/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7579 - val_loss: 0.4676 - val_accuracy: 0.7879\n",
            "Epoch 145/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5062 - accuracy: 0.7579 - val_loss: 0.4674 - val_accuracy: 0.7879\n",
            "Epoch 146/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7598 - val_loss: 0.4671 - val_accuracy: 0.7879\n",
            "Epoch 147/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7598 - val_loss: 0.4668 - val_accuracy: 0.7879\n",
            "Epoch 148/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7616 - val_loss: 0.4666 - val_accuracy: 0.7922\n",
            "Epoch 149/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7635 - val_loss: 0.4663 - val_accuracy: 0.7879\n",
            "Epoch 150/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5046 - accuracy: 0.7654 - val_loss: 0.4660 - val_accuracy: 0.7879\n",
            "Epoch 151/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7616 - val_loss: 0.4658 - val_accuracy: 0.7879\n",
            "Epoch 152/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7635 - val_loss: 0.4655 - val_accuracy: 0.7879\n",
            "Epoch 153/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.7654 - val_loss: 0.4654 - val_accuracy: 0.7879\n",
            "Epoch 154/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5034 - accuracy: 0.7654 - val_loss: 0.4651 - val_accuracy: 0.7879\n",
            "Epoch 155/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5032 - accuracy: 0.7654 - val_loss: 0.4649 - val_accuracy: 0.7879\n",
            "Epoch 156/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7635 - val_loss: 0.4647 - val_accuracy: 0.7879\n",
            "Epoch 157/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5026 - accuracy: 0.7654 - val_loss: 0.4644 - val_accuracy: 0.7879\n",
            "Epoch 158/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5024 - accuracy: 0.7616 - val_loss: 0.4642 - val_accuracy: 0.7879\n",
            "Epoch 159/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7635 - val_loss: 0.4640 - val_accuracy: 0.7922\n",
            "Epoch 160/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5018 - accuracy: 0.7709 - val_loss: 0.4638 - val_accuracy: 0.7922\n",
            "Epoch 161/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5015 - accuracy: 0.7691 - val_loss: 0.4637 - val_accuracy: 0.7922\n",
            "Epoch 162/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5013 - accuracy: 0.7672 - val_loss: 0.4636 - val_accuracy: 0.7835\n",
            "Epoch 163/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5010 - accuracy: 0.7709 - val_loss: 0.4633 - val_accuracy: 0.7835\n",
            "Epoch 164/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5008 - accuracy: 0.7654 - val_loss: 0.4632 - val_accuracy: 0.7792\n",
            "Epoch 165/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5004 - accuracy: 0.7765 - val_loss: 0.4630 - val_accuracy: 0.7792\n",
            "Epoch 166/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5002 - accuracy: 0.7765 - val_loss: 0.4628 - val_accuracy: 0.7792\n",
            "Epoch 167/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5000 - accuracy: 0.7747 - val_loss: 0.4626 - val_accuracy: 0.7792\n",
            "Epoch 168/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4998 - accuracy: 0.7765 - val_loss: 0.4624 - val_accuracy: 0.7792\n",
            "Epoch 169/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4994 - accuracy: 0.7765 - val_loss: 0.4623 - val_accuracy: 0.7792\n",
            "Epoch 170/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4993 - accuracy: 0.7784 - val_loss: 0.4621 - val_accuracy: 0.7792\n",
            "Epoch 171/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4990 - accuracy: 0.7803 - val_loss: 0.4619 - val_accuracy: 0.7792\n",
            "Epoch 172/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4988 - accuracy: 0.7784 - val_loss: 0.4617 - val_accuracy: 0.7792\n",
            "Epoch 173/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.7821 - val_loss: 0.4616 - val_accuracy: 0.7835\n",
            "Epoch 174/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4983 - accuracy: 0.7803 - val_loss: 0.4615 - val_accuracy: 0.7835\n",
            "Epoch 175/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4980 - accuracy: 0.7821 - val_loss: 0.4614 - val_accuracy: 0.7792\n",
            "Epoch 176/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4978 - accuracy: 0.7821 - val_loss: 0.4612 - val_accuracy: 0.7792\n",
            "Epoch 177/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.7821 - val_loss: 0.4610 - val_accuracy: 0.7792\n",
            "Epoch 178/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4973 - accuracy: 0.7840 - val_loss: 0.4609 - val_accuracy: 0.7792\n",
            "Epoch 179/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4972 - accuracy: 0.7840 - val_loss: 0.4607 - val_accuracy: 0.7792\n",
            "Epoch 180/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4969 - accuracy: 0.7840 - val_loss: 0.4605 - val_accuracy: 0.7792\n",
            "Epoch 181/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4967 - accuracy: 0.7840 - val_loss: 0.4604 - val_accuracy: 0.7792\n",
            "Epoch 182/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4965 - accuracy: 0.7840 - val_loss: 0.4603 - val_accuracy: 0.7792\n",
            "Epoch 183/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4963 - accuracy: 0.7840 - val_loss: 0.4602 - val_accuracy: 0.7792\n",
            "Epoch 184/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.7821 - val_loss: 0.4600 - val_accuracy: 0.7792\n",
            "Epoch 185/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4959 - accuracy: 0.7840 - val_loss: 0.4599 - val_accuracy: 0.7792\n",
            "Epoch 186/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4957 - accuracy: 0.7821 - val_loss: 0.4598 - val_accuracy: 0.7792\n",
            "Epoch 187/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4955 - accuracy: 0.7821 - val_loss: 0.4597 - val_accuracy: 0.7792\n",
            "Epoch 188/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4953 - accuracy: 0.7821 - val_loss: 0.4595 - val_accuracy: 0.7792\n",
            "Epoch 189/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4951 - accuracy: 0.7821 - val_loss: 0.4594 - val_accuracy: 0.7792\n",
            "Epoch 190/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4948 - accuracy: 0.7821 - val_loss: 0.4592 - val_accuracy: 0.7792\n",
            "Epoch 191/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4948 - accuracy: 0.7821 - val_loss: 0.4592 - val_accuracy: 0.7792\n",
            "Epoch 192/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4944 - accuracy: 0.7821 - val_loss: 0.4591 - val_accuracy: 0.7792\n",
            "Epoch 193/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4943 - accuracy: 0.7821 - val_loss: 0.4589 - val_accuracy: 0.7792\n",
            "Epoch 194/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4941 - accuracy: 0.7821 - val_loss: 0.4589 - val_accuracy: 0.7835\n",
            "Epoch 195/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4939 - accuracy: 0.7840 - val_loss: 0.4589 - val_accuracy: 0.7835\n",
            "Epoch 196/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4938 - accuracy: 0.7840 - val_loss: 0.4587 - val_accuracy: 0.7835\n",
            "Epoch 197/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4936 - accuracy: 0.7784 - val_loss: 0.4586 - val_accuracy: 0.7835\n",
            "Epoch 198/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4933 - accuracy: 0.7803 - val_loss: 0.4585 - val_accuracy: 0.7835\n",
            "Epoch 199/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4932 - accuracy: 0.7821 - val_loss: 0.4585 - val_accuracy: 0.7835\n",
            "Epoch 200/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4930 - accuracy: 0.7821 - val_loss: 0.4583 - val_accuracy: 0.7835\n",
            "Epoch 201/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4928 - accuracy: 0.7803 - val_loss: 0.4582 - val_accuracy: 0.7835\n",
            "Epoch 202/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4927 - accuracy: 0.7821 - val_loss: 0.4581 - val_accuracy: 0.7792\n",
            "Epoch 203/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4926 - accuracy: 0.7803 - val_loss: 0.4580 - val_accuracy: 0.7792\n",
            "Epoch 204/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4923 - accuracy: 0.7821 - val_loss: 0.4580 - val_accuracy: 0.7835\n",
            "Epoch 205/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4923 - accuracy: 0.7803 - val_loss: 0.4579 - val_accuracy: 0.7835\n",
            "Epoch 206/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4920 - accuracy: 0.7803 - val_loss: 0.4577 - val_accuracy: 0.7835\n",
            "Epoch 207/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4918 - accuracy: 0.7803 - val_loss: 0.4576 - val_accuracy: 0.7879\n",
            "Epoch 208/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4917 - accuracy: 0.7784 - val_loss: 0.4575 - val_accuracy: 0.7835\n",
            "Epoch 209/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4915 - accuracy: 0.7765 - val_loss: 0.4575 - val_accuracy: 0.7835\n",
            "Epoch 210/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4914 - accuracy: 0.7784 - val_loss: 0.4575 - val_accuracy: 0.7835\n",
            "Epoch 211/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4913 - accuracy: 0.7765 - val_loss: 0.4573 - val_accuracy: 0.7835\n",
            "Epoch 212/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4910 - accuracy: 0.7784 - val_loss: 0.4573 - val_accuracy: 0.7879\n",
            "Epoch 213/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4909 - accuracy: 0.7821 - val_loss: 0.4572 - val_accuracy: 0.7879\n",
            "Epoch 214/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4907 - accuracy: 0.7765 - val_loss: 0.4573 - val_accuracy: 0.7879\n",
            "Epoch 215/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4906 - accuracy: 0.7784 - val_loss: 0.4572 - val_accuracy: 0.7879\n",
            "Epoch 216/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4905 - accuracy: 0.7803 - val_loss: 0.4571 - val_accuracy: 0.7879\n",
            "Epoch 217/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4904 - accuracy: 0.7765 - val_loss: 0.4569 - val_accuracy: 0.7922\n",
            "Epoch 218/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4901 - accuracy: 0.7784 - val_loss: 0.4568 - val_accuracy: 0.7922\n",
            "Epoch 219/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4900 - accuracy: 0.7784 - val_loss: 0.4567 - val_accuracy: 0.7922\n",
            "Epoch 220/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4898 - accuracy: 0.7765 - val_loss: 0.4566 - val_accuracy: 0.7922\n",
            "Epoch 221/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4897 - accuracy: 0.7784 - val_loss: 0.4565 - val_accuracy: 0.7922\n",
            "Epoch 222/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4895 - accuracy: 0.7765 - val_loss: 0.4564 - val_accuracy: 0.7879\n",
            "Epoch 223/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4894 - accuracy: 0.7765 - val_loss: 0.4564 - val_accuracy: 0.7879\n",
            "Epoch 224/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4892 - accuracy: 0.7765 - val_loss: 0.4563 - val_accuracy: 0.7879\n",
            "Epoch 225/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.7765 - val_loss: 0.4562 - val_accuracy: 0.7879\n",
            "Epoch 226/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4890 - accuracy: 0.7747 - val_loss: 0.4561 - val_accuracy: 0.7879\n",
            "Epoch 227/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4889 - accuracy: 0.7765 - val_loss: 0.4560 - val_accuracy: 0.7879\n",
            "Epoch 228/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4887 - accuracy: 0.7747 - val_loss: 0.4558 - val_accuracy: 0.7879\n",
            "Epoch 229/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.7747 - val_loss: 0.4558 - val_accuracy: 0.7879\n",
            "Epoch 230/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4885 - accuracy: 0.7747 - val_loss: 0.4558 - val_accuracy: 0.7879\n",
            "Epoch 231/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4883 - accuracy: 0.7765 - val_loss: 0.4557 - val_accuracy: 0.7879\n",
            "Epoch 232/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4883 - accuracy: 0.7747 - val_loss: 0.4558 - val_accuracy: 0.7879\n",
            "Epoch 233/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4881 - accuracy: 0.7747 - val_loss: 0.4556 - val_accuracy: 0.7879\n",
            "Epoch 234/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4880 - accuracy: 0.7728 - val_loss: 0.4556 - val_accuracy: 0.7879\n",
            "Epoch 235/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4878 - accuracy: 0.7747 - val_loss: 0.4556 - val_accuracy: 0.7879\n",
            "Epoch 236/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4877 - accuracy: 0.7728 - val_loss: 0.4554 - val_accuracy: 0.7879\n",
            "Epoch 237/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4876 - accuracy: 0.7765 - val_loss: 0.4553 - val_accuracy: 0.7879\n",
            "Epoch 238/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4876 - accuracy: 0.7728 - val_loss: 0.4552 - val_accuracy: 0.7879\n",
            "Epoch 239/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4874 - accuracy: 0.7747 - val_loss: 0.4551 - val_accuracy: 0.7879\n",
            "Epoch 240/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4873 - accuracy: 0.7728 - val_loss: 0.4551 - val_accuracy: 0.7879\n",
            "Epoch 241/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4871 - accuracy: 0.7728 - val_loss: 0.4551 - val_accuracy: 0.7879\n",
            "Epoch 242/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4870 - accuracy: 0.7728 - val_loss: 0.4550 - val_accuracy: 0.7879\n",
            "Epoch 243/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4869 - accuracy: 0.7728 - val_loss: 0.4548 - val_accuracy: 0.7879\n",
            "Epoch 244/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4868 - accuracy: 0.7709 - val_loss: 0.4546 - val_accuracy: 0.7879\n",
            "Epoch 245/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4866 - accuracy: 0.7728 - val_loss: 0.4545 - val_accuracy: 0.7879\n",
            "Epoch 246/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4865 - accuracy: 0.7709 - val_loss: 0.4545 - val_accuracy: 0.7879\n",
            "Epoch 247/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4864 - accuracy: 0.7747 - val_loss: 0.4544 - val_accuracy: 0.7879\n",
            "Epoch 248/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4864 - accuracy: 0.7728 - val_loss: 0.4542 - val_accuracy: 0.7879\n",
            "Epoch 249/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4862 - accuracy: 0.7728 - val_loss: 0.4541 - val_accuracy: 0.7879\n",
            "Epoch 250/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4860 - accuracy: 0.7747 - val_loss: 0.4540 - val_accuracy: 0.7879\n",
            "Epoch 251/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4858 - accuracy: 0.7728 - val_loss: 0.4539 - val_accuracy: 0.7879\n",
            "Epoch 252/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4858 - accuracy: 0.7709 - val_loss: 0.4539 - val_accuracy: 0.7879\n",
            "Epoch 253/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4855 - accuracy: 0.7728 - val_loss: 0.4538 - val_accuracy: 0.7879\n",
            "Epoch 254/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4856 - accuracy: 0.7728 - val_loss: 0.4537 - val_accuracy: 0.7879\n",
            "Epoch 255/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4855 - accuracy: 0.7728 - val_loss: 0.4536 - val_accuracy: 0.7879\n",
            "Epoch 256/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4853 - accuracy: 0.7709 - val_loss: 0.4536 - val_accuracy: 0.7879\n",
            "Epoch 257/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4853 - accuracy: 0.7728 - val_loss: 0.4534 - val_accuracy: 0.7879\n",
            "Epoch 258/500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4852 - accuracy: 0.7709 - val_loss: 0.4534 - val_accuracy: 0.7879\n",
            "Epoch 259/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4850 - accuracy: 0.7728 - val_loss: 0.4533 - val_accuracy: 0.7879\n",
            "Epoch 260/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4849 - accuracy: 0.7728 - val_loss: 0.4534 - val_accuracy: 0.7879\n",
            "Epoch 261/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4847 - accuracy: 0.7747 - val_loss: 0.4532 - val_accuracy: 0.7879\n",
            "Epoch 262/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4847 - accuracy: 0.7728 - val_loss: 0.4531 - val_accuracy: 0.7879\n",
            "Epoch 263/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.7728 - val_loss: 0.4530 - val_accuracy: 0.7879\n",
            "Epoch 264/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7728 - val_loss: 0.4530 - val_accuracy: 0.7879\n",
            "Epoch 265/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4844 - accuracy: 0.7709 - val_loss: 0.4529 - val_accuracy: 0.7879\n",
            "Epoch 266/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4842 - accuracy: 0.7728 - val_loss: 0.4529 - val_accuracy: 0.7879\n",
            "Epoch 267/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4841 - accuracy: 0.7747 - val_loss: 0.4528 - val_accuracy: 0.7879\n",
            "Epoch 268/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7747 - val_loss: 0.4527 - val_accuracy: 0.7879\n",
            "Epoch 269/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4839 - accuracy: 0.7691 - val_loss: 0.4527 - val_accuracy: 0.7879\n",
            "Epoch 270/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4838 - accuracy: 0.7709 - val_loss: 0.4526 - val_accuracy: 0.7879\n",
            "Epoch 271/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4837 - accuracy: 0.7691 - val_loss: 0.4525 - val_accuracy: 0.7879\n",
            "Epoch 272/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4836 - accuracy: 0.7672 - val_loss: 0.4524 - val_accuracy: 0.7879\n",
            "Epoch 273/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4835 - accuracy: 0.7691 - val_loss: 0.4524 - val_accuracy: 0.7879\n",
            "Epoch 274/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4833 - accuracy: 0.7691 - val_loss: 0.4524 - val_accuracy: 0.7879\n",
            "Epoch 275/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4834 - accuracy: 0.7691 - val_loss: 0.4523 - val_accuracy: 0.7879\n",
            "Epoch 276/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4833 - accuracy: 0.7691 - val_loss: 0.4522 - val_accuracy: 0.7879\n",
            "Epoch 277/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4831 - accuracy: 0.7672 - val_loss: 0.4521 - val_accuracy: 0.7879\n",
            "Epoch 278/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4830 - accuracy: 0.7691 - val_loss: 0.4521 - val_accuracy: 0.7879\n",
            "Epoch 279/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4830 - accuracy: 0.7672 - val_loss: 0.4520 - val_accuracy: 0.7879\n",
            "Epoch 280/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4828 - accuracy: 0.7691 - val_loss: 0.4520 - val_accuracy: 0.7879\n",
            "Epoch 281/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4827 - accuracy: 0.7672 - val_loss: 0.4519 - val_accuracy: 0.7879\n",
            "Epoch 282/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4826 - accuracy: 0.7691 - val_loss: 0.4518 - val_accuracy: 0.7835\n",
            "Epoch 283/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4825 - accuracy: 0.7691 - val_loss: 0.4518 - val_accuracy: 0.7835\n",
            "Epoch 284/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4824 - accuracy: 0.7691 - val_loss: 0.4517 - val_accuracy: 0.7835\n",
            "Epoch 285/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4824 - accuracy: 0.7691 - val_loss: 0.4517 - val_accuracy: 0.7835\n",
            "Epoch 286/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4823 - accuracy: 0.7672 - val_loss: 0.4516 - val_accuracy: 0.7835\n",
            "Epoch 287/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4822 - accuracy: 0.7709 - val_loss: 0.4515 - val_accuracy: 0.7879\n",
            "Epoch 288/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4820 - accuracy: 0.7709 - val_loss: 0.4515 - val_accuracy: 0.7835\n",
            "Epoch 289/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4821 - accuracy: 0.7691 - val_loss: 0.4515 - val_accuracy: 0.7835\n",
            "Epoch 290/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.7709 - val_loss: 0.4514 - val_accuracy: 0.7835\n",
            "Epoch 291/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4818 - accuracy: 0.7691 - val_loss: 0.4514 - val_accuracy: 0.7835\n",
            "Epoch 292/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4817 - accuracy: 0.7709 - val_loss: 0.4513 - val_accuracy: 0.7835\n",
            "Epoch 293/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4816 - accuracy: 0.7709 - val_loss: 0.4511 - val_accuracy: 0.7835\n",
            "Epoch 294/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.7691 - val_loss: 0.4510 - val_accuracy: 0.7835\n",
            "Epoch 295/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4815 - accuracy: 0.7728 - val_loss: 0.4508 - val_accuracy: 0.7879\n",
            "Epoch 296/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4814 - accuracy: 0.7709 - val_loss: 0.4509 - val_accuracy: 0.7879\n",
            "Epoch 297/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4813 - accuracy: 0.7709 - val_loss: 0.4508 - val_accuracy: 0.7879\n",
            "Epoch 298/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4811 - accuracy: 0.7709 - val_loss: 0.4508 - val_accuracy: 0.7835\n",
            "Epoch 299/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4812 - accuracy: 0.7709 - val_loss: 0.4508 - val_accuracy: 0.7835\n",
            "Epoch 300/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4810 - accuracy: 0.7709 - val_loss: 0.4508 - val_accuracy: 0.7835\n",
            "Epoch 301/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4809 - accuracy: 0.7728 - val_loss: 0.4509 - val_accuracy: 0.7835\n",
            "Epoch 302/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4808 - accuracy: 0.7709 - val_loss: 0.4508 - val_accuracy: 0.7835\n",
            "Epoch 303/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4809 - accuracy: 0.7709 - val_loss: 0.4507 - val_accuracy: 0.7835\n",
            "Epoch 304/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4806 - accuracy: 0.7728 - val_loss: 0.4507 - val_accuracy: 0.7835\n",
            "Epoch 305/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4806 - accuracy: 0.7728 - val_loss: 0.4507 - val_accuracy: 0.7835\n",
            "Epoch 306/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4805 - accuracy: 0.7747 - val_loss: 0.4507 - val_accuracy: 0.7835\n",
            "Epoch 307/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4804 - accuracy: 0.7728 - val_loss: 0.4506 - val_accuracy: 0.7835\n",
            "Epoch 308/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4803 - accuracy: 0.7728 - val_loss: 0.4506 - val_accuracy: 0.7835\n",
            "Epoch 309/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4803 - accuracy: 0.7728 - val_loss: 0.4504 - val_accuracy: 0.7835\n",
            "Epoch 310/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4801 - accuracy: 0.7784 - val_loss: 0.4504 - val_accuracy: 0.7879\n",
            "Epoch 311/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4801 - accuracy: 0.7747 - val_loss: 0.4505 - val_accuracy: 0.7879\n",
            "Epoch 312/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4800 - accuracy: 0.7765 - val_loss: 0.4503 - val_accuracy: 0.7879\n",
            "Epoch 313/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4799 - accuracy: 0.7747 - val_loss: 0.4502 - val_accuracy: 0.7835\n",
            "Epoch 314/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.7747 - val_loss: 0.4503 - val_accuracy: 0.7835\n",
            "Epoch 315/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4797 - accuracy: 0.7765 - val_loss: 0.4502 - val_accuracy: 0.7835\n",
            "Epoch 316/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4796 - accuracy: 0.7728 - val_loss: 0.4501 - val_accuracy: 0.7835\n",
            "Epoch 317/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4796 - accuracy: 0.7747 - val_loss: 0.4501 - val_accuracy: 0.7835\n",
            "Epoch 318/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4796 - accuracy: 0.7747 - val_loss: 0.4500 - val_accuracy: 0.7835\n",
            "Epoch 319/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4794 - accuracy: 0.7747 - val_loss: 0.4499 - val_accuracy: 0.7835\n",
            "Epoch 320/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4792 - accuracy: 0.7765 - val_loss: 0.4497 - val_accuracy: 0.7835\n",
            "Epoch 321/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4792 - accuracy: 0.7728 - val_loss: 0.4497 - val_accuracy: 0.7835\n",
            "Epoch 322/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4791 - accuracy: 0.7765 - val_loss: 0.4497 - val_accuracy: 0.7835\n",
            "Epoch 323/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4791 - accuracy: 0.7765 - val_loss: 0.4496 - val_accuracy: 0.7835\n",
            "Epoch 324/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4790 - accuracy: 0.7747 - val_loss: 0.4494 - val_accuracy: 0.7879\n",
            "Epoch 325/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4789 - accuracy: 0.7728 - val_loss: 0.4494 - val_accuracy: 0.7879\n",
            "Epoch 326/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.7747 - val_loss: 0.4493 - val_accuracy: 0.7879\n",
            "Epoch 327/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4789 - accuracy: 0.7747 - val_loss: 0.4494 - val_accuracy: 0.7879\n",
            "Epoch 328/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4787 - accuracy: 0.7728 - val_loss: 0.4494 - val_accuracy: 0.7879\n",
            "Epoch 329/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4785 - accuracy: 0.7691 - val_loss: 0.4493 - val_accuracy: 0.7879\n",
            "Epoch 330/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4785 - accuracy: 0.7728 - val_loss: 0.4492 - val_accuracy: 0.7879\n",
            "Epoch 331/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4785 - accuracy: 0.7747 - val_loss: 0.4491 - val_accuracy: 0.7879\n",
            "Epoch 332/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4785 - accuracy: 0.7747 - val_loss: 0.4492 - val_accuracy: 0.7879\n",
            "Epoch 333/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4783 - accuracy: 0.7747 - val_loss: 0.4491 - val_accuracy: 0.7879\n",
            "Epoch 334/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4782 - accuracy: 0.7747 - val_loss: 0.4492 - val_accuracy: 0.7879\n",
            "Epoch 335/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.7747 - val_loss: 0.4491 - val_accuracy: 0.7879\n",
            "Epoch 336/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4781 - accuracy: 0.7747 - val_loss: 0.4489 - val_accuracy: 0.7879\n",
            "Epoch 337/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4780 - accuracy: 0.7747 - val_loss: 0.4488 - val_accuracy: 0.7879\n",
            "Epoch 338/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.7728 - val_loss: 0.4488 - val_accuracy: 0.7879\n",
            "Epoch 339/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7747 - val_loss: 0.4487 - val_accuracy: 0.7835\n",
            "Epoch 340/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7747 - val_loss: 0.4487 - val_accuracy: 0.7835\n",
            "Epoch 341/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4777 - accuracy: 0.7709 - val_loss: 0.4487 - val_accuracy: 0.7835\n",
            "Epoch 342/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4776 - accuracy: 0.7747 - val_loss: 0.4488 - val_accuracy: 0.7835\n",
            "Epoch 343/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.7709 - val_loss: 0.4488 - val_accuracy: 0.7835\n",
            "Epoch 344/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4774 - accuracy: 0.7747 - val_loss: 0.4487 - val_accuracy: 0.7835\n",
            "Epoch 345/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4773 - accuracy: 0.7747 - val_loss: 0.4485 - val_accuracy: 0.7835\n",
            "Epoch 346/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4773 - accuracy: 0.7747 - val_loss: 0.4485 - val_accuracy: 0.7835\n",
            "Epoch 347/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4772 - accuracy: 0.7747 - val_loss: 0.4483 - val_accuracy: 0.7835\n",
            "Epoch 348/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4771 - accuracy: 0.7728 - val_loss: 0.4482 - val_accuracy: 0.7835\n",
            "Epoch 349/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4771 - accuracy: 0.7709 - val_loss: 0.4482 - val_accuracy: 0.7835\n",
            "Epoch 350/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4771 - accuracy: 0.7728 - val_loss: 0.4482 - val_accuracy: 0.7835\n",
            "Epoch 351/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4769 - accuracy: 0.7747 - val_loss: 0.4481 - val_accuracy: 0.7835\n",
            "Epoch 352/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4769 - accuracy: 0.7728 - val_loss: 0.4481 - val_accuracy: 0.7792\n",
            "Epoch 353/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4768 - accuracy: 0.7728 - val_loss: 0.4480 - val_accuracy: 0.7792\n",
            "Epoch 354/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4767 - accuracy: 0.7765 - val_loss: 0.4480 - val_accuracy: 0.7749\n",
            "Epoch 355/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4767 - accuracy: 0.7765 - val_loss: 0.4479 - val_accuracy: 0.7749\n",
            "Epoch 356/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4766 - accuracy: 0.7728 - val_loss: 0.4478 - val_accuracy: 0.7749\n",
            "Epoch 357/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.7728 - val_loss: 0.4478 - val_accuracy: 0.7749\n",
            "Epoch 358/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7765 - val_loss: 0.4476 - val_accuracy: 0.7749\n",
            "Epoch 359/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.7765 - val_loss: 0.4475 - val_accuracy: 0.7749\n",
            "Epoch 360/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4764 - accuracy: 0.7728 - val_loss: 0.4476 - val_accuracy: 0.7792\n",
            "Epoch 361/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4762 - accuracy: 0.7747 - val_loss: 0.4475 - val_accuracy: 0.7749\n",
            "Epoch 362/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4762 - accuracy: 0.7728 - val_loss: 0.4475 - val_accuracy: 0.7749\n",
            "Epoch 363/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4761 - accuracy: 0.7747 - val_loss: 0.4475 - val_accuracy: 0.7792\n",
            "Epoch 364/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4760 - accuracy: 0.7747 - val_loss: 0.4474 - val_accuracy: 0.7792\n",
            "Epoch 365/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4759 - accuracy: 0.7765 - val_loss: 0.4475 - val_accuracy: 0.7792\n",
            "Epoch 366/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4759 - accuracy: 0.7747 - val_loss: 0.4475 - val_accuracy: 0.7792\n",
            "Epoch 367/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4758 - accuracy: 0.7747 - val_loss: 0.4477 - val_accuracy: 0.7835\n",
            "Epoch 368/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4758 - accuracy: 0.7747 - val_loss: 0.4476 - val_accuracy: 0.7835\n",
            "Epoch 369/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4756 - accuracy: 0.7747 - val_loss: 0.4474 - val_accuracy: 0.7835\n",
            "Epoch 370/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4756 - accuracy: 0.7765 - val_loss: 0.4474 - val_accuracy: 0.7792\n",
            "Epoch 371/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4754 - accuracy: 0.7747 - val_loss: 0.4473 - val_accuracy: 0.7749\n",
            "Epoch 372/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4754 - accuracy: 0.7747 - val_loss: 0.4473 - val_accuracy: 0.7792\n",
            "Epoch 373/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4755 - accuracy: 0.7728 - val_loss: 0.4472 - val_accuracy: 0.7792\n",
            "Epoch 374/500\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.4754 - accuracy: 0.7747 - val_loss: 0.4471 - val_accuracy: 0.7792\n",
            "Epoch 375/500\n",
            "17/17 [==============================] - 0s 31ms/step - loss: 0.4753 - accuracy: 0.7728 - val_loss: 0.4471 - val_accuracy: 0.7792\n",
            "Epoch 376/500\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 0.4753 - accuracy: 0.7728 - val_loss: 0.4471 - val_accuracy: 0.7792\n",
            "Epoch 377/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4753 - accuracy: 0.7747 - val_loss: 0.4469 - val_accuracy: 0.7749\n",
            "Epoch 378/500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4751 - accuracy: 0.7747 - val_loss: 0.4470 - val_accuracy: 0.7749\n",
            "Epoch 379/500\n",
            "17/17 [==============================] - 1s 36ms/step - loss: 0.4750 - accuracy: 0.7765 - val_loss: 0.4469 - val_accuracy: 0.7749\n",
            "Epoch 380/500\n",
            "17/17 [==============================] - 0s 26ms/step - loss: 0.4750 - accuracy: 0.7728 - val_loss: 0.4470 - val_accuracy: 0.7749\n",
            "Epoch 381/500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4750 - accuracy: 0.7747 - val_loss: 0.4470 - val_accuracy: 0.7792\n",
            "Epoch 382/500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4748 - accuracy: 0.7747 - val_loss: 0.4470 - val_accuracy: 0.7749\n",
            "Epoch 383/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4748 - accuracy: 0.7747 - val_loss: 0.4469 - val_accuracy: 0.7749\n",
            "Epoch 384/500\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.4748 - accuracy: 0.7747 - val_loss: 0.4470 - val_accuracy: 0.7749\n",
            "Epoch 385/500\n",
            "17/17 [==============================] - 1s 36ms/step - loss: 0.4747 - accuracy: 0.7765 - val_loss: 0.4469 - val_accuracy: 0.7792\n",
            "Epoch 386/500\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.4746 - accuracy: 0.7765 - val_loss: 0.4467 - val_accuracy: 0.7749\n",
            "Epoch 387/500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4746 - accuracy: 0.7728 - val_loss: 0.4469 - val_accuracy: 0.7792\n",
            "Epoch 388/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4746 - accuracy: 0.7747 - val_loss: 0.4468 - val_accuracy: 0.7792\n",
            "Epoch 389/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4745 - accuracy: 0.7728 - val_loss: 0.4469 - val_accuracy: 0.7792\n",
            "Epoch 390/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4744 - accuracy: 0.7728 - val_loss: 0.4469 - val_accuracy: 0.7792\n",
            "Epoch 391/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4744 - accuracy: 0.7747 - val_loss: 0.4470 - val_accuracy: 0.7792\n",
            "Epoch 392/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4743 - accuracy: 0.7728 - val_loss: 0.4469 - val_accuracy: 0.7792\n",
            "Epoch 393/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4743 - accuracy: 0.7747 - val_loss: 0.4470 - val_accuracy: 0.7749\n",
            "Epoch 394/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4742 - accuracy: 0.7747 - val_loss: 0.4470 - val_accuracy: 0.7749\n",
            "Epoch 395/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4742 - accuracy: 0.7765 - val_loss: 0.4471 - val_accuracy: 0.7749\n",
            "Epoch 396/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4742 - accuracy: 0.7747 - val_loss: 0.4471 - val_accuracy: 0.7749\n",
            "Epoch 397/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4741 - accuracy: 0.7728 - val_loss: 0.4469 - val_accuracy: 0.7749\n",
            "Epoch 398/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7747 - val_loss: 0.4468 - val_accuracy: 0.7749\n",
            "Epoch 399/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4740 - accuracy: 0.7747 - val_loss: 0.4469 - val_accuracy: 0.7749\n",
            "Epoch 400/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4738 - accuracy: 0.7747 - val_loss: 0.4468 - val_accuracy: 0.7749\n",
            "Epoch 401/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7728 - val_loss: 0.4467 - val_accuracy: 0.7749\n",
            "Epoch 402/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7747 - val_loss: 0.4467 - val_accuracy: 0.7749\n",
            "Epoch 403/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4737 - accuracy: 0.7728 - val_loss: 0.4466 - val_accuracy: 0.7749\n",
            "Epoch 404/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4736 - accuracy: 0.7709 - val_loss: 0.4466 - val_accuracy: 0.7749\n",
            "Epoch 405/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.7728 - val_loss: 0.4466 - val_accuracy: 0.7749\n",
            "Epoch 406/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4736 - accuracy: 0.7728 - val_loss: 0.4466 - val_accuracy: 0.7749\n",
            "Epoch 407/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4735 - accuracy: 0.7728 - val_loss: 0.4465 - val_accuracy: 0.7749\n",
            "Epoch 408/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4734 - accuracy: 0.7709 - val_loss: 0.4465 - val_accuracy: 0.7749\n",
            "Epoch 409/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4734 - accuracy: 0.7728 - val_loss: 0.4464 - val_accuracy: 0.7749\n",
            "Epoch 410/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4733 - accuracy: 0.7709 - val_loss: 0.4465 - val_accuracy: 0.7749\n",
            "Epoch 411/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4733 - accuracy: 0.7709 - val_loss: 0.4464 - val_accuracy: 0.7749\n",
            "Epoch 412/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4732 - accuracy: 0.7728 - val_loss: 0.4464 - val_accuracy: 0.7749\n",
            "Epoch 413/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4731 - accuracy: 0.7709 - val_loss: 0.4465 - val_accuracy: 0.7749\n",
            "Epoch 414/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.7747 - val_loss: 0.4466 - val_accuracy: 0.7792\n",
            "Epoch 415/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4730 - accuracy: 0.7728 - val_loss: 0.4465 - val_accuracy: 0.7792\n",
            "Epoch 416/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4730 - accuracy: 0.7728 - val_loss: 0.4467 - val_accuracy: 0.7792\n",
            "Epoch 417/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4729 - accuracy: 0.7728 - val_loss: 0.4465 - val_accuracy: 0.7792\n",
            "Epoch 418/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4728 - accuracy: 0.7728 - val_loss: 0.4464 - val_accuracy: 0.7792\n",
            "Epoch 419/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4728 - accuracy: 0.7709 - val_loss: 0.4465 - val_accuracy: 0.7792\n",
            "Epoch 420/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4728 - accuracy: 0.7709 - val_loss: 0.4465 - val_accuracy: 0.7792\n",
            "Epoch 421/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4728 - accuracy: 0.7709 - val_loss: 0.4466 - val_accuracy: 0.7792\n",
            "Epoch 422/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4727 - accuracy: 0.7728 - val_loss: 0.4464 - val_accuracy: 0.7792\n",
            "Epoch 423/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4726 - accuracy: 0.7728 - val_loss: 0.4463 - val_accuracy: 0.7749\n",
            "Epoch 424/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4727 - accuracy: 0.7728 - val_loss: 0.4462 - val_accuracy: 0.7749\n",
            "Epoch 425/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4725 - accuracy: 0.7709 - val_loss: 0.4461 - val_accuracy: 0.7749\n",
            "Epoch 426/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4725 - accuracy: 0.7709 - val_loss: 0.4460 - val_accuracy: 0.7749\n",
            "Epoch 427/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7709 - val_loss: 0.4460 - val_accuracy: 0.7749\n",
            "Epoch 428/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4724 - accuracy: 0.7709 - val_loss: 0.4460 - val_accuracy: 0.7749\n",
            "Epoch 429/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4724 - accuracy: 0.7709 - val_loss: 0.4460 - val_accuracy: 0.7749\n",
            "Epoch 430/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4723 - accuracy: 0.7709 - val_loss: 0.4461 - val_accuracy: 0.7749\n",
            "Epoch 431/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7709 - val_loss: 0.4461 - val_accuracy: 0.7749\n",
            "Epoch 432/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4723 - accuracy: 0.7709 - val_loss: 0.4461 - val_accuracy: 0.7792\n",
            "Epoch 433/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7747 - val_loss: 0.4459 - val_accuracy: 0.7792\n",
            "Epoch 434/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4720 - accuracy: 0.7709 - val_loss: 0.4459 - val_accuracy: 0.7792\n",
            "Epoch 435/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4719 - accuracy: 0.7765 - val_loss: 0.4458 - val_accuracy: 0.7792\n",
            "Epoch 436/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4720 - accuracy: 0.7728 - val_loss: 0.4458 - val_accuracy: 0.7792\n",
            "Epoch 437/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4719 - accuracy: 0.7747 - val_loss: 0.4458 - val_accuracy: 0.7792\n",
            "Epoch 438/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4719 - accuracy: 0.7728 - val_loss: 0.4458 - val_accuracy: 0.7792\n",
            "Epoch 439/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4719 - accuracy: 0.7728 - val_loss: 0.4458 - val_accuracy: 0.7792\n",
            "Epoch 440/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4718 - accuracy: 0.7709 - val_loss: 0.4459 - val_accuracy: 0.7792\n",
            "Epoch 441/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4717 - accuracy: 0.7728 - val_loss: 0.4459 - val_accuracy: 0.7792\n",
            "Epoch 442/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4716 - accuracy: 0.7728 - val_loss: 0.4459 - val_accuracy: 0.7792\n",
            "Epoch 443/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4717 - accuracy: 0.7765 - val_loss: 0.4458 - val_accuracy: 0.7792\n",
            "Epoch 444/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4715 - accuracy: 0.7728 - val_loss: 0.4458 - val_accuracy: 0.7792\n",
            "Epoch 445/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4715 - accuracy: 0.7728 - val_loss: 0.4459 - val_accuracy: 0.7792\n",
            "Epoch 446/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.7747 - val_loss: 0.4458 - val_accuracy: 0.7792\n",
            "Epoch 447/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7747 - val_loss: 0.4457 - val_accuracy: 0.7792\n",
            "Epoch 448/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.7747 - val_loss: 0.4456 - val_accuracy: 0.7792\n",
            "Epoch 449/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7728 - val_loss: 0.4456 - val_accuracy: 0.7792\n",
            "Epoch 450/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4713 - accuracy: 0.7747 - val_loss: 0.4457 - val_accuracy: 0.7792\n",
            "Epoch 451/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4713 - accuracy: 0.7747 - val_loss: 0.4457 - val_accuracy: 0.7792\n",
            "Epoch 452/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4712 - accuracy: 0.7747 - val_loss: 0.4459 - val_accuracy: 0.7792\n",
            "Epoch 453/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.7765 - val_loss: 0.4460 - val_accuracy: 0.7792\n",
            "Epoch 454/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7709 - val_loss: 0.4460 - val_accuracy: 0.7792\n",
            "Epoch 455/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4710 - accuracy: 0.7765 - val_loss: 0.4460 - val_accuracy: 0.7792\n",
            "Epoch 456/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4710 - accuracy: 0.7765 - val_loss: 0.4460 - val_accuracy: 0.7792\n",
            "Epoch 457/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.7728 - val_loss: 0.4460 - val_accuracy: 0.7792\n",
            "Epoch 458/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4708 - accuracy: 0.7747 - val_loss: 0.4458 - val_accuracy: 0.7792\n",
            "Epoch 459/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.7765 - val_loss: 0.4457 - val_accuracy: 0.7792\n",
            "Epoch 460/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7765 - val_loss: 0.4457 - val_accuracy: 0.7792\n",
            "Epoch 461/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4707 - accuracy: 0.7765 - val_loss: 0.4455 - val_accuracy: 0.7792\n",
            "Epoch 462/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4706 - accuracy: 0.7765 - val_loss: 0.4454 - val_accuracy: 0.7792\n",
            "Epoch 463/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4705 - accuracy: 0.7747 - val_loss: 0.4456 - val_accuracy: 0.7792\n",
            "Epoch 464/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4707 - accuracy: 0.7709 - val_loss: 0.4456 - val_accuracy: 0.7792\n",
            "Epoch 465/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4704 - accuracy: 0.7765 - val_loss: 0.4456 - val_accuracy: 0.7792\n",
            "Epoch 466/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7765 - val_loss: 0.4455 - val_accuracy: 0.7792\n",
            "Epoch 467/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4704 - accuracy: 0.7747 - val_loss: 0.4455 - val_accuracy: 0.7792\n",
            "Epoch 468/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4703 - accuracy: 0.7765 - val_loss: 0.4456 - val_accuracy: 0.7792\n",
            "Epoch 469/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7747 - val_loss: 0.4456 - val_accuracy: 0.7792\n",
            "Epoch 470/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4703 - accuracy: 0.7747 - val_loss: 0.4456 - val_accuracy: 0.7792\n",
            "Epoch 471/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.7784 - val_loss: 0.4455 - val_accuracy: 0.7792\n",
            "Epoch 472/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4702 - accuracy: 0.7765 - val_loss: 0.4456 - val_accuracy: 0.7792\n",
            "Epoch 473/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4701 - accuracy: 0.7784 - val_loss: 0.4456 - val_accuracy: 0.7792\n",
            "Epoch 474/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4700 - accuracy: 0.7765 - val_loss: 0.4455 - val_accuracy: 0.7835\n",
            "Epoch 475/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4701 - accuracy: 0.7784 - val_loss: 0.4455 - val_accuracy: 0.7835\n",
            "Epoch 476/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4699 - accuracy: 0.7747 - val_loss: 0.4455 - val_accuracy: 0.7835\n",
            "Epoch 477/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4699 - accuracy: 0.7784 - val_loss: 0.4454 - val_accuracy: 0.7835\n",
            "Epoch 478/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4700 - accuracy: 0.7784 - val_loss: 0.4455 - val_accuracy: 0.7835\n",
            "Epoch 479/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4697 - accuracy: 0.7784 - val_loss: 0.4455 - val_accuracy: 0.7792\n",
            "Epoch 480/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4698 - accuracy: 0.7765 - val_loss: 0.4456 - val_accuracy: 0.7792\n",
            "Epoch 481/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.7765 - val_loss: 0.4454 - val_accuracy: 0.7792\n",
            "Epoch 482/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4697 - accuracy: 0.7784 - val_loss: 0.4454 - val_accuracy: 0.7792\n",
            "Epoch 483/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7765 - val_loss: 0.4455 - val_accuracy: 0.7792\n",
            "Epoch 484/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7765 - val_loss: 0.4455 - val_accuracy: 0.7792\n",
            "Epoch 485/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7784 - val_loss: 0.4456 - val_accuracy: 0.7792\n",
            "Epoch 486/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4695 - accuracy: 0.7765 - val_loss: 0.4455 - val_accuracy: 0.7792\n",
            "Epoch 487/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4695 - accuracy: 0.7784 - val_loss: 0.4455 - val_accuracy: 0.7792\n",
            "Epoch 488/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.7784 - val_loss: 0.4455 - val_accuracy: 0.7792\n",
            "Epoch 489/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4693 - accuracy: 0.7784 - val_loss: 0.4456 - val_accuracy: 0.7792\n",
            "Epoch 490/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7784 - val_loss: 0.4455 - val_accuracy: 0.7792\n",
            "Epoch 491/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7784 - val_loss: 0.4454 - val_accuracy: 0.7792\n",
            "Epoch 492/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7784 - val_loss: 0.4453 - val_accuracy: 0.7792\n",
            "Epoch 493/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4694 - accuracy: 0.7765 - val_loss: 0.4453 - val_accuracy: 0.7835\n",
            "Epoch 494/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4691 - accuracy: 0.7784 - val_loss: 0.4453 - val_accuracy: 0.7792\n",
            "Epoch 495/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4691 - accuracy: 0.7784 - val_loss: 0.4451 - val_accuracy: 0.7835\n",
            "Epoch 496/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4690 - accuracy: 0.7747 - val_loss: 0.4451 - val_accuracy: 0.7835\n",
            "Epoch 497/500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.7784 - val_loss: 0.4450 - val_accuracy: 0.7835\n",
            "Epoch 498/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4689 - accuracy: 0.7784 - val_loss: 0.4451 - val_accuracy: 0.7835\n",
            "Epoch 499/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4688 - accuracy: 0.7784 - val_loss: 0.4450 - val_accuracy: 0.7835\n",
            "Epoch 500/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4688 - accuracy: 0.7784 - val_loss: 0.4451 - val_accuracy: 0.7835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5.compile(SGD(lr = .005), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_5= model5.fit(x2_train_norm, y2_train, validation_data=(x2_test_norm, y2_test), epochs=1500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApQnZ0q6Tfl0",
        "outputId": "3cb24b51-5bbd-4c9e-c39e-05f4c2603303"
      },
      "id": "ApQnZ0q6Tfl0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1500\n",
            "17/17 [==============================] - 1s 16ms/step - loss: 0.8608 - accuracy: 0.3743 - val_loss: 0.8332 - val_accuracy: 0.3550\n",
            "Epoch 2/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.8109 - accuracy: 0.3799 - val_loss: 0.7912 - val_accuracy: 0.4026\n",
            "Epoch 3/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.7756 - accuracy: 0.4004 - val_loss: 0.7618 - val_accuracy: 0.4156\n",
            "Epoch 4/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.7500 - accuracy: 0.4432 - val_loss: 0.7408 - val_accuracy: 0.4242\n",
            "Epoch 5/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.7322 - accuracy: 0.4581 - val_loss: 0.7251 - val_accuracy: 0.4545\n",
            "Epoch 6/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.7186 - accuracy: 0.4879 - val_loss: 0.7121 - val_accuracy: 0.4935\n",
            "Epoch 7/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.7076 - accuracy: 0.5158 - val_loss: 0.7020 - val_accuracy: 0.5195\n",
            "Epoch 8/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6988 - accuracy: 0.5438 - val_loss: 0.6936 - val_accuracy: 0.5498\n",
            "Epoch 9/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6915 - accuracy: 0.5736 - val_loss: 0.6865 - val_accuracy: 0.5628\n",
            "Epoch 10/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6855 - accuracy: 0.5903 - val_loss: 0.6804 - val_accuracy: 0.5887\n",
            "Epoch 11/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6805 - accuracy: 0.6089 - val_loss: 0.6752 - val_accuracy: 0.6190\n",
            "Epoch 12/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6761 - accuracy: 0.6276 - val_loss: 0.6706 - val_accuracy: 0.6623\n",
            "Epoch 13/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6724 - accuracy: 0.6331 - val_loss: 0.6664 - val_accuracy: 0.6883\n",
            "Epoch 14/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6689 - accuracy: 0.6499 - val_loss: 0.6626 - val_accuracy: 0.6926\n",
            "Epoch 15/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6658 - accuracy: 0.6443 - val_loss: 0.6590 - val_accuracy: 0.7056\n",
            "Epoch 16/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6629 - accuracy: 0.6592 - val_loss: 0.6558 - val_accuracy: 0.7100\n",
            "Epoch 17/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6602 - accuracy: 0.6648 - val_loss: 0.6527 - val_accuracy: 0.7143\n",
            "Epoch 18/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6577 - accuracy: 0.6741 - val_loss: 0.6498 - val_accuracy: 0.7186\n",
            "Epoch 19/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6553 - accuracy: 0.6778 - val_loss: 0.6471 - val_accuracy: 0.7229\n",
            "Epoch 20/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6531 - accuracy: 0.6816 - val_loss: 0.6446 - val_accuracy: 0.7273\n",
            "Epoch 21/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6510 - accuracy: 0.6797 - val_loss: 0.6422 - val_accuracy: 0.7316\n",
            "Epoch 22/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6491 - accuracy: 0.6872 - val_loss: 0.6398 - val_accuracy: 0.7316\n",
            "Epoch 23/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6471 - accuracy: 0.6853 - val_loss: 0.6375 - val_accuracy: 0.7273\n",
            "Epoch 24/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6453 - accuracy: 0.6853 - val_loss: 0.6353 - val_accuracy: 0.7316\n",
            "Epoch 25/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6436 - accuracy: 0.6816 - val_loss: 0.6331 - val_accuracy: 0.7316\n",
            "Epoch 26/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6418 - accuracy: 0.6797 - val_loss: 0.6310 - val_accuracy: 0.7359\n",
            "Epoch 27/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6401 - accuracy: 0.6834 - val_loss: 0.6290 - val_accuracy: 0.7403\n",
            "Epoch 28/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6385 - accuracy: 0.6872 - val_loss: 0.6271 - val_accuracy: 0.7403\n",
            "Epoch 29/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6369 - accuracy: 0.6890 - val_loss: 0.6252 - val_accuracy: 0.7403\n",
            "Epoch 30/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6353 - accuracy: 0.6946 - val_loss: 0.6233 - val_accuracy: 0.7446\n",
            "Epoch 31/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6338 - accuracy: 0.6946 - val_loss: 0.6215 - val_accuracy: 0.7446\n",
            "Epoch 32/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6323 - accuracy: 0.6946 - val_loss: 0.6196 - val_accuracy: 0.7489\n",
            "Epoch 33/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6308 - accuracy: 0.7020 - val_loss: 0.6177 - val_accuracy: 0.7576\n",
            "Epoch 34/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6293 - accuracy: 0.7020 - val_loss: 0.6158 - val_accuracy: 0.7576\n",
            "Epoch 35/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6279 - accuracy: 0.7002 - val_loss: 0.6140 - val_accuracy: 0.7576\n",
            "Epoch 36/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6265 - accuracy: 0.7020 - val_loss: 0.6122 - val_accuracy: 0.7576\n",
            "Epoch 37/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6251 - accuracy: 0.7039 - val_loss: 0.6104 - val_accuracy: 0.7619\n",
            "Epoch 38/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6236 - accuracy: 0.7058 - val_loss: 0.6086 - val_accuracy: 0.7576\n",
            "Epoch 39/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6222 - accuracy: 0.7076 - val_loss: 0.6069 - val_accuracy: 0.7662\n",
            "Epoch 40/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6206 - accuracy: 0.7076 - val_loss: 0.6051 - val_accuracy: 0.7706\n",
            "Epoch 41/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6190 - accuracy: 0.7058 - val_loss: 0.6032 - val_accuracy: 0.7749\n",
            "Epoch 42/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6173 - accuracy: 0.7095 - val_loss: 0.6013 - val_accuracy: 0.7792\n",
            "Epoch 43/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6156 - accuracy: 0.7076 - val_loss: 0.5994 - val_accuracy: 0.7792\n",
            "Epoch 44/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6139 - accuracy: 0.7076 - val_loss: 0.5974 - val_accuracy: 0.7792\n",
            "Epoch 45/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6123 - accuracy: 0.7076 - val_loss: 0.5955 - val_accuracy: 0.7792\n",
            "Epoch 46/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6106 - accuracy: 0.7095 - val_loss: 0.5937 - val_accuracy: 0.7792\n",
            "Epoch 47/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6089 - accuracy: 0.7151 - val_loss: 0.5919 - val_accuracy: 0.7792\n",
            "Epoch 48/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6072 - accuracy: 0.7169 - val_loss: 0.5901 - val_accuracy: 0.7835\n",
            "Epoch 49/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6055 - accuracy: 0.7188 - val_loss: 0.5884 - val_accuracy: 0.7835\n",
            "Epoch 50/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6038 - accuracy: 0.7188 - val_loss: 0.5868 - val_accuracy: 0.7835\n",
            "Epoch 51/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6022 - accuracy: 0.7151 - val_loss: 0.5852 - val_accuracy: 0.7835\n",
            "Epoch 52/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6006 - accuracy: 0.7207 - val_loss: 0.5836 - val_accuracy: 0.7879\n",
            "Epoch 53/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5991 - accuracy: 0.7188 - val_loss: 0.5820 - val_accuracy: 0.7879\n",
            "Epoch 54/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5974 - accuracy: 0.7207 - val_loss: 0.5805 - val_accuracy: 0.7879\n",
            "Epoch 55/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5958 - accuracy: 0.7263 - val_loss: 0.5789 - val_accuracy: 0.7879\n",
            "Epoch 56/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5942 - accuracy: 0.7244 - val_loss: 0.5774 - val_accuracy: 0.7879\n",
            "Epoch 57/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5927 - accuracy: 0.7244 - val_loss: 0.5759 - val_accuracy: 0.7879\n",
            "Epoch 58/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5913 - accuracy: 0.7263 - val_loss: 0.5745 - val_accuracy: 0.7792\n",
            "Epoch 59/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5898 - accuracy: 0.7300 - val_loss: 0.5730 - val_accuracy: 0.7749\n",
            "Epoch 60/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5884 - accuracy: 0.7300 - val_loss: 0.5716 - val_accuracy: 0.7749\n",
            "Epoch 61/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5870 - accuracy: 0.7356 - val_loss: 0.5702 - val_accuracy: 0.7749\n",
            "Epoch 62/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5857 - accuracy: 0.7374 - val_loss: 0.5690 - val_accuracy: 0.7749\n",
            "Epoch 63/1500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.5845 - accuracy: 0.7412 - val_loss: 0.5677 - val_accuracy: 0.7749\n",
            "Epoch 64/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5832 - accuracy: 0.7393 - val_loss: 0.5665 - val_accuracy: 0.7749\n",
            "Epoch 65/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5820 - accuracy: 0.7412 - val_loss: 0.5653 - val_accuracy: 0.7749\n",
            "Epoch 66/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5808 - accuracy: 0.7430 - val_loss: 0.5641 - val_accuracy: 0.7749\n",
            "Epoch 67/1500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.5796 - accuracy: 0.7412 - val_loss: 0.5630 - val_accuracy: 0.7706\n",
            "Epoch 68/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.5784 - accuracy: 0.7412 - val_loss: 0.5619 - val_accuracy: 0.7706\n",
            "Epoch 69/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5772 - accuracy: 0.7412 - val_loss: 0.5608 - val_accuracy: 0.7706\n",
            "Epoch 70/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5761 - accuracy: 0.7412 - val_loss: 0.5597 - val_accuracy: 0.7662\n",
            "Epoch 71/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5750 - accuracy: 0.7430 - val_loss: 0.5586 - val_accuracy: 0.7662\n",
            "Epoch 72/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5740 - accuracy: 0.7449 - val_loss: 0.5576 - val_accuracy: 0.7662\n",
            "Epoch 73/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5729 - accuracy: 0.7449 - val_loss: 0.5565 - val_accuracy: 0.7706\n",
            "Epoch 74/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5719 - accuracy: 0.7430 - val_loss: 0.5555 - val_accuracy: 0.7706\n",
            "Epoch 75/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5709 - accuracy: 0.7430 - val_loss: 0.5545 - val_accuracy: 0.7706\n",
            "Epoch 76/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5699 - accuracy: 0.7430 - val_loss: 0.5536 - val_accuracy: 0.7749\n",
            "Epoch 77/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5689 - accuracy: 0.7449 - val_loss: 0.5526 - val_accuracy: 0.7749\n",
            "Epoch 78/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.5679 - accuracy: 0.7430 - val_loss: 0.5517 - val_accuracy: 0.7749\n",
            "Epoch 79/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5670 - accuracy: 0.7467 - val_loss: 0.5508 - val_accuracy: 0.7749\n",
            "Epoch 80/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5661 - accuracy: 0.7449 - val_loss: 0.5499 - val_accuracy: 0.7749\n",
            "Epoch 81/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5651 - accuracy: 0.7467 - val_loss: 0.5491 - val_accuracy: 0.7792\n",
            "Epoch 82/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5642 - accuracy: 0.7467 - val_loss: 0.5483 - val_accuracy: 0.7792\n",
            "Epoch 83/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.5634 - accuracy: 0.7467 - val_loss: 0.5474 - val_accuracy: 0.7792\n",
            "Epoch 84/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5626 - accuracy: 0.7449 - val_loss: 0.5466 - val_accuracy: 0.7792\n",
            "Epoch 85/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5618 - accuracy: 0.7467 - val_loss: 0.5459 - val_accuracy: 0.7792\n",
            "Epoch 86/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5610 - accuracy: 0.7486 - val_loss: 0.5451 - val_accuracy: 0.7792\n",
            "Epoch 87/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5602 - accuracy: 0.7486 - val_loss: 0.5444 - val_accuracy: 0.7792\n",
            "Epoch 88/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5594 - accuracy: 0.7505 - val_loss: 0.5437 - val_accuracy: 0.7792\n",
            "Epoch 89/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5587 - accuracy: 0.7486 - val_loss: 0.5430 - val_accuracy: 0.7792\n",
            "Epoch 90/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5579 - accuracy: 0.7467 - val_loss: 0.5422 - val_accuracy: 0.7792\n",
            "Epoch 91/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5571 - accuracy: 0.7486 - val_loss: 0.5416 - val_accuracy: 0.7792\n",
            "Epoch 92/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5564 - accuracy: 0.7486 - val_loss: 0.5409 - val_accuracy: 0.7792\n",
            "Epoch 93/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5557 - accuracy: 0.7467 - val_loss: 0.5403 - val_accuracy: 0.7792\n",
            "Epoch 94/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5549 - accuracy: 0.7467 - val_loss: 0.5396 - val_accuracy: 0.7792\n",
            "Epoch 95/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5542 - accuracy: 0.7505 - val_loss: 0.5390 - val_accuracy: 0.7792\n",
            "Epoch 96/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5535 - accuracy: 0.7467 - val_loss: 0.5385 - val_accuracy: 0.7792\n",
            "Epoch 97/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5529 - accuracy: 0.7486 - val_loss: 0.5379 - val_accuracy: 0.7792\n",
            "Epoch 98/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5522 - accuracy: 0.7486 - val_loss: 0.5374 - val_accuracy: 0.7792\n",
            "Epoch 99/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5516 - accuracy: 0.7486 - val_loss: 0.5368 - val_accuracy: 0.7835\n",
            "Epoch 100/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5510 - accuracy: 0.7486 - val_loss: 0.5363 - val_accuracy: 0.7835\n",
            "Epoch 101/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5503 - accuracy: 0.7467 - val_loss: 0.5358 - val_accuracy: 0.7835\n",
            "Epoch 102/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5497 - accuracy: 0.7467 - val_loss: 0.5353 - val_accuracy: 0.7835\n",
            "Epoch 103/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5491 - accuracy: 0.7467 - val_loss: 0.5348 - val_accuracy: 0.7879\n",
            "Epoch 104/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5486 - accuracy: 0.7467 - val_loss: 0.5344 - val_accuracy: 0.7879\n",
            "Epoch 105/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5479 - accuracy: 0.7467 - val_loss: 0.5339 - val_accuracy: 0.7879\n",
            "Epoch 106/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5474 - accuracy: 0.7467 - val_loss: 0.5334 - val_accuracy: 0.7879\n",
            "Epoch 107/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5468 - accuracy: 0.7467 - val_loss: 0.5330 - val_accuracy: 0.7879\n",
            "Epoch 108/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5464 - accuracy: 0.7467 - val_loss: 0.5325 - val_accuracy: 0.7879\n",
            "Epoch 109/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5458 - accuracy: 0.7467 - val_loss: 0.5321 - val_accuracy: 0.7879\n",
            "Epoch 110/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5452 - accuracy: 0.7467 - val_loss: 0.5317 - val_accuracy: 0.7879\n",
            "Epoch 111/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5447 - accuracy: 0.7449 - val_loss: 0.5313 - val_accuracy: 0.7922\n",
            "Epoch 112/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5441 - accuracy: 0.7449 - val_loss: 0.5309 - val_accuracy: 0.7922\n",
            "Epoch 113/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5437 - accuracy: 0.7449 - val_loss: 0.5305 - val_accuracy: 0.7922\n",
            "Epoch 114/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5432 - accuracy: 0.7430 - val_loss: 0.5301 - val_accuracy: 0.7922\n",
            "Epoch 115/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5428 - accuracy: 0.7430 - val_loss: 0.5297 - val_accuracy: 0.7922\n",
            "Epoch 116/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5422 - accuracy: 0.7430 - val_loss: 0.5293 - val_accuracy: 0.7922\n",
            "Epoch 117/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5418 - accuracy: 0.7430 - val_loss: 0.5289 - val_accuracy: 0.7922\n",
            "Epoch 118/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5413 - accuracy: 0.7449 - val_loss: 0.5285 - val_accuracy: 0.7922\n",
            "Epoch 119/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5409 - accuracy: 0.7430 - val_loss: 0.5281 - val_accuracy: 0.7922\n",
            "Epoch 120/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5404 - accuracy: 0.7449 - val_loss: 0.5278 - val_accuracy: 0.7965\n",
            "Epoch 121/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5400 - accuracy: 0.7449 - val_loss: 0.5274 - val_accuracy: 0.7965\n",
            "Epoch 122/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5396 - accuracy: 0.7449 - val_loss: 0.5271 - val_accuracy: 0.7922\n",
            "Epoch 123/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5392 - accuracy: 0.7449 - val_loss: 0.5268 - val_accuracy: 0.7922\n",
            "Epoch 124/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5387 - accuracy: 0.7412 - val_loss: 0.5265 - val_accuracy: 0.7965\n",
            "Epoch 125/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.7467 - val_loss: 0.5261 - val_accuracy: 0.7965\n",
            "Epoch 126/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5378 - accuracy: 0.7430 - val_loss: 0.5258 - val_accuracy: 0.7965\n",
            "Epoch 127/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5374 - accuracy: 0.7430 - val_loss: 0.5255 - val_accuracy: 0.7965\n",
            "Epoch 128/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5371 - accuracy: 0.7430 - val_loss: 0.5252 - val_accuracy: 0.7965\n",
            "Epoch 129/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5367 - accuracy: 0.7449 - val_loss: 0.5249 - val_accuracy: 0.7965\n",
            "Epoch 130/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5364 - accuracy: 0.7449 - val_loss: 0.5246 - val_accuracy: 0.7965\n",
            "Epoch 131/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5359 - accuracy: 0.7412 - val_loss: 0.5243 - val_accuracy: 0.7965\n",
            "Epoch 132/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5356 - accuracy: 0.7430 - val_loss: 0.5239 - val_accuracy: 0.7965\n",
            "Epoch 133/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5351 - accuracy: 0.7412 - val_loss: 0.5236 - val_accuracy: 0.7922\n",
            "Epoch 134/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5348 - accuracy: 0.7412 - val_loss: 0.5233 - val_accuracy: 0.7922\n",
            "Epoch 135/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5345 - accuracy: 0.7412 - val_loss: 0.5230 - val_accuracy: 0.7922\n",
            "Epoch 136/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5342 - accuracy: 0.7412 - val_loss: 0.5227 - val_accuracy: 0.7922\n",
            "Epoch 137/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.7430 - val_loss: 0.5224 - val_accuracy: 0.7879\n",
            "Epoch 138/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5335 - accuracy: 0.7430 - val_loss: 0.5221 - val_accuracy: 0.7879\n",
            "Epoch 139/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7430 - val_loss: 0.5218 - val_accuracy: 0.7922\n",
            "Epoch 140/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5327 - accuracy: 0.7430 - val_loss: 0.5215 - val_accuracy: 0.7922\n",
            "Epoch 141/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5324 - accuracy: 0.7430 - val_loss: 0.5212 - val_accuracy: 0.7922\n",
            "Epoch 142/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5321 - accuracy: 0.7449 - val_loss: 0.5209 - val_accuracy: 0.7922\n",
            "Epoch 143/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5318 - accuracy: 0.7449 - val_loss: 0.5207 - val_accuracy: 0.7922\n",
            "Epoch 144/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5314 - accuracy: 0.7449 - val_loss: 0.5204 - val_accuracy: 0.7922\n",
            "Epoch 145/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5311 - accuracy: 0.7467 - val_loss: 0.5201 - val_accuracy: 0.7922\n",
            "Epoch 146/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5308 - accuracy: 0.7467 - val_loss: 0.5199 - val_accuracy: 0.7922\n",
            "Epoch 147/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5306 - accuracy: 0.7467 - val_loss: 0.5196 - val_accuracy: 0.7922\n",
            "Epoch 148/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5302 - accuracy: 0.7467 - val_loss: 0.5193 - val_accuracy: 0.7922\n",
            "Epoch 149/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5299 - accuracy: 0.7486 - val_loss: 0.5191 - val_accuracy: 0.7922\n",
            "Epoch 150/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5295 - accuracy: 0.7467 - val_loss: 0.5189 - val_accuracy: 0.7922\n",
            "Epoch 151/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5293 - accuracy: 0.7467 - val_loss: 0.5187 - val_accuracy: 0.7922\n",
            "Epoch 152/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.7486 - val_loss: 0.5185 - val_accuracy: 0.7922\n",
            "Epoch 153/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5287 - accuracy: 0.7486 - val_loss: 0.5182 - val_accuracy: 0.7922\n",
            "Epoch 154/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5284 - accuracy: 0.7486 - val_loss: 0.5180 - val_accuracy: 0.7922\n",
            "Epoch 155/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.7486 - val_loss: 0.5178 - val_accuracy: 0.7922\n",
            "Epoch 156/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.7486 - val_loss: 0.5176 - val_accuracy: 0.7922\n",
            "Epoch 157/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5275 - accuracy: 0.7486 - val_loss: 0.5174 - val_accuracy: 0.7922\n",
            "Epoch 158/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5272 - accuracy: 0.7486 - val_loss: 0.5172 - val_accuracy: 0.7922\n",
            "Epoch 159/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5270 - accuracy: 0.7486 - val_loss: 0.5170 - val_accuracy: 0.7922\n",
            "Epoch 160/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5267 - accuracy: 0.7486 - val_loss: 0.5168 - val_accuracy: 0.7922\n",
            "Epoch 161/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5265 - accuracy: 0.7486 - val_loss: 0.5166 - val_accuracy: 0.7922\n",
            "Epoch 162/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5262 - accuracy: 0.7486 - val_loss: 0.5164 - val_accuracy: 0.7922\n",
            "Epoch 163/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5259 - accuracy: 0.7486 - val_loss: 0.5162 - val_accuracy: 0.7922\n",
            "Epoch 164/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5257 - accuracy: 0.7486 - val_loss: 0.5160 - val_accuracy: 0.7922\n",
            "Epoch 165/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.7486 - val_loss: 0.5158 - val_accuracy: 0.7922\n",
            "Epoch 166/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5251 - accuracy: 0.7486 - val_loss: 0.5156 - val_accuracy: 0.7922\n",
            "Epoch 167/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5250 - accuracy: 0.7486 - val_loss: 0.5155 - val_accuracy: 0.7922\n",
            "Epoch 168/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5246 - accuracy: 0.7486 - val_loss: 0.5153 - val_accuracy: 0.7922\n",
            "Epoch 169/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5245 - accuracy: 0.7505 - val_loss: 0.5151 - val_accuracy: 0.7922\n",
            "Epoch 170/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5242 - accuracy: 0.7486 - val_loss: 0.5149 - val_accuracy: 0.7922\n",
            "Epoch 171/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5239 - accuracy: 0.7486 - val_loss: 0.5148 - val_accuracy: 0.7922\n",
            "Epoch 172/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5238 - accuracy: 0.7523 - val_loss: 0.5146 - val_accuracy: 0.7922\n",
            "Epoch 173/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5235 - accuracy: 0.7505 - val_loss: 0.5144 - val_accuracy: 0.7922\n",
            "Epoch 174/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5233 - accuracy: 0.7523 - val_loss: 0.5142 - val_accuracy: 0.7922\n",
            "Epoch 175/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5230 - accuracy: 0.7486 - val_loss: 0.5140 - val_accuracy: 0.7922\n",
            "Epoch 176/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5229 - accuracy: 0.7505 - val_loss: 0.5138 - val_accuracy: 0.7922\n",
            "Epoch 177/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5226 - accuracy: 0.7486 - val_loss: 0.5137 - val_accuracy: 0.7922\n",
            "Epoch 178/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5223 - accuracy: 0.7486 - val_loss: 0.5135 - val_accuracy: 0.7922\n",
            "Epoch 179/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5220 - accuracy: 0.7505 - val_loss: 0.5134 - val_accuracy: 0.7965\n",
            "Epoch 180/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5218 - accuracy: 0.7505 - val_loss: 0.5132 - val_accuracy: 0.7965\n",
            "Epoch 181/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5217 - accuracy: 0.7486 - val_loss: 0.5130 - val_accuracy: 0.7965\n",
            "Epoch 182/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5214 - accuracy: 0.7505 - val_loss: 0.5129 - val_accuracy: 0.7965\n",
            "Epoch 183/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5212 - accuracy: 0.7505 - val_loss: 0.5127 - val_accuracy: 0.7965\n",
            "Epoch 184/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5210 - accuracy: 0.7505 - val_loss: 0.5126 - val_accuracy: 0.7922\n",
            "Epoch 185/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5208 - accuracy: 0.7505 - val_loss: 0.5124 - val_accuracy: 0.7922\n",
            "Epoch 186/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5205 - accuracy: 0.7505 - val_loss: 0.5123 - val_accuracy: 0.7922\n",
            "Epoch 187/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5204 - accuracy: 0.7505 - val_loss: 0.5121 - val_accuracy: 0.7922\n",
            "Epoch 188/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5201 - accuracy: 0.7523 - val_loss: 0.5120 - val_accuracy: 0.7922\n",
            "Epoch 189/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5199 - accuracy: 0.7505 - val_loss: 0.5118 - val_accuracy: 0.7922\n",
            "Epoch 190/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5197 - accuracy: 0.7542 - val_loss: 0.5116 - val_accuracy: 0.7922\n",
            "Epoch 191/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5194 - accuracy: 0.7542 - val_loss: 0.5115 - val_accuracy: 0.7922\n",
            "Epoch 192/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5192 - accuracy: 0.7542 - val_loss: 0.5113 - val_accuracy: 0.7965\n",
            "Epoch 193/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.7542 - val_loss: 0.5111 - val_accuracy: 0.7965\n",
            "Epoch 194/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5188 - accuracy: 0.7561 - val_loss: 0.5109 - val_accuracy: 0.7965\n",
            "Epoch 195/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5186 - accuracy: 0.7542 - val_loss: 0.5108 - val_accuracy: 0.7965\n",
            "Epoch 196/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5183 - accuracy: 0.7561 - val_loss: 0.5106 - val_accuracy: 0.7965\n",
            "Epoch 197/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5181 - accuracy: 0.7561 - val_loss: 0.5104 - val_accuracy: 0.7965\n",
            "Epoch 198/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5180 - accuracy: 0.7561 - val_loss: 0.5103 - val_accuracy: 0.7965\n",
            "Epoch 199/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5177 - accuracy: 0.7561 - val_loss: 0.5101 - val_accuracy: 0.7965\n",
            "Epoch 200/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5174 - accuracy: 0.7561 - val_loss: 0.5100 - val_accuracy: 0.7965\n",
            "Epoch 201/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5173 - accuracy: 0.7561 - val_loss: 0.5098 - val_accuracy: 0.7965\n",
            "Epoch 202/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5170 - accuracy: 0.7561 - val_loss: 0.5097 - val_accuracy: 0.7965\n",
            "Epoch 203/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5169 - accuracy: 0.7561 - val_loss: 0.5095 - val_accuracy: 0.7965\n",
            "Epoch 204/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5167 - accuracy: 0.7561 - val_loss: 0.5093 - val_accuracy: 0.7965\n",
            "Epoch 205/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5165 - accuracy: 0.7561 - val_loss: 0.5092 - val_accuracy: 0.7965\n",
            "Epoch 206/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5163 - accuracy: 0.7579 - val_loss: 0.5090 - val_accuracy: 0.7965\n",
            "Epoch 207/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5161 - accuracy: 0.7598 - val_loss: 0.5089 - val_accuracy: 0.7965\n",
            "Epoch 208/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.5160 - accuracy: 0.7579 - val_loss: 0.5087 - val_accuracy: 0.7965\n",
            "Epoch 209/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5158 - accuracy: 0.7598 - val_loss: 0.5086 - val_accuracy: 0.7965\n",
            "Epoch 210/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5156 - accuracy: 0.7579 - val_loss: 0.5084 - val_accuracy: 0.7965\n",
            "Epoch 211/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5154 - accuracy: 0.7616 - val_loss: 0.5082 - val_accuracy: 0.7965\n",
            "Epoch 212/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5152 - accuracy: 0.7598 - val_loss: 0.5081 - val_accuracy: 0.7965\n",
            "Epoch 213/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5150 - accuracy: 0.7598 - val_loss: 0.5080 - val_accuracy: 0.7965\n",
            "Epoch 214/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5150 - accuracy: 0.7616 - val_loss: 0.5079 - val_accuracy: 0.7965\n",
            "Epoch 215/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5146 - accuracy: 0.7616 - val_loss: 0.5077 - val_accuracy: 0.7922\n",
            "Epoch 216/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5146 - accuracy: 0.7598 - val_loss: 0.5076 - val_accuracy: 0.7922\n",
            "Epoch 217/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5143 - accuracy: 0.7616 - val_loss: 0.5074 - val_accuracy: 0.7922\n",
            "Epoch 218/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5142 - accuracy: 0.7635 - val_loss: 0.5073 - val_accuracy: 0.7922\n",
            "Epoch 219/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.5140 - accuracy: 0.7616 - val_loss: 0.5072 - val_accuracy: 0.7922\n",
            "Epoch 220/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5139 - accuracy: 0.7635 - val_loss: 0.5071 - val_accuracy: 0.7922\n",
            "Epoch 221/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5137 - accuracy: 0.7635 - val_loss: 0.5069 - val_accuracy: 0.7922\n",
            "Epoch 222/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5135 - accuracy: 0.7616 - val_loss: 0.5068 - val_accuracy: 0.7922\n",
            "Epoch 223/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5133 - accuracy: 0.7635 - val_loss: 0.5067 - val_accuracy: 0.7922\n",
            "Epoch 224/1500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.5131 - accuracy: 0.7616 - val_loss: 0.5066 - val_accuracy: 0.7922\n",
            "Epoch 225/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5131 - accuracy: 0.7616 - val_loss: 0.5065 - val_accuracy: 0.7922\n",
            "Epoch 226/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5130 - accuracy: 0.7616 - val_loss: 0.5064 - val_accuracy: 0.7922\n",
            "Epoch 227/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5127 - accuracy: 0.7616 - val_loss: 0.5063 - val_accuracy: 0.7922\n",
            "Epoch 228/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5128 - accuracy: 0.7616 - val_loss: 0.5061 - val_accuracy: 0.7922\n",
            "Epoch 229/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5126 - accuracy: 0.7616 - val_loss: 0.5060 - val_accuracy: 0.7922\n",
            "Epoch 230/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5123 - accuracy: 0.7616 - val_loss: 0.5059 - val_accuracy: 0.7922\n",
            "Epoch 231/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5122 - accuracy: 0.7579 - val_loss: 0.5058 - val_accuracy: 0.7922\n",
            "Epoch 232/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.7616 - val_loss: 0.5058 - val_accuracy: 0.7922\n",
            "Epoch 233/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5119 - accuracy: 0.7598 - val_loss: 0.5057 - val_accuracy: 0.7922\n",
            "Epoch 234/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5118 - accuracy: 0.7598 - val_loss: 0.5056 - val_accuracy: 0.7922\n",
            "Epoch 235/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5116 - accuracy: 0.7616 - val_loss: 0.5054 - val_accuracy: 0.7922\n",
            "Epoch 236/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5116 - accuracy: 0.7616 - val_loss: 0.5053 - val_accuracy: 0.7922\n",
            "Epoch 237/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.7598 - val_loss: 0.5053 - val_accuracy: 0.7922\n",
            "Epoch 238/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5114 - accuracy: 0.7598 - val_loss: 0.5051 - val_accuracy: 0.7922\n",
            "Epoch 239/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5111 - accuracy: 0.7635 - val_loss: 0.5050 - val_accuracy: 0.7922\n",
            "Epoch 240/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5111 - accuracy: 0.7598 - val_loss: 0.5049 - val_accuracy: 0.7922\n",
            "Epoch 241/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5108 - accuracy: 0.7598 - val_loss: 0.5048 - val_accuracy: 0.7922\n",
            "Epoch 242/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5107 - accuracy: 0.7616 - val_loss: 0.5048 - val_accuracy: 0.7922\n",
            "Epoch 243/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5106 - accuracy: 0.7579 - val_loss: 0.5047 - val_accuracy: 0.7922\n",
            "Epoch 244/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5105 - accuracy: 0.7598 - val_loss: 0.5046 - val_accuracy: 0.7922\n",
            "Epoch 245/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5103 - accuracy: 0.7598 - val_loss: 0.5046 - val_accuracy: 0.7922\n",
            "Epoch 246/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5102 - accuracy: 0.7616 - val_loss: 0.5045 - val_accuracy: 0.7922\n",
            "Epoch 247/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5101 - accuracy: 0.7616 - val_loss: 0.5044 - val_accuracy: 0.7922\n",
            "Epoch 248/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5100 - accuracy: 0.7579 - val_loss: 0.5043 - val_accuracy: 0.7922\n",
            "Epoch 249/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5097 - accuracy: 0.7598 - val_loss: 0.5042 - val_accuracy: 0.7965\n",
            "Epoch 250/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5096 - accuracy: 0.7598 - val_loss: 0.5041 - val_accuracy: 0.7965\n",
            "Epoch 251/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5095 - accuracy: 0.7616 - val_loss: 0.5041 - val_accuracy: 0.7965\n",
            "Epoch 252/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5094 - accuracy: 0.7598 - val_loss: 0.5040 - val_accuracy: 0.7965\n",
            "Epoch 253/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5092 - accuracy: 0.7579 - val_loss: 0.5039 - val_accuracy: 0.7965\n",
            "Epoch 254/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7616 - val_loss: 0.5039 - val_accuracy: 0.7965\n",
            "Epoch 255/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.7579 - val_loss: 0.5038 - val_accuracy: 0.7965\n",
            "Epoch 256/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5088 - accuracy: 0.7598 - val_loss: 0.5037 - val_accuracy: 0.7965\n",
            "Epoch 257/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5087 - accuracy: 0.7616 - val_loss: 0.5037 - val_accuracy: 0.7965\n",
            "Epoch 258/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5085 - accuracy: 0.7579 - val_loss: 0.5036 - val_accuracy: 0.7965\n",
            "Epoch 259/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5085 - accuracy: 0.7579 - val_loss: 0.5035 - val_accuracy: 0.7965\n",
            "Epoch 260/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7579 - val_loss: 0.5035 - val_accuracy: 0.7965\n",
            "Epoch 261/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5083 - accuracy: 0.7579 - val_loss: 0.5034 - val_accuracy: 0.7965\n",
            "Epoch 262/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5081 - accuracy: 0.7598 - val_loss: 0.5034 - val_accuracy: 0.7965\n",
            "Epoch 263/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5080 - accuracy: 0.7598 - val_loss: 0.5033 - val_accuracy: 0.7965\n",
            "Epoch 264/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.7598 - val_loss: 0.5033 - val_accuracy: 0.7965\n",
            "Epoch 265/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.7598 - val_loss: 0.5032 - val_accuracy: 0.7965\n",
            "Epoch 266/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5077 - accuracy: 0.7579 - val_loss: 0.5032 - val_accuracy: 0.7965\n",
            "Epoch 267/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5075 - accuracy: 0.7579 - val_loss: 0.5032 - val_accuracy: 0.7965\n",
            "Epoch 268/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.7579 - val_loss: 0.5031 - val_accuracy: 0.7965\n",
            "Epoch 269/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.7579 - val_loss: 0.5030 - val_accuracy: 0.7965\n",
            "Epoch 270/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7579 - val_loss: 0.5030 - val_accuracy: 0.7965\n",
            "Epoch 271/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5071 - accuracy: 0.7579 - val_loss: 0.5029 - val_accuracy: 0.7965\n",
            "Epoch 272/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5071 - accuracy: 0.7598 - val_loss: 0.5029 - val_accuracy: 0.7965\n",
            "Epoch 273/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7579 - val_loss: 0.5028 - val_accuracy: 0.7965\n",
            "Epoch 274/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5068 - accuracy: 0.7598 - val_loss: 0.5027 - val_accuracy: 0.7965\n",
            "Epoch 275/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5067 - accuracy: 0.7598 - val_loss: 0.5027 - val_accuracy: 0.7965\n",
            "Epoch 276/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7598 - val_loss: 0.5027 - val_accuracy: 0.7965\n",
            "Epoch 277/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7579 - val_loss: 0.5026 - val_accuracy: 0.7965\n",
            "Epoch 278/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7579 - val_loss: 0.5026 - val_accuracy: 0.7965\n",
            "Epoch 279/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7579 - val_loss: 0.5025 - val_accuracy: 0.7965\n",
            "Epoch 280/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7579 - val_loss: 0.5024 - val_accuracy: 0.7965\n",
            "Epoch 281/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7598 - val_loss: 0.5024 - val_accuracy: 0.7965\n",
            "Epoch 282/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7579 - val_loss: 0.5023 - val_accuracy: 0.7965\n",
            "Epoch 283/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7598 - val_loss: 0.5022 - val_accuracy: 0.7965\n",
            "Epoch 284/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7598 - val_loss: 0.5022 - val_accuracy: 0.7965\n",
            "Epoch 285/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7598 - val_loss: 0.5021 - val_accuracy: 0.7965\n",
            "Epoch 286/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7616 - val_loss: 0.5021 - val_accuracy: 0.7965\n",
            "Epoch 287/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7598 - val_loss: 0.5020 - val_accuracy: 0.7965\n",
            "Epoch 288/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5054 - accuracy: 0.7598 - val_loss: 0.5019 - val_accuracy: 0.7965\n",
            "Epoch 289/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7598 - val_loss: 0.5019 - val_accuracy: 0.7965\n",
            "Epoch 290/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5053 - accuracy: 0.7579 - val_loss: 0.5018 - val_accuracy: 0.7965\n",
            "Epoch 291/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5051 - accuracy: 0.7579 - val_loss: 0.5017 - val_accuracy: 0.7965\n",
            "Epoch 292/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7598 - val_loss: 0.5017 - val_accuracy: 0.7965\n",
            "Epoch 293/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7579 - val_loss: 0.5017 - val_accuracy: 0.7965\n",
            "Epoch 294/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7579 - val_loss: 0.5016 - val_accuracy: 0.7965\n",
            "Epoch 295/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7598 - val_loss: 0.5015 - val_accuracy: 0.7965\n",
            "Epoch 296/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7616 - val_loss: 0.5015 - val_accuracy: 0.7965\n",
            "Epoch 297/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5045 - accuracy: 0.7616 - val_loss: 0.5014 - val_accuracy: 0.7965\n",
            "Epoch 298/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7598 - val_loss: 0.5013 - val_accuracy: 0.7965\n",
            "Epoch 299/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5044 - accuracy: 0.7598 - val_loss: 0.5012 - val_accuracy: 0.7965\n",
            "Epoch 300/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5042 - accuracy: 0.7635 - val_loss: 0.5011 - val_accuracy: 0.7965\n",
            "Epoch 301/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7635 - val_loss: 0.5011 - val_accuracy: 0.7965\n",
            "Epoch 302/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5041 - accuracy: 0.7598 - val_loss: 0.5011 - val_accuracy: 0.7965\n",
            "Epoch 303/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7598 - val_loss: 0.5010 - val_accuracy: 0.7965\n",
            "Epoch 304/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7635 - val_loss: 0.5009 - val_accuracy: 0.7965\n",
            "Epoch 305/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7635 - val_loss: 0.5009 - val_accuracy: 0.7965\n",
            "Epoch 306/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5037 - accuracy: 0.7616 - val_loss: 0.5008 - val_accuracy: 0.7965\n",
            "Epoch 307/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5036 - accuracy: 0.7616 - val_loss: 0.5008 - val_accuracy: 0.7965\n",
            "Epoch 308/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5036 - accuracy: 0.7616 - val_loss: 0.5007 - val_accuracy: 0.7965\n",
            "Epoch 309/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7654 - val_loss: 0.5007 - val_accuracy: 0.7965\n",
            "Epoch 310/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5034 - accuracy: 0.7635 - val_loss: 0.5006 - val_accuracy: 0.7965\n",
            "Epoch 311/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7616 - val_loss: 0.5005 - val_accuracy: 0.7965\n",
            "Epoch 312/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7654 - val_loss: 0.5005 - val_accuracy: 0.7965\n",
            "Epoch 313/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5030 - accuracy: 0.7616 - val_loss: 0.5004 - val_accuracy: 0.7965\n",
            "Epoch 314/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5031 - accuracy: 0.7635 - val_loss: 0.5004 - val_accuracy: 0.7965\n",
            "Epoch 315/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7654 - val_loss: 0.5003 - val_accuracy: 0.7965\n",
            "Epoch 316/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.7635 - val_loss: 0.5002 - val_accuracy: 0.7965\n",
            "Epoch 317/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.7654 - val_loss: 0.5002 - val_accuracy: 0.7965\n",
            "Epoch 318/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7672 - val_loss: 0.5002 - val_accuracy: 0.7965\n",
            "Epoch 319/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5026 - accuracy: 0.7672 - val_loss: 0.5001 - val_accuracy: 0.7965\n",
            "Epoch 320/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7672 - val_loss: 0.5001 - val_accuracy: 0.7965\n",
            "Epoch 321/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7635 - val_loss: 0.5001 - val_accuracy: 0.7965\n",
            "Epoch 322/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5023 - accuracy: 0.7654 - val_loss: 0.5000 - val_accuracy: 0.8009\n",
            "Epoch 323/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5022 - accuracy: 0.7635 - val_loss: 0.5000 - val_accuracy: 0.8009\n",
            "Epoch 324/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.7672 - val_loss: 0.5000 - val_accuracy: 0.8009\n",
            "Epoch 325/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5021 - accuracy: 0.7672 - val_loss: 0.4999 - val_accuracy: 0.8009\n",
            "Epoch 326/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5020 - accuracy: 0.7672 - val_loss: 0.4999 - val_accuracy: 0.7965\n",
            "Epoch 327/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5019 - accuracy: 0.7654 - val_loss: 0.4998 - val_accuracy: 0.7965\n",
            "Epoch 328/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7654 - val_loss: 0.4998 - val_accuracy: 0.7965\n",
            "Epoch 329/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7635 - val_loss: 0.4997 - val_accuracy: 0.7965\n",
            "Epoch 330/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.7654 - val_loss: 0.4997 - val_accuracy: 0.7965\n",
            "Epoch 331/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5017 - accuracy: 0.7598 - val_loss: 0.4996 - val_accuracy: 0.7965\n",
            "Epoch 332/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5016 - accuracy: 0.7654 - val_loss: 0.4995 - val_accuracy: 0.8009\n",
            "Epoch 333/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7672 - val_loss: 0.4995 - val_accuracy: 0.8009\n",
            "Epoch 334/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.7654 - val_loss: 0.4994 - val_accuracy: 0.8009\n",
            "Epoch 335/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5014 - accuracy: 0.7654 - val_loss: 0.4994 - val_accuracy: 0.8009\n",
            "Epoch 336/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7654 - val_loss: 0.4993 - val_accuracy: 0.8009\n",
            "Epoch 337/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5012 - accuracy: 0.7672 - val_loss: 0.4992 - val_accuracy: 0.8009\n",
            "Epoch 338/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.7654 - val_loss: 0.4992 - val_accuracy: 0.8009\n",
            "Epoch 339/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5010 - accuracy: 0.7672 - val_loss: 0.4991 - val_accuracy: 0.8009\n",
            "Epoch 340/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5009 - accuracy: 0.7672 - val_loss: 0.4991 - val_accuracy: 0.8009\n",
            "Epoch 341/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5008 - accuracy: 0.7654 - val_loss: 0.4990 - val_accuracy: 0.8009\n",
            "Epoch 342/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5008 - accuracy: 0.7635 - val_loss: 0.4990 - val_accuracy: 0.8009\n",
            "Epoch 343/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5007 - accuracy: 0.7672 - val_loss: 0.4989 - val_accuracy: 0.8009\n",
            "Epoch 344/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5007 - accuracy: 0.7672 - val_loss: 0.4988 - val_accuracy: 0.8009\n",
            "Epoch 345/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.7654 - val_loss: 0.4987 - val_accuracy: 0.8009\n",
            "Epoch 346/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5004 - accuracy: 0.7654 - val_loss: 0.4987 - val_accuracy: 0.8009\n",
            "Epoch 347/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7635 - val_loss: 0.4987 - val_accuracy: 0.8009\n",
            "Epoch 348/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5003 - accuracy: 0.7672 - val_loss: 0.4986 - val_accuracy: 0.8009\n",
            "Epoch 349/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5003 - accuracy: 0.7672 - val_loss: 0.4985 - val_accuracy: 0.8009\n",
            "Epoch 350/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5003 - accuracy: 0.7635 - val_loss: 0.4985 - val_accuracy: 0.8009\n",
            "Epoch 351/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5002 - accuracy: 0.7654 - val_loss: 0.4984 - val_accuracy: 0.8009\n",
            "Epoch 352/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5001 - accuracy: 0.7635 - val_loss: 0.4983 - val_accuracy: 0.8009\n",
            "Epoch 353/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.7672 - val_loss: 0.4982 - val_accuracy: 0.8009\n",
            "Epoch 354/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4999 - accuracy: 0.7672 - val_loss: 0.4982 - val_accuracy: 0.8009\n",
            "Epoch 355/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4998 - accuracy: 0.7691 - val_loss: 0.4982 - val_accuracy: 0.8009\n",
            "Epoch 356/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4998 - accuracy: 0.7635 - val_loss: 0.4981 - val_accuracy: 0.8009\n",
            "Epoch 357/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4997 - accuracy: 0.7672 - val_loss: 0.4981 - val_accuracy: 0.8009\n",
            "Epoch 358/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4996 - accuracy: 0.7672 - val_loss: 0.4980 - val_accuracy: 0.8009\n",
            "Epoch 359/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4994 - accuracy: 0.7672 - val_loss: 0.4980 - val_accuracy: 0.8009\n",
            "Epoch 360/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4995 - accuracy: 0.7672 - val_loss: 0.4980 - val_accuracy: 0.8009\n",
            "Epoch 361/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4993 - accuracy: 0.7635 - val_loss: 0.4979 - val_accuracy: 0.8009\n",
            "Epoch 362/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4992 - accuracy: 0.7691 - val_loss: 0.4979 - val_accuracy: 0.8009\n",
            "Epoch 363/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4991 - accuracy: 0.7654 - val_loss: 0.4979 - val_accuracy: 0.8009\n",
            "Epoch 364/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4991 - accuracy: 0.7654 - val_loss: 0.4978 - val_accuracy: 0.8009\n",
            "Epoch 365/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4991 - accuracy: 0.7691 - val_loss: 0.4978 - val_accuracy: 0.8009\n",
            "Epoch 366/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4992 - accuracy: 0.7691 - val_loss: 0.4978 - val_accuracy: 0.8009\n",
            "Epoch 367/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4989 - accuracy: 0.7672 - val_loss: 0.4977 - val_accuracy: 0.8009\n",
            "Epoch 368/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4988 - accuracy: 0.7672 - val_loss: 0.4977 - val_accuracy: 0.8009\n",
            "Epoch 369/1500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.4988 - accuracy: 0.7672 - val_loss: 0.4976 - val_accuracy: 0.8009\n",
            "Epoch 370/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4986 - accuracy: 0.7672 - val_loss: 0.4975 - val_accuracy: 0.8009\n",
            "Epoch 371/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4985 - accuracy: 0.7691 - val_loss: 0.4975 - val_accuracy: 0.8009\n",
            "Epoch 372/1500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.4985 - accuracy: 0.7691 - val_loss: 0.4975 - val_accuracy: 0.8009\n",
            "Epoch 373/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4985 - accuracy: 0.7672 - val_loss: 0.4975 - val_accuracy: 0.8009\n",
            "Epoch 374/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4983 - accuracy: 0.7672 - val_loss: 0.4974 - val_accuracy: 0.8009\n",
            "Epoch 375/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4983 - accuracy: 0.7654 - val_loss: 0.4974 - val_accuracy: 0.8009\n",
            "Epoch 376/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4982 - accuracy: 0.7654 - val_loss: 0.4973 - val_accuracy: 0.8009\n",
            "Epoch 377/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.7691 - val_loss: 0.4973 - val_accuracy: 0.8009\n",
            "Epoch 378/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4980 - accuracy: 0.7691 - val_loss: 0.4973 - val_accuracy: 0.8009\n",
            "Epoch 379/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4979 - accuracy: 0.7691 - val_loss: 0.4972 - val_accuracy: 0.8009\n",
            "Epoch 380/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4979 - accuracy: 0.7691 - val_loss: 0.4971 - val_accuracy: 0.8009\n",
            "Epoch 381/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4978 - accuracy: 0.7672 - val_loss: 0.4971 - val_accuracy: 0.8009\n",
            "Epoch 382/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4978 - accuracy: 0.7654 - val_loss: 0.4971 - val_accuracy: 0.8009\n",
            "Epoch 383/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4976 - accuracy: 0.7691 - val_loss: 0.4970 - val_accuracy: 0.8009\n",
            "Epoch 384/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.7672 - val_loss: 0.4970 - val_accuracy: 0.8009\n",
            "Epoch 385/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4975 - accuracy: 0.7691 - val_loss: 0.4970 - val_accuracy: 0.8009\n",
            "Epoch 386/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4975 - accuracy: 0.7672 - val_loss: 0.4969 - val_accuracy: 0.8009\n",
            "Epoch 387/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4973 - accuracy: 0.7691 - val_loss: 0.4969 - val_accuracy: 0.8009\n",
            "Epoch 388/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4973 - accuracy: 0.7672 - val_loss: 0.4969 - val_accuracy: 0.8009\n",
            "Epoch 389/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4972 - accuracy: 0.7672 - val_loss: 0.4968 - val_accuracy: 0.8009\n",
            "Epoch 390/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4970 - accuracy: 0.7672 - val_loss: 0.4968 - val_accuracy: 0.8009\n",
            "Epoch 391/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4971 - accuracy: 0.7672 - val_loss: 0.4967 - val_accuracy: 0.8009\n",
            "Epoch 392/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4969 - accuracy: 0.7672 - val_loss: 0.4967 - val_accuracy: 0.8009\n",
            "Epoch 393/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4969 - accuracy: 0.7672 - val_loss: 0.4967 - val_accuracy: 0.8009\n",
            "Epoch 394/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4968 - accuracy: 0.7672 - val_loss: 0.4966 - val_accuracy: 0.8009\n",
            "Epoch 395/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4966 - accuracy: 0.7691 - val_loss: 0.4965 - val_accuracy: 0.8009\n",
            "Epoch 396/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4966 - accuracy: 0.7691 - val_loss: 0.4965 - val_accuracy: 0.8009\n",
            "Epoch 397/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4966 - accuracy: 0.7691 - val_loss: 0.4965 - val_accuracy: 0.8009\n",
            "Epoch 398/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4963 - accuracy: 0.7672 - val_loss: 0.4965 - val_accuracy: 0.8009\n",
            "Epoch 399/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4964 - accuracy: 0.7672 - val_loss: 0.4965 - val_accuracy: 0.8009\n",
            "Epoch 400/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4962 - accuracy: 0.7672 - val_loss: 0.4964 - val_accuracy: 0.8009\n",
            "Epoch 401/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4962 - accuracy: 0.7691 - val_loss: 0.4964 - val_accuracy: 0.8009\n",
            "Epoch 402/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4961 - accuracy: 0.7709 - val_loss: 0.4964 - val_accuracy: 0.8009\n",
            "Epoch 403/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4960 - accuracy: 0.7691 - val_loss: 0.4963 - val_accuracy: 0.8009\n",
            "Epoch 404/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4959 - accuracy: 0.7672 - val_loss: 0.4964 - val_accuracy: 0.8009\n",
            "Epoch 405/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4960 - accuracy: 0.7672 - val_loss: 0.4964 - val_accuracy: 0.8009\n",
            "Epoch 406/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4957 - accuracy: 0.7672 - val_loss: 0.4964 - val_accuracy: 0.8009\n",
            "Epoch 407/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4957 - accuracy: 0.7672 - val_loss: 0.4963 - val_accuracy: 0.8009\n",
            "Epoch 408/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4955 - accuracy: 0.7709 - val_loss: 0.4963 - val_accuracy: 0.8009\n",
            "Epoch 409/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4955 - accuracy: 0.7709 - val_loss: 0.4962 - val_accuracy: 0.8009\n",
            "Epoch 410/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.7691 - val_loss: 0.4962 - val_accuracy: 0.8009\n",
            "Epoch 411/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4954 - accuracy: 0.7691 - val_loss: 0.4962 - val_accuracy: 0.8009\n",
            "Epoch 412/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4953 - accuracy: 0.7691 - val_loss: 0.4962 - val_accuracy: 0.8009\n",
            "Epoch 413/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4951 - accuracy: 0.7709 - val_loss: 0.4962 - val_accuracy: 0.8009\n",
            "Epoch 414/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4951 - accuracy: 0.7691 - val_loss: 0.4961 - val_accuracy: 0.8009\n",
            "Epoch 415/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4950 - accuracy: 0.7709 - val_loss: 0.4961 - val_accuracy: 0.8009\n",
            "Epoch 416/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4949 - accuracy: 0.7709 - val_loss: 0.4961 - val_accuracy: 0.8009\n",
            "Epoch 417/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4948 - accuracy: 0.7691 - val_loss: 0.4961 - val_accuracy: 0.8009\n",
            "Epoch 418/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4948 - accuracy: 0.7691 - val_loss: 0.4961 - val_accuracy: 0.8009\n",
            "Epoch 419/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4947 - accuracy: 0.7672 - val_loss: 0.4960 - val_accuracy: 0.8009\n",
            "Epoch 420/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4946 - accuracy: 0.7709 - val_loss: 0.4960 - val_accuracy: 0.8009\n",
            "Epoch 421/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4945 - accuracy: 0.7691 - val_loss: 0.4960 - val_accuracy: 0.7965\n",
            "Epoch 422/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4944 - accuracy: 0.7691 - val_loss: 0.4960 - val_accuracy: 0.7965\n",
            "Epoch 423/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4942 - accuracy: 0.7691 - val_loss: 0.4959 - val_accuracy: 0.7965\n",
            "Epoch 424/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4941 - accuracy: 0.7691 - val_loss: 0.4959 - val_accuracy: 0.7965\n",
            "Epoch 425/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4941 - accuracy: 0.7709 - val_loss: 0.4959 - val_accuracy: 0.7965\n",
            "Epoch 426/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4941 - accuracy: 0.7691 - val_loss: 0.4959 - val_accuracy: 0.7965\n",
            "Epoch 427/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4940 - accuracy: 0.7709 - val_loss: 0.4959 - val_accuracy: 0.7965\n",
            "Epoch 428/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4940 - accuracy: 0.7709 - val_loss: 0.4958 - val_accuracy: 0.7965\n",
            "Epoch 429/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4938 - accuracy: 0.7691 - val_loss: 0.4958 - val_accuracy: 0.7965\n",
            "Epoch 430/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4938 - accuracy: 0.7728 - val_loss: 0.4958 - val_accuracy: 0.7965\n",
            "Epoch 431/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4936 - accuracy: 0.7691 - val_loss: 0.4958 - val_accuracy: 0.7965\n",
            "Epoch 432/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4935 - accuracy: 0.7709 - val_loss: 0.4958 - val_accuracy: 0.7965\n",
            "Epoch 433/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4935 - accuracy: 0.7691 - val_loss: 0.4957 - val_accuracy: 0.7965\n",
            "Epoch 434/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4934 - accuracy: 0.7709 - val_loss: 0.4957 - val_accuracy: 0.7965\n",
            "Epoch 435/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4934 - accuracy: 0.7691 - val_loss: 0.4956 - val_accuracy: 0.7965\n",
            "Epoch 436/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4933 - accuracy: 0.7691 - val_loss: 0.4956 - val_accuracy: 0.7965\n",
            "Epoch 437/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4933 - accuracy: 0.7709 - val_loss: 0.4956 - val_accuracy: 0.7965\n",
            "Epoch 438/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4932 - accuracy: 0.7709 - val_loss: 0.4956 - val_accuracy: 0.7965\n",
            "Epoch 439/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4931 - accuracy: 0.7709 - val_loss: 0.4956 - val_accuracy: 0.7965\n",
            "Epoch 440/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4930 - accuracy: 0.7728 - val_loss: 0.4956 - val_accuracy: 0.7965\n",
            "Epoch 441/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4929 - accuracy: 0.7709 - val_loss: 0.4956 - val_accuracy: 0.7965\n",
            "Epoch 442/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4928 - accuracy: 0.7691 - val_loss: 0.4956 - val_accuracy: 0.7965\n",
            "Epoch 443/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4927 - accuracy: 0.7691 - val_loss: 0.4955 - val_accuracy: 0.7965\n",
            "Epoch 444/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4926 - accuracy: 0.7691 - val_loss: 0.4955 - val_accuracy: 0.7965\n",
            "Epoch 445/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4925 - accuracy: 0.7728 - val_loss: 0.4955 - val_accuracy: 0.7965\n",
            "Epoch 446/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4925 - accuracy: 0.7691 - val_loss: 0.4955 - val_accuracy: 0.7965\n",
            "Epoch 447/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4923 - accuracy: 0.7672 - val_loss: 0.4954 - val_accuracy: 0.7965\n",
            "Epoch 448/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4924 - accuracy: 0.7728 - val_loss: 0.4953 - val_accuracy: 0.7922\n",
            "Epoch 449/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4921 - accuracy: 0.7691 - val_loss: 0.4952 - val_accuracy: 0.7922\n",
            "Epoch 450/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4921 - accuracy: 0.7728 - val_loss: 0.4952 - val_accuracy: 0.7922\n",
            "Epoch 451/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4919 - accuracy: 0.7728 - val_loss: 0.4952 - val_accuracy: 0.7922\n",
            "Epoch 452/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4919 - accuracy: 0.7728 - val_loss: 0.4952 - val_accuracy: 0.7922\n",
            "Epoch 453/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4916 - accuracy: 0.7728 - val_loss: 0.4953 - val_accuracy: 0.7922\n",
            "Epoch 454/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4915 - accuracy: 0.7747 - val_loss: 0.4953 - val_accuracy: 0.7922\n",
            "Epoch 455/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4914 - accuracy: 0.7728 - val_loss: 0.4953 - val_accuracy: 0.7922\n",
            "Epoch 456/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4912 - accuracy: 0.7747 - val_loss: 0.4953 - val_accuracy: 0.7922\n",
            "Epoch 457/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4912 - accuracy: 0.7728 - val_loss: 0.4953 - val_accuracy: 0.7922\n",
            "Epoch 458/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4911 - accuracy: 0.7747 - val_loss: 0.4954 - val_accuracy: 0.7922\n",
            "Epoch 459/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4909 - accuracy: 0.7728 - val_loss: 0.4953 - val_accuracy: 0.7922\n",
            "Epoch 460/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4908 - accuracy: 0.7728 - val_loss: 0.4954 - val_accuracy: 0.7922\n",
            "Epoch 461/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4907 - accuracy: 0.7728 - val_loss: 0.4954 - val_accuracy: 0.7922\n",
            "Epoch 462/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4906 - accuracy: 0.7747 - val_loss: 0.4954 - val_accuracy: 0.7922\n",
            "Epoch 463/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4905 - accuracy: 0.7747 - val_loss: 0.4954 - val_accuracy: 0.7922\n",
            "Epoch 464/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4904 - accuracy: 0.7728 - val_loss: 0.4954 - val_accuracy: 0.7922\n",
            "Epoch 465/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4903 - accuracy: 0.7747 - val_loss: 0.4953 - val_accuracy: 0.7922\n",
            "Epoch 466/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4902 - accuracy: 0.7747 - val_loss: 0.4953 - val_accuracy: 0.7922\n",
            "Epoch 467/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4901 - accuracy: 0.7747 - val_loss: 0.4954 - val_accuracy: 0.7922\n",
            "Epoch 468/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4901 - accuracy: 0.7765 - val_loss: 0.4953 - val_accuracy: 0.7922\n",
            "Epoch 469/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4899 - accuracy: 0.7747 - val_loss: 0.4953 - val_accuracy: 0.7922\n",
            "Epoch 470/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4898 - accuracy: 0.7728 - val_loss: 0.4953 - val_accuracy: 0.7922\n",
            "Epoch 471/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4898 - accuracy: 0.7747 - val_loss: 0.4953 - val_accuracy: 0.7922\n",
            "Epoch 472/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4897 - accuracy: 0.7765 - val_loss: 0.4953 - val_accuracy: 0.7922\n",
            "Epoch 473/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4896 - accuracy: 0.7765 - val_loss: 0.4953 - val_accuracy: 0.7922\n",
            "Epoch 474/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4894 - accuracy: 0.7765 - val_loss: 0.4953 - val_accuracy: 0.7922\n",
            "Epoch 475/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4894 - accuracy: 0.7765 - val_loss: 0.4953 - val_accuracy: 0.7922\n",
            "Epoch 476/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4893 - accuracy: 0.7765 - val_loss: 0.4953 - val_accuracy: 0.7922\n",
            "Epoch 477/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4892 - accuracy: 0.7765 - val_loss: 0.4953 - val_accuracy: 0.7922\n",
            "Epoch 478/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4891 - accuracy: 0.7765 - val_loss: 0.4953 - val_accuracy: 0.7922\n",
            "Epoch 479/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4890 - accuracy: 0.7765 - val_loss: 0.4952 - val_accuracy: 0.7922\n",
            "Epoch 480/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4889 - accuracy: 0.7765 - val_loss: 0.4952 - val_accuracy: 0.7922\n",
            "Epoch 481/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4888 - accuracy: 0.7765 - val_loss: 0.4953 - val_accuracy: 0.7922\n",
            "Epoch 482/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4888 - accuracy: 0.7765 - val_loss: 0.4952 - val_accuracy: 0.7922\n",
            "Epoch 483/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4888 - accuracy: 0.7765 - val_loss: 0.4953 - val_accuracy: 0.7922\n",
            "Epoch 484/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4887 - accuracy: 0.7784 - val_loss: 0.4952 - val_accuracy: 0.7922\n",
            "Epoch 485/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4886 - accuracy: 0.7765 - val_loss: 0.4952 - val_accuracy: 0.7922\n",
            "Epoch 486/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4885 - accuracy: 0.7765 - val_loss: 0.4952 - val_accuracy: 0.7922\n",
            "Epoch 487/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4884 - accuracy: 0.7765 - val_loss: 0.4952 - val_accuracy: 0.7922\n",
            "Epoch 488/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4883 - accuracy: 0.7765 - val_loss: 0.4952 - val_accuracy: 0.7922\n",
            "Epoch 489/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4882 - accuracy: 0.7765 - val_loss: 0.4951 - val_accuracy: 0.7922\n",
            "Epoch 490/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4882 - accuracy: 0.7747 - val_loss: 0.4951 - val_accuracy: 0.7922\n",
            "Epoch 491/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4882 - accuracy: 0.7765 - val_loss: 0.4950 - val_accuracy: 0.7922\n",
            "Epoch 492/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4881 - accuracy: 0.7765 - val_loss: 0.4950 - val_accuracy: 0.7922\n",
            "Epoch 493/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4881 - accuracy: 0.7747 - val_loss: 0.4950 - val_accuracy: 0.7922\n",
            "Epoch 494/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4880 - accuracy: 0.7747 - val_loss: 0.4950 - val_accuracy: 0.7922\n",
            "Epoch 495/1500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4879 - accuracy: 0.7747 - val_loss: 0.4950 - val_accuracy: 0.7922\n",
            "Epoch 496/1500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4879 - accuracy: 0.7747 - val_loss: 0.4949 - val_accuracy: 0.7922\n",
            "Epoch 497/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4879 - accuracy: 0.7747 - val_loss: 0.4949 - val_accuracy: 0.7922\n",
            "Epoch 498/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4877 - accuracy: 0.7747 - val_loss: 0.4949 - val_accuracy: 0.7922\n",
            "Epoch 499/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4877 - accuracy: 0.7747 - val_loss: 0.4948 - val_accuracy: 0.7922\n",
            "Epoch 500/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4877 - accuracy: 0.7765 - val_loss: 0.4948 - val_accuracy: 0.7879\n",
            "Epoch 501/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4875 - accuracy: 0.7747 - val_loss: 0.4948 - val_accuracy: 0.7922\n",
            "Epoch 502/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4876 - accuracy: 0.7747 - val_loss: 0.4948 - val_accuracy: 0.7922\n",
            "Epoch 503/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4874 - accuracy: 0.7747 - val_loss: 0.4948 - val_accuracy: 0.7965\n",
            "Epoch 504/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4875 - accuracy: 0.7765 - val_loss: 0.4947 - val_accuracy: 0.7922\n",
            "Epoch 505/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4873 - accuracy: 0.7747 - val_loss: 0.4947 - val_accuracy: 0.7879\n",
            "Epoch 506/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4872 - accuracy: 0.7747 - val_loss: 0.4946 - val_accuracy: 0.7965\n",
            "Epoch 507/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4871 - accuracy: 0.7747 - val_loss: 0.4945 - val_accuracy: 0.7922\n",
            "Epoch 508/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4871 - accuracy: 0.7747 - val_loss: 0.4945 - val_accuracy: 0.7922\n",
            "Epoch 509/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4870 - accuracy: 0.7747 - val_loss: 0.4945 - val_accuracy: 0.7922\n",
            "Epoch 510/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4869 - accuracy: 0.7784 - val_loss: 0.4945 - val_accuracy: 0.7922\n",
            "Epoch 511/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4870 - accuracy: 0.7765 - val_loss: 0.4944 - val_accuracy: 0.7922\n",
            "Epoch 512/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4868 - accuracy: 0.7747 - val_loss: 0.4944 - val_accuracy: 0.7922\n",
            "Epoch 513/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4869 - accuracy: 0.7747 - val_loss: 0.4943 - val_accuracy: 0.7922\n",
            "Epoch 514/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4869 - accuracy: 0.7747 - val_loss: 0.4943 - val_accuracy: 0.7922\n",
            "Epoch 515/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4866 - accuracy: 0.7747 - val_loss: 0.4942 - val_accuracy: 0.7922\n",
            "Epoch 516/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4867 - accuracy: 0.7784 - val_loss: 0.4942 - val_accuracy: 0.7922\n",
            "Epoch 517/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4866 - accuracy: 0.7765 - val_loss: 0.4942 - val_accuracy: 0.7922\n",
            "Epoch 518/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4865 - accuracy: 0.7765 - val_loss: 0.4941 - val_accuracy: 0.7922\n",
            "Epoch 519/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4864 - accuracy: 0.7747 - val_loss: 0.4941 - val_accuracy: 0.7922\n",
            "Epoch 520/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4863 - accuracy: 0.7784 - val_loss: 0.4941 - val_accuracy: 0.7922\n",
            "Epoch 521/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4863 - accuracy: 0.7765 - val_loss: 0.4941 - val_accuracy: 0.7922\n",
            "Epoch 522/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4863 - accuracy: 0.7765 - val_loss: 0.4940 - val_accuracy: 0.7922\n",
            "Epoch 523/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4862 - accuracy: 0.7765 - val_loss: 0.4940 - val_accuracy: 0.7922\n",
            "Epoch 524/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4862 - accuracy: 0.7784 - val_loss: 0.4940 - val_accuracy: 0.7922\n",
            "Epoch 525/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4861 - accuracy: 0.7765 - val_loss: 0.4940 - val_accuracy: 0.7922\n",
            "Epoch 526/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4860 - accuracy: 0.7747 - val_loss: 0.4939 - val_accuracy: 0.7922\n",
            "Epoch 527/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4860 - accuracy: 0.7784 - val_loss: 0.4939 - val_accuracy: 0.7922\n",
            "Epoch 528/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4859 - accuracy: 0.7765 - val_loss: 0.4938 - val_accuracy: 0.7922\n",
            "Epoch 529/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4859 - accuracy: 0.7784 - val_loss: 0.4938 - val_accuracy: 0.7922\n",
            "Epoch 530/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4858 - accuracy: 0.7784 - val_loss: 0.4938 - val_accuracy: 0.7922\n",
            "Epoch 531/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4857 - accuracy: 0.7784 - val_loss: 0.4938 - val_accuracy: 0.7922\n",
            "Epoch 532/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4857 - accuracy: 0.7784 - val_loss: 0.4937 - val_accuracy: 0.7922\n",
            "Epoch 533/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4856 - accuracy: 0.7784 - val_loss: 0.4937 - val_accuracy: 0.7922\n",
            "Epoch 534/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4856 - accuracy: 0.7784 - val_loss: 0.4937 - val_accuracy: 0.7922\n",
            "Epoch 535/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4854 - accuracy: 0.7784 - val_loss: 0.4936 - val_accuracy: 0.7922\n",
            "Epoch 536/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4855 - accuracy: 0.7784 - val_loss: 0.4936 - val_accuracy: 0.7922\n",
            "Epoch 537/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4854 - accuracy: 0.7784 - val_loss: 0.4935 - val_accuracy: 0.7922\n",
            "Epoch 538/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4854 - accuracy: 0.7784 - val_loss: 0.4935 - val_accuracy: 0.7922\n",
            "Epoch 539/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4853 - accuracy: 0.7784 - val_loss: 0.4935 - val_accuracy: 0.7922\n",
            "Epoch 540/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4853 - accuracy: 0.7784 - val_loss: 0.4935 - val_accuracy: 0.7922\n",
            "Epoch 541/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4853 - accuracy: 0.7784 - val_loss: 0.4934 - val_accuracy: 0.7922\n",
            "Epoch 542/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4851 - accuracy: 0.7784 - val_loss: 0.4934 - val_accuracy: 0.7922\n",
            "Epoch 543/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4850 - accuracy: 0.7784 - val_loss: 0.4934 - val_accuracy: 0.7922\n",
            "Epoch 544/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4851 - accuracy: 0.7765 - val_loss: 0.4934 - val_accuracy: 0.7922\n",
            "Epoch 545/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4851 - accuracy: 0.7765 - val_loss: 0.4934 - val_accuracy: 0.7922\n",
            "Epoch 546/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7765 - val_loss: 0.4934 - val_accuracy: 0.7922\n",
            "Epoch 547/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4849 - accuracy: 0.7765 - val_loss: 0.4933 - val_accuracy: 0.7922\n",
            "Epoch 548/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4849 - accuracy: 0.7765 - val_loss: 0.4933 - val_accuracy: 0.7922\n",
            "Epoch 549/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4848 - accuracy: 0.7784 - val_loss: 0.4933 - val_accuracy: 0.7922\n",
            "Epoch 550/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4848 - accuracy: 0.7784 - val_loss: 0.4933 - val_accuracy: 0.7922\n",
            "Epoch 551/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7803 - val_loss: 0.4932 - val_accuracy: 0.7922\n",
            "Epoch 552/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4847 - accuracy: 0.7784 - val_loss: 0.4932 - val_accuracy: 0.7922\n",
            "Epoch 553/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4848 - accuracy: 0.7784 - val_loss: 0.4932 - val_accuracy: 0.7922\n",
            "Epoch 554/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7803 - val_loss: 0.4932 - val_accuracy: 0.7922\n",
            "Epoch 555/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4847 - accuracy: 0.7803 - val_loss: 0.4932 - val_accuracy: 0.7922\n",
            "Epoch 556/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7803 - val_loss: 0.4931 - val_accuracy: 0.7922\n",
            "Epoch 557/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7803 - val_loss: 0.4931 - val_accuracy: 0.7922\n",
            "Epoch 558/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4844 - accuracy: 0.7784 - val_loss: 0.4930 - val_accuracy: 0.7922\n",
            "Epoch 559/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7803 - val_loss: 0.4930 - val_accuracy: 0.7922\n",
            "Epoch 560/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7803 - val_loss: 0.4930 - val_accuracy: 0.7922\n",
            "Epoch 561/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7803 - val_loss: 0.4931 - val_accuracy: 0.7922\n",
            "Epoch 562/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7803 - val_loss: 0.4930 - val_accuracy: 0.7922\n",
            "Epoch 563/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4840 - accuracy: 0.7784 - val_loss: 0.4930 - val_accuracy: 0.7922\n",
            "Epoch 564/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7803 - val_loss: 0.4930 - val_accuracy: 0.7922\n",
            "Epoch 565/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4840 - accuracy: 0.7803 - val_loss: 0.4930 - val_accuracy: 0.7922\n",
            "Epoch 566/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4840 - accuracy: 0.7803 - val_loss: 0.4929 - val_accuracy: 0.7922\n",
            "Epoch 567/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4840 - accuracy: 0.7784 - val_loss: 0.4929 - val_accuracy: 0.7922\n",
            "Epoch 568/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4838 - accuracy: 0.7803 - val_loss: 0.4929 - val_accuracy: 0.7922\n",
            "Epoch 569/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4838 - accuracy: 0.7803 - val_loss: 0.4929 - val_accuracy: 0.7922\n",
            "Epoch 570/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4837 - accuracy: 0.7784 - val_loss: 0.4929 - val_accuracy: 0.7922\n",
            "Epoch 571/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4837 - accuracy: 0.7784 - val_loss: 0.4929 - val_accuracy: 0.7922\n",
            "Epoch 572/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4839 - accuracy: 0.7803 - val_loss: 0.4929 - val_accuracy: 0.7922\n",
            "Epoch 573/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4837 - accuracy: 0.7803 - val_loss: 0.4928 - val_accuracy: 0.7922\n",
            "Epoch 574/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4836 - accuracy: 0.7803 - val_loss: 0.4928 - val_accuracy: 0.7922\n",
            "Epoch 575/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4835 - accuracy: 0.7803 - val_loss: 0.4928 - val_accuracy: 0.7922\n",
            "Epoch 576/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4835 - accuracy: 0.7784 - val_loss: 0.4927 - val_accuracy: 0.7922\n",
            "Epoch 577/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4835 - accuracy: 0.7803 - val_loss: 0.4927 - val_accuracy: 0.7922\n",
            "Epoch 578/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4835 - accuracy: 0.7784 - val_loss: 0.4927 - val_accuracy: 0.7922\n",
            "Epoch 579/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4834 - accuracy: 0.7803 - val_loss: 0.4926 - val_accuracy: 0.7922\n",
            "Epoch 580/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.7803 - val_loss: 0.4925 - val_accuracy: 0.7922\n",
            "Epoch 581/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4832 - accuracy: 0.7803 - val_loss: 0.4926 - val_accuracy: 0.7922\n",
            "Epoch 582/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4831 - accuracy: 0.7784 - val_loss: 0.4925 - val_accuracy: 0.7922\n",
            "Epoch 583/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4832 - accuracy: 0.7784 - val_loss: 0.4925 - val_accuracy: 0.7922\n",
            "Epoch 584/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4831 - accuracy: 0.7803 - val_loss: 0.4926 - val_accuracy: 0.7922\n",
            "Epoch 585/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4831 - accuracy: 0.7803 - val_loss: 0.4926 - val_accuracy: 0.7922\n",
            "Epoch 586/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4830 - accuracy: 0.7803 - val_loss: 0.4925 - val_accuracy: 0.7922\n",
            "Epoch 587/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4830 - accuracy: 0.7803 - val_loss: 0.4926 - val_accuracy: 0.7922\n",
            "Epoch 588/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4829 - accuracy: 0.7803 - val_loss: 0.4925 - val_accuracy: 0.7922\n",
            "Epoch 589/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4828 - accuracy: 0.7803 - val_loss: 0.4925 - val_accuracy: 0.7922\n",
            "Epoch 590/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4827 - accuracy: 0.7803 - val_loss: 0.4925 - val_accuracy: 0.7922\n",
            "Epoch 591/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4828 - accuracy: 0.7803 - val_loss: 0.4925 - val_accuracy: 0.7922\n",
            "Epoch 592/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4828 - accuracy: 0.7803 - val_loss: 0.4925 - val_accuracy: 0.7922\n",
            "Epoch 593/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4826 - accuracy: 0.7803 - val_loss: 0.4925 - val_accuracy: 0.7922\n",
            "Epoch 594/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4826 - accuracy: 0.7803 - val_loss: 0.4924 - val_accuracy: 0.7922\n",
            "Epoch 595/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4826 - accuracy: 0.7803 - val_loss: 0.4924 - val_accuracy: 0.7922\n",
            "Epoch 596/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4825 - accuracy: 0.7803 - val_loss: 0.4923 - val_accuracy: 0.7922\n",
            "Epoch 597/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4826 - accuracy: 0.7803 - val_loss: 0.4923 - val_accuracy: 0.7922\n",
            "Epoch 598/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4825 - accuracy: 0.7803 - val_loss: 0.4923 - val_accuracy: 0.7922\n",
            "Epoch 599/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4823 - accuracy: 0.7803 - val_loss: 0.4922 - val_accuracy: 0.7922\n",
            "Epoch 600/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4823 - accuracy: 0.7784 - val_loss: 0.4922 - val_accuracy: 0.7922\n",
            "Epoch 601/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4823 - accuracy: 0.7821 - val_loss: 0.4922 - val_accuracy: 0.7922\n",
            "Epoch 602/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4823 - accuracy: 0.7803 - val_loss: 0.4922 - val_accuracy: 0.7922\n",
            "Epoch 603/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4822 - accuracy: 0.7803 - val_loss: 0.4921 - val_accuracy: 0.7922\n",
            "Epoch 604/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4823 - accuracy: 0.7803 - val_loss: 0.4922 - val_accuracy: 0.7922\n",
            "Epoch 605/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4821 - accuracy: 0.7784 - val_loss: 0.4921 - val_accuracy: 0.7922\n",
            "Epoch 606/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4821 - accuracy: 0.7803 - val_loss: 0.4922 - val_accuracy: 0.7922\n",
            "Epoch 607/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4821 - accuracy: 0.7784 - val_loss: 0.4921 - val_accuracy: 0.7922\n",
            "Epoch 608/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4819 - accuracy: 0.7803 - val_loss: 0.4920 - val_accuracy: 0.7922\n",
            "Epoch 609/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4819 - accuracy: 0.7803 - val_loss: 0.4920 - val_accuracy: 0.7922\n",
            "Epoch 610/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4819 - accuracy: 0.7784 - val_loss: 0.4920 - val_accuracy: 0.7922\n",
            "Epoch 611/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4818 - accuracy: 0.7803 - val_loss: 0.4920 - val_accuracy: 0.7922\n",
            "Epoch 612/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4818 - accuracy: 0.7803 - val_loss: 0.4919 - val_accuracy: 0.7922\n",
            "Epoch 613/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4818 - accuracy: 0.7728 - val_loss: 0.4918 - val_accuracy: 0.7922\n",
            "Epoch 614/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4817 - accuracy: 0.7784 - val_loss: 0.4918 - val_accuracy: 0.7922\n",
            "Epoch 615/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4817 - accuracy: 0.7803 - val_loss: 0.4917 - val_accuracy: 0.7922\n",
            "Epoch 616/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4816 - accuracy: 0.7803 - val_loss: 0.4918 - val_accuracy: 0.7922\n",
            "Epoch 617/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4817 - accuracy: 0.7821 - val_loss: 0.4918 - val_accuracy: 0.7922\n",
            "Epoch 618/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4816 - accuracy: 0.7821 - val_loss: 0.4918 - val_accuracy: 0.7922\n",
            "Epoch 619/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4815 - accuracy: 0.7803 - val_loss: 0.4917 - val_accuracy: 0.7922\n",
            "Epoch 620/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4814 - accuracy: 0.7803 - val_loss: 0.4917 - val_accuracy: 0.7922\n",
            "Epoch 621/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4814 - accuracy: 0.7803 - val_loss: 0.4917 - val_accuracy: 0.7922\n",
            "Epoch 622/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4815 - accuracy: 0.7803 - val_loss: 0.4916 - val_accuracy: 0.7922\n",
            "Epoch 623/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4813 - accuracy: 0.7821 - val_loss: 0.4916 - val_accuracy: 0.7922\n",
            "Epoch 624/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4812 - accuracy: 0.7821 - val_loss: 0.4916 - val_accuracy: 0.7922\n",
            "Epoch 625/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4812 - accuracy: 0.7821 - val_loss: 0.4915 - val_accuracy: 0.7922\n",
            "Epoch 626/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4814 - accuracy: 0.7821 - val_loss: 0.4914 - val_accuracy: 0.7922\n",
            "Epoch 627/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4812 - accuracy: 0.7821 - val_loss: 0.4915 - val_accuracy: 0.7922\n",
            "Epoch 628/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4811 - accuracy: 0.7821 - val_loss: 0.4914 - val_accuracy: 0.7922\n",
            "Epoch 629/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4811 - accuracy: 0.7821 - val_loss: 0.4914 - val_accuracy: 0.7922\n",
            "Epoch 630/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4812 - accuracy: 0.7821 - val_loss: 0.4914 - val_accuracy: 0.7922\n",
            "Epoch 631/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4811 - accuracy: 0.7803 - val_loss: 0.4914 - val_accuracy: 0.7922\n",
            "Epoch 632/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4811 - accuracy: 0.7821 - val_loss: 0.4914 - val_accuracy: 0.7922\n",
            "Epoch 633/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4810 - accuracy: 0.7803 - val_loss: 0.4914 - val_accuracy: 0.7922\n",
            "Epoch 634/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4809 - accuracy: 0.7821 - val_loss: 0.4914 - val_accuracy: 0.7922\n",
            "Epoch 635/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4809 - accuracy: 0.7840 - val_loss: 0.4914 - val_accuracy: 0.7922\n",
            "Epoch 636/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4809 - accuracy: 0.7803 - val_loss: 0.4913 - val_accuracy: 0.7922\n",
            "Epoch 637/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4810 - accuracy: 0.7803 - val_loss: 0.4913 - val_accuracy: 0.7922\n",
            "Epoch 638/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4808 - accuracy: 0.7840 - val_loss: 0.4912 - val_accuracy: 0.7922\n",
            "Epoch 639/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4808 - accuracy: 0.7840 - val_loss: 0.4911 - val_accuracy: 0.7922\n",
            "Epoch 640/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4807 - accuracy: 0.7840 - val_loss: 0.4911 - val_accuracy: 0.7922\n",
            "Epoch 641/1500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4807 - accuracy: 0.7803 - val_loss: 0.4911 - val_accuracy: 0.7922\n",
            "Epoch 642/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4807 - accuracy: 0.7840 - val_loss: 0.4911 - val_accuracy: 0.7922\n",
            "Epoch 643/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4807 - accuracy: 0.7803 - val_loss: 0.4911 - val_accuracy: 0.7922\n",
            "Epoch 644/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4806 - accuracy: 0.7821 - val_loss: 0.4911 - val_accuracy: 0.7922\n",
            "Epoch 645/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4806 - accuracy: 0.7821 - val_loss: 0.4911 - val_accuracy: 0.7922\n",
            "Epoch 646/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4805 - accuracy: 0.7803 - val_loss: 0.4910 - val_accuracy: 0.7922\n",
            "Epoch 647/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4805 - accuracy: 0.7821 - val_loss: 0.4910 - val_accuracy: 0.7922\n",
            "Epoch 648/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4804 - accuracy: 0.7784 - val_loss: 0.4910 - val_accuracy: 0.7922\n",
            "Epoch 649/1500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4804 - accuracy: 0.7803 - val_loss: 0.4910 - val_accuracy: 0.7922\n",
            "Epoch 650/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4803 - accuracy: 0.7803 - val_loss: 0.4910 - val_accuracy: 0.7922\n",
            "Epoch 651/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4802 - accuracy: 0.7840 - val_loss: 0.4910 - val_accuracy: 0.7922\n",
            "Epoch 652/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4804 - accuracy: 0.7803 - val_loss: 0.4909 - val_accuracy: 0.7922\n",
            "Epoch 653/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4803 - accuracy: 0.7840 - val_loss: 0.4910 - val_accuracy: 0.7922\n",
            "Epoch 654/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4802 - accuracy: 0.7840 - val_loss: 0.4910 - val_accuracy: 0.7922\n",
            "Epoch 655/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7821 - val_loss: 0.4909 - val_accuracy: 0.7922\n",
            "Epoch 656/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4801 - accuracy: 0.7858 - val_loss: 0.4909 - val_accuracy: 0.7922\n",
            "Epoch 657/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4801 - accuracy: 0.7858 - val_loss: 0.4909 - val_accuracy: 0.7922\n",
            "Epoch 658/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4801 - accuracy: 0.7821 - val_loss: 0.4908 - val_accuracy: 0.7922\n",
            "Epoch 659/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4800 - accuracy: 0.7803 - val_loss: 0.4908 - val_accuracy: 0.7922\n",
            "Epoch 660/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4799 - accuracy: 0.7821 - val_loss: 0.4908 - val_accuracy: 0.7922\n",
            "Epoch 661/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4799 - accuracy: 0.7821 - val_loss: 0.4908 - val_accuracy: 0.7922\n",
            "Epoch 662/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4798 - accuracy: 0.7840 - val_loss: 0.4908 - val_accuracy: 0.7922\n",
            "Epoch 663/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4799 - accuracy: 0.7840 - val_loss: 0.4908 - val_accuracy: 0.7922\n",
            "Epoch 664/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4799 - accuracy: 0.7821 - val_loss: 0.4907 - val_accuracy: 0.7922\n",
            "Epoch 665/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4798 - accuracy: 0.7840 - val_loss: 0.4907 - val_accuracy: 0.7922\n",
            "Epoch 666/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4799 - accuracy: 0.7840 - val_loss: 0.4906 - val_accuracy: 0.7922\n",
            "Epoch 667/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4797 - accuracy: 0.7803 - val_loss: 0.4906 - val_accuracy: 0.7922\n",
            "Epoch 668/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4796 - accuracy: 0.7840 - val_loss: 0.4906 - val_accuracy: 0.7922\n",
            "Epoch 669/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4796 - accuracy: 0.7840 - val_loss: 0.4906 - val_accuracy: 0.7922\n",
            "Epoch 670/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4796 - accuracy: 0.7858 - val_loss: 0.4906 - val_accuracy: 0.7922\n",
            "Epoch 671/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4797 - accuracy: 0.7840 - val_loss: 0.4906 - val_accuracy: 0.7922\n",
            "Epoch 672/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4796 - accuracy: 0.7821 - val_loss: 0.4906 - val_accuracy: 0.7922\n",
            "Epoch 673/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4796 - accuracy: 0.7803 - val_loss: 0.4906 - val_accuracy: 0.7922\n",
            "Epoch 674/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4794 - accuracy: 0.7840 - val_loss: 0.4906 - val_accuracy: 0.7922\n",
            "Epoch 675/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4794 - accuracy: 0.7840 - val_loss: 0.4905 - val_accuracy: 0.7922\n",
            "Epoch 676/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4795 - accuracy: 0.7803 - val_loss: 0.4906 - val_accuracy: 0.7922\n",
            "Epoch 677/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4793 - accuracy: 0.7840 - val_loss: 0.4906 - val_accuracy: 0.7922\n",
            "Epoch 678/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4793 - accuracy: 0.7784 - val_loss: 0.4905 - val_accuracy: 0.7922\n",
            "Epoch 679/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4793 - accuracy: 0.7803 - val_loss: 0.4906 - val_accuracy: 0.7922\n",
            "Epoch 680/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4792 - accuracy: 0.7821 - val_loss: 0.4905 - val_accuracy: 0.7922\n",
            "Epoch 681/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4793 - accuracy: 0.7840 - val_loss: 0.4905 - val_accuracy: 0.7922\n",
            "Epoch 682/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4791 - accuracy: 0.7821 - val_loss: 0.4905 - val_accuracy: 0.7922\n",
            "Epoch 683/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4793 - accuracy: 0.7821 - val_loss: 0.4905 - val_accuracy: 0.7922\n",
            "Epoch 684/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4791 - accuracy: 0.7821 - val_loss: 0.4905 - val_accuracy: 0.7922\n",
            "Epoch 685/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4791 - accuracy: 0.7803 - val_loss: 0.4905 - val_accuracy: 0.7922\n",
            "Epoch 686/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4791 - accuracy: 0.7821 - val_loss: 0.4905 - val_accuracy: 0.7922\n",
            "Epoch 687/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4789 - accuracy: 0.7821 - val_loss: 0.4905 - val_accuracy: 0.7922\n",
            "Epoch 688/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4790 - accuracy: 0.7821 - val_loss: 0.4905 - val_accuracy: 0.7922\n",
            "Epoch 689/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4790 - accuracy: 0.7803 - val_loss: 0.4905 - val_accuracy: 0.7965\n",
            "Epoch 690/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4788 - accuracy: 0.7821 - val_loss: 0.4905 - val_accuracy: 0.7965\n",
            "Epoch 691/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4787 - accuracy: 0.7840 - val_loss: 0.4904 - val_accuracy: 0.7965\n",
            "Epoch 692/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4789 - accuracy: 0.7803 - val_loss: 0.4904 - val_accuracy: 0.7965\n",
            "Epoch 693/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4789 - accuracy: 0.7840 - val_loss: 0.4904 - val_accuracy: 0.7965\n",
            "Epoch 694/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4787 - accuracy: 0.7858 - val_loss: 0.4904 - val_accuracy: 0.7922\n",
            "Epoch 695/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4788 - accuracy: 0.7821 - val_loss: 0.4904 - val_accuracy: 0.7922\n",
            "Epoch 696/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4787 - accuracy: 0.7840 - val_loss: 0.4903 - val_accuracy: 0.7922\n",
            "Epoch 697/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4785 - accuracy: 0.7840 - val_loss: 0.4903 - val_accuracy: 0.7922\n",
            "Epoch 698/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4786 - accuracy: 0.7840 - val_loss: 0.4903 - val_accuracy: 0.7922\n",
            "Epoch 699/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4785 - accuracy: 0.7840 - val_loss: 0.4903 - val_accuracy: 0.7922\n",
            "Epoch 700/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4785 - accuracy: 0.7858 - val_loss: 0.4902 - val_accuracy: 0.7965\n",
            "Epoch 701/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4784 - accuracy: 0.7858 - val_loss: 0.4902 - val_accuracy: 0.7965\n",
            "Epoch 702/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4783 - accuracy: 0.7858 - val_loss: 0.4902 - val_accuracy: 0.7965\n",
            "Epoch 703/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4782 - accuracy: 0.7840 - val_loss: 0.4902 - val_accuracy: 0.7965\n",
            "Epoch 704/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4782 - accuracy: 0.7858 - val_loss: 0.4902 - val_accuracy: 0.7965\n",
            "Epoch 705/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4781 - accuracy: 0.7840 - val_loss: 0.4901 - val_accuracy: 0.7965\n",
            "Epoch 706/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4782 - accuracy: 0.7858 - val_loss: 0.4901 - val_accuracy: 0.7965\n",
            "Epoch 707/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4782 - accuracy: 0.7858 - val_loss: 0.4901 - val_accuracy: 0.7965\n",
            "Epoch 708/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4780 - accuracy: 0.7858 - val_loss: 0.4900 - val_accuracy: 0.7965\n",
            "Epoch 709/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4780 - accuracy: 0.7858 - val_loss: 0.4899 - val_accuracy: 0.7965\n",
            "Epoch 710/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4780 - accuracy: 0.7858 - val_loss: 0.4899 - val_accuracy: 0.7965\n",
            "Epoch 711/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4780 - accuracy: 0.7877 - val_loss: 0.4899 - val_accuracy: 0.7965\n",
            "Epoch 712/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.7840 - val_loss: 0.4899 - val_accuracy: 0.7965\n",
            "Epoch 713/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4779 - accuracy: 0.7858 - val_loss: 0.4899 - val_accuracy: 0.7965\n",
            "Epoch 714/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4778 - accuracy: 0.7840 - val_loss: 0.4899 - val_accuracy: 0.7965\n",
            "Epoch 715/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4778 - accuracy: 0.7840 - val_loss: 0.4898 - val_accuracy: 0.7965\n",
            "Epoch 716/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4778 - accuracy: 0.7858 - val_loss: 0.4898 - val_accuracy: 0.7965\n",
            "Epoch 717/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4777 - accuracy: 0.7858 - val_loss: 0.4898 - val_accuracy: 0.7965\n",
            "Epoch 718/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4776 - accuracy: 0.7840 - val_loss: 0.4898 - val_accuracy: 0.7965\n",
            "Epoch 719/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4777 - accuracy: 0.7858 - val_loss: 0.4898 - val_accuracy: 0.7965\n",
            "Epoch 720/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4776 - accuracy: 0.7858 - val_loss: 0.4898 - val_accuracy: 0.7965\n",
            "Epoch 721/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4775 - accuracy: 0.7858 - val_loss: 0.4898 - val_accuracy: 0.7965\n",
            "Epoch 722/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4774 - accuracy: 0.7858 - val_loss: 0.4898 - val_accuracy: 0.7965\n",
            "Epoch 723/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4774 - accuracy: 0.7840 - val_loss: 0.4897 - val_accuracy: 0.7965\n",
            "Epoch 724/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4775 - accuracy: 0.7858 - val_loss: 0.4897 - val_accuracy: 0.7965\n",
            "Epoch 725/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4774 - accuracy: 0.7803 - val_loss: 0.4896 - val_accuracy: 0.7965\n",
            "Epoch 726/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4773 - accuracy: 0.7877 - val_loss: 0.4897 - val_accuracy: 0.7965\n",
            "Epoch 727/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4774 - accuracy: 0.7858 - val_loss: 0.4897 - val_accuracy: 0.7965\n",
            "Epoch 728/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4772 - accuracy: 0.7821 - val_loss: 0.4896 - val_accuracy: 0.7965\n",
            "Epoch 729/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4773 - accuracy: 0.7821 - val_loss: 0.4896 - val_accuracy: 0.7965\n",
            "Epoch 730/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4772 - accuracy: 0.7840 - val_loss: 0.4896 - val_accuracy: 0.7965\n",
            "Epoch 731/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4773 - accuracy: 0.7840 - val_loss: 0.4896 - val_accuracy: 0.7965\n",
            "Epoch 732/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4770 - accuracy: 0.7858 - val_loss: 0.4896 - val_accuracy: 0.7965\n",
            "Epoch 733/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4771 - accuracy: 0.7821 - val_loss: 0.4896 - val_accuracy: 0.7965\n",
            "Epoch 734/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4771 - accuracy: 0.7840 - val_loss: 0.4895 - val_accuracy: 0.7965\n",
            "Epoch 735/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4769 - accuracy: 0.7821 - val_loss: 0.4895 - val_accuracy: 0.7965\n",
            "Epoch 736/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4769 - accuracy: 0.7821 - val_loss: 0.4895 - val_accuracy: 0.7965\n",
            "Epoch 737/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4769 - accuracy: 0.7840 - val_loss: 0.4895 - val_accuracy: 0.7965\n",
            "Epoch 738/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4770 - accuracy: 0.7858 - val_loss: 0.4895 - val_accuracy: 0.7965\n",
            "Epoch 739/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4768 - accuracy: 0.7803 - val_loss: 0.4895 - val_accuracy: 0.7965\n",
            "Epoch 740/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4768 - accuracy: 0.7840 - val_loss: 0.4895 - val_accuracy: 0.7965\n",
            "Epoch 741/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4769 - accuracy: 0.7784 - val_loss: 0.4895 - val_accuracy: 0.7965\n",
            "Epoch 742/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4767 - accuracy: 0.7821 - val_loss: 0.4895 - val_accuracy: 0.7965\n",
            "Epoch 743/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4766 - accuracy: 0.7821 - val_loss: 0.4895 - val_accuracy: 0.7965\n",
            "Epoch 744/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4766 - accuracy: 0.7840 - val_loss: 0.4895 - val_accuracy: 0.7965\n",
            "Epoch 745/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4766 - accuracy: 0.7784 - val_loss: 0.4894 - val_accuracy: 0.7965\n",
            "Epoch 746/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4766 - accuracy: 0.7765 - val_loss: 0.4894 - val_accuracy: 0.7965\n",
            "Epoch 747/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4765 - accuracy: 0.7784 - val_loss: 0.4894 - val_accuracy: 0.7922\n",
            "Epoch 748/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4765 - accuracy: 0.7803 - val_loss: 0.4894 - val_accuracy: 0.7922\n",
            "Epoch 749/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4764 - accuracy: 0.7765 - val_loss: 0.4894 - val_accuracy: 0.7922\n",
            "Epoch 750/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4763 - accuracy: 0.7765 - val_loss: 0.4893 - val_accuracy: 0.7922\n",
            "Epoch 751/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4763 - accuracy: 0.7784 - val_loss: 0.4892 - val_accuracy: 0.7922\n",
            "Epoch 752/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4764 - accuracy: 0.7765 - val_loss: 0.4892 - val_accuracy: 0.7965\n",
            "Epoch 753/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4761 - accuracy: 0.7784 - val_loss: 0.4892 - val_accuracy: 0.7922\n",
            "Epoch 754/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4762 - accuracy: 0.7803 - val_loss: 0.4892 - val_accuracy: 0.7922\n",
            "Epoch 755/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4762 - accuracy: 0.7765 - val_loss: 0.4891 - val_accuracy: 0.7922\n",
            "Epoch 756/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4760 - accuracy: 0.7784 - val_loss: 0.4890 - val_accuracy: 0.7922\n",
            "Epoch 757/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4761 - accuracy: 0.7803 - val_loss: 0.4891 - val_accuracy: 0.7879\n",
            "Epoch 758/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4759 - accuracy: 0.7784 - val_loss: 0.4891 - val_accuracy: 0.7879\n",
            "Epoch 759/1500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.4759 - accuracy: 0.7747 - val_loss: 0.4890 - val_accuracy: 0.7879\n",
            "Epoch 760/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4759 - accuracy: 0.7803 - val_loss: 0.4891 - val_accuracy: 0.7879\n",
            "Epoch 761/1500\n",
            "17/17 [==============================] - 0s 22ms/step - loss: 0.4758 - accuracy: 0.7784 - val_loss: 0.4890 - val_accuracy: 0.7879\n",
            "Epoch 762/1500\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 0.4757 - accuracy: 0.7784 - val_loss: 0.4888 - val_accuracy: 0.7879\n",
            "Epoch 763/1500\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.4758 - accuracy: 0.7803 - val_loss: 0.4888 - val_accuracy: 0.7879\n",
            "Epoch 764/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4756 - accuracy: 0.7784 - val_loss: 0.4887 - val_accuracy: 0.7879\n",
            "Epoch 765/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4756 - accuracy: 0.7784 - val_loss: 0.4887 - val_accuracy: 0.7835\n",
            "Epoch 766/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4756 - accuracy: 0.7784 - val_loss: 0.4886 - val_accuracy: 0.7835\n",
            "Epoch 767/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4754 - accuracy: 0.7784 - val_loss: 0.4886 - val_accuracy: 0.7835\n",
            "Epoch 768/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4755 - accuracy: 0.7765 - val_loss: 0.4884 - val_accuracy: 0.7879\n",
            "Epoch 769/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4755 - accuracy: 0.7784 - val_loss: 0.4884 - val_accuracy: 0.7879\n",
            "Epoch 770/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4753 - accuracy: 0.7803 - val_loss: 0.4883 - val_accuracy: 0.7879\n",
            "Epoch 771/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4752 - accuracy: 0.7765 - val_loss: 0.4882 - val_accuracy: 0.7879\n",
            "Epoch 772/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4751 - accuracy: 0.7784 - val_loss: 0.4882 - val_accuracy: 0.7879\n",
            "Epoch 773/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4752 - accuracy: 0.7784 - val_loss: 0.4881 - val_accuracy: 0.7879\n",
            "Epoch 774/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4750 - accuracy: 0.7803 - val_loss: 0.4880 - val_accuracy: 0.7879\n",
            "Epoch 775/1500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4752 - accuracy: 0.7784 - val_loss: 0.4879 - val_accuracy: 0.7879\n",
            "Epoch 776/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4750 - accuracy: 0.7803 - val_loss: 0.4878 - val_accuracy: 0.7879\n",
            "Epoch 777/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4748 - accuracy: 0.7784 - val_loss: 0.4877 - val_accuracy: 0.7879\n",
            "Epoch 778/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4748 - accuracy: 0.7821 - val_loss: 0.4878 - val_accuracy: 0.7879\n",
            "Epoch 779/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4747 - accuracy: 0.7803 - val_loss: 0.4877 - val_accuracy: 0.7879\n",
            "Epoch 780/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4747 - accuracy: 0.7784 - val_loss: 0.4876 - val_accuracy: 0.7879\n",
            "Epoch 781/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4745 - accuracy: 0.7803 - val_loss: 0.4876 - val_accuracy: 0.7879\n",
            "Epoch 782/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4745 - accuracy: 0.7821 - val_loss: 0.4876 - val_accuracy: 0.7879\n",
            "Epoch 783/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4744 - accuracy: 0.7747 - val_loss: 0.4876 - val_accuracy: 0.7879\n",
            "Epoch 784/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4744 - accuracy: 0.7784 - val_loss: 0.4876 - val_accuracy: 0.7879\n",
            "Epoch 785/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4743 - accuracy: 0.7765 - val_loss: 0.4875 - val_accuracy: 0.7879\n",
            "Epoch 786/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4742 - accuracy: 0.7803 - val_loss: 0.4875 - val_accuracy: 0.7879\n",
            "Epoch 787/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4740 - accuracy: 0.7840 - val_loss: 0.4874 - val_accuracy: 0.7879\n",
            "Epoch 788/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4741 - accuracy: 0.7765 - val_loss: 0.4873 - val_accuracy: 0.7879\n",
            "Epoch 789/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4740 - accuracy: 0.7765 - val_loss: 0.4871 - val_accuracy: 0.7879\n",
            "Epoch 790/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4739 - accuracy: 0.7784 - val_loss: 0.4871 - val_accuracy: 0.7879\n",
            "Epoch 791/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4741 - accuracy: 0.7784 - val_loss: 0.4872 - val_accuracy: 0.7879\n",
            "Epoch 792/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4737 - accuracy: 0.7765 - val_loss: 0.4871 - val_accuracy: 0.7879\n",
            "Epoch 793/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4736 - accuracy: 0.7765 - val_loss: 0.4869 - val_accuracy: 0.7879\n",
            "Epoch 794/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4737 - accuracy: 0.7803 - val_loss: 0.4869 - val_accuracy: 0.7879\n",
            "Epoch 795/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4735 - accuracy: 0.7765 - val_loss: 0.4869 - val_accuracy: 0.7879\n",
            "Epoch 796/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4735 - accuracy: 0.7765 - val_loss: 0.4868 - val_accuracy: 0.7879\n",
            "Epoch 797/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4733 - accuracy: 0.7784 - val_loss: 0.4867 - val_accuracy: 0.7879\n",
            "Epoch 798/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4734 - accuracy: 0.7784 - val_loss: 0.4866 - val_accuracy: 0.7879\n",
            "Epoch 799/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4732 - accuracy: 0.7765 - val_loss: 0.4865 - val_accuracy: 0.7879\n",
            "Epoch 800/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4732 - accuracy: 0.7803 - val_loss: 0.4865 - val_accuracy: 0.7879\n",
            "Epoch 801/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4730 - accuracy: 0.7784 - val_loss: 0.4864 - val_accuracy: 0.7879\n",
            "Epoch 802/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4730 - accuracy: 0.7765 - val_loss: 0.4864 - val_accuracy: 0.7879\n",
            "Epoch 803/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4730 - accuracy: 0.7803 - val_loss: 0.4863 - val_accuracy: 0.7835\n",
            "Epoch 804/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4728 - accuracy: 0.7765 - val_loss: 0.4863 - val_accuracy: 0.7835\n",
            "Epoch 805/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4728 - accuracy: 0.7784 - val_loss: 0.4862 - val_accuracy: 0.7835\n",
            "Epoch 806/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4726 - accuracy: 0.7821 - val_loss: 0.4861 - val_accuracy: 0.7835\n",
            "Epoch 807/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4726 - accuracy: 0.7765 - val_loss: 0.4861 - val_accuracy: 0.7835\n",
            "Epoch 808/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4725 - accuracy: 0.7784 - val_loss: 0.4860 - val_accuracy: 0.7835\n",
            "Epoch 809/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4723 - accuracy: 0.7784 - val_loss: 0.4860 - val_accuracy: 0.7835\n",
            "Epoch 810/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4723 - accuracy: 0.7803 - val_loss: 0.4859 - val_accuracy: 0.7835\n",
            "Epoch 811/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4723 - accuracy: 0.7803 - val_loss: 0.4858 - val_accuracy: 0.7835\n",
            "Epoch 812/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4719 - accuracy: 0.7765 - val_loss: 0.4857 - val_accuracy: 0.7835\n",
            "Epoch 813/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4720 - accuracy: 0.7784 - val_loss: 0.4856 - val_accuracy: 0.7835\n",
            "Epoch 814/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4719 - accuracy: 0.7784 - val_loss: 0.4856 - val_accuracy: 0.7835\n",
            "Epoch 815/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4719 - accuracy: 0.7784 - val_loss: 0.4855 - val_accuracy: 0.7835\n",
            "Epoch 816/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4717 - accuracy: 0.7803 - val_loss: 0.4854 - val_accuracy: 0.7835\n",
            "Epoch 817/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4717 - accuracy: 0.7821 - val_loss: 0.4854 - val_accuracy: 0.7835\n",
            "Epoch 818/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4715 - accuracy: 0.7821 - val_loss: 0.4853 - val_accuracy: 0.7835\n",
            "Epoch 819/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.7803 - val_loss: 0.4853 - val_accuracy: 0.7835\n",
            "Epoch 820/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7803 - val_loss: 0.4852 - val_accuracy: 0.7835\n",
            "Epoch 821/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4713 - accuracy: 0.7821 - val_loss: 0.4852 - val_accuracy: 0.7879\n",
            "Epoch 822/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4711 - accuracy: 0.7821 - val_loss: 0.4851 - val_accuracy: 0.7879\n",
            "Epoch 823/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4711 - accuracy: 0.7803 - val_loss: 0.4850 - val_accuracy: 0.7879\n",
            "Epoch 824/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4709 - accuracy: 0.7803 - val_loss: 0.4850 - val_accuracy: 0.7879\n",
            "Epoch 825/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.7821 - val_loss: 0.4849 - val_accuracy: 0.7879\n",
            "Epoch 826/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4707 - accuracy: 0.7821 - val_loss: 0.4849 - val_accuracy: 0.7879\n",
            "Epoch 827/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4708 - accuracy: 0.7803 - val_loss: 0.4850 - val_accuracy: 0.7879\n",
            "Epoch 828/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4706 - accuracy: 0.7821 - val_loss: 0.4849 - val_accuracy: 0.7879\n",
            "Epoch 829/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4706 - accuracy: 0.7840 - val_loss: 0.4848 - val_accuracy: 0.7879\n",
            "Epoch 830/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4704 - accuracy: 0.7803 - val_loss: 0.4847 - val_accuracy: 0.7835\n",
            "Epoch 831/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4705 - accuracy: 0.7840 - val_loss: 0.4847 - val_accuracy: 0.7835\n",
            "Epoch 832/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4703 - accuracy: 0.7840 - val_loss: 0.4846 - val_accuracy: 0.7835\n",
            "Epoch 833/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4701 - accuracy: 0.7821 - val_loss: 0.4846 - val_accuracy: 0.7835\n",
            "Epoch 834/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4701 - accuracy: 0.7840 - val_loss: 0.4847 - val_accuracy: 0.7835\n",
            "Epoch 835/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4699 - accuracy: 0.7821 - val_loss: 0.4846 - val_accuracy: 0.7835\n",
            "Epoch 836/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4699 - accuracy: 0.7840 - val_loss: 0.4844 - val_accuracy: 0.7835\n",
            "Epoch 837/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4699 - accuracy: 0.7840 - val_loss: 0.4845 - val_accuracy: 0.7835\n",
            "Epoch 838/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4697 - accuracy: 0.7784 - val_loss: 0.4844 - val_accuracy: 0.7835\n",
            "Epoch 839/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4696 - accuracy: 0.7803 - val_loss: 0.4844 - val_accuracy: 0.7835\n",
            "Epoch 840/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4697 - accuracy: 0.7821 - val_loss: 0.4844 - val_accuracy: 0.7835\n",
            "Epoch 841/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4695 - accuracy: 0.7821 - val_loss: 0.4843 - val_accuracy: 0.7835\n",
            "Epoch 842/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4693 - accuracy: 0.7821 - val_loss: 0.4843 - val_accuracy: 0.7879\n",
            "Epoch 843/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4695 - accuracy: 0.7858 - val_loss: 0.4843 - val_accuracy: 0.7835\n",
            "Epoch 844/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4693 - accuracy: 0.7821 - val_loss: 0.4844 - val_accuracy: 0.7879\n",
            "Epoch 845/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4693 - accuracy: 0.7821 - val_loss: 0.4842 - val_accuracy: 0.7835\n",
            "Epoch 846/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4691 - accuracy: 0.7821 - val_loss: 0.4840 - val_accuracy: 0.7835\n",
            "Epoch 847/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4690 - accuracy: 0.7821 - val_loss: 0.4840 - val_accuracy: 0.7835\n",
            "Epoch 848/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4689 - accuracy: 0.7821 - val_loss: 0.4840 - val_accuracy: 0.7835\n",
            "Epoch 849/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4687 - accuracy: 0.7821 - val_loss: 0.4840 - val_accuracy: 0.7835\n",
            "Epoch 850/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4686 - accuracy: 0.7803 - val_loss: 0.4839 - val_accuracy: 0.7835\n",
            "Epoch 851/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7784 - val_loss: 0.4837 - val_accuracy: 0.7835\n",
            "Epoch 852/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7803 - val_loss: 0.4837 - val_accuracy: 0.7835\n",
            "Epoch 853/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4685 - accuracy: 0.7803 - val_loss: 0.4837 - val_accuracy: 0.7835\n",
            "Epoch 854/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4683 - accuracy: 0.7803 - val_loss: 0.4835 - val_accuracy: 0.7835\n",
            "Epoch 855/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4682 - accuracy: 0.7803 - val_loss: 0.4834 - val_accuracy: 0.7835\n",
            "Epoch 856/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4681 - accuracy: 0.7784 - val_loss: 0.4832 - val_accuracy: 0.7835\n",
            "Epoch 857/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4682 - accuracy: 0.7821 - val_loss: 0.4832 - val_accuracy: 0.7835\n",
            "Epoch 858/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4679 - accuracy: 0.7803 - val_loss: 0.4831 - val_accuracy: 0.7835\n",
            "Epoch 859/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4679 - accuracy: 0.7821 - val_loss: 0.4830 - val_accuracy: 0.7835\n",
            "Epoch 860/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4677 - accuracy: 0.7840 - val_loss: 0.4830 - val_accuracy: 0.7835\n",
            "Epoch 861/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4677 - accuracy: 0.7821 - val_loss: 0.4830 - val_accuracy: 0.7835\n",
            "Epoch 862/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.7821 - val_loss: 0.4829 - val_accuracy: 0.7835\n",
            "Epoch 863/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7840 - val_loss: 0.4829 - val_accuracy: 0.7835\n",
            "Epoch 864/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7803 - val_loss: 0.4828 - val_accuracy: 0.7835\n",
            "Epoch 865/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7840 - val_loss: 0.4827 - val_accuracy: 0.7835\n",
            "Epoch 866/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4672 - accuracy: 0.7840 - val_loss: 0.4826 - val_accuracy: 0.7835\n",
            "Epoch 867/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7803 - val_loss: 0.4827 - val_accuracy: 0.7835\n",
            "Epoch 868/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7840 - val_loss: 0.4825 - val_accuracy: 0.7835\n",
            "Epoch 869/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7840 - val_loss: 0.4824 - val_accuracy: 0.7835\n",
            "Epoch 870/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4670 - accuracy: 0.7840 - val_loss: 0.4823 - val_accuracy: 0.7835\n",
            "Epoch 871/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4668 - accuracy: 0.7840 - val_loss: 0.4822 - val_accuracy: 0.7835\n",
            "Epoch 872/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4668 - accuracy: 0.7821 - val_loss: 0.4822 - val_accuracy: 0.7835\n",
            "Epoch 873/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4667 - accuracy: 0.7821 - val_loss: 0.4821 - val_accuracy: 0.7835\n",
            "Epoch 874/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4665 - accuracy: 0.7840 - val_loss: 0.4822 - val_accuracy: 0.7835\n",
            "Epoch 875/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4665 - accuracy: 0.7840 - val_loss: 0.4822 - val_accuracy: 0.7835\n",
            "Epoch 876/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7840 - val_loss: 0.4820 - val_accuracy: 0.7835\n",
            "Epoch 877/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7840 - val_loss: 0.4819 - val_accuracy: 0.7835\n",
            "Epoch 878/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7840 - val_loss: 0.4817 - val_accuracy: 0.7835\n",
            "Epoch 879/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4661 - accuracy: 0.7858 - val_loss: 0.4816 - val_accuracy: 0.7835\n",
            "Epoch 880/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4663 - accuracy: 0.7840 - val_loss: 0.4816 - val_accuracy: 0.7835\n",
            "Epoch 881/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4660 - accuracy: 0.7840 - val_loss: 0.4815 - val_accuracy: 0.7835\n",
            "Epoch 882/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7840 - val_loss: 0.4815 - val_accuracy: 0.7835\n",
            "Epoch 883/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.7821 - val_loss: 0.4813 - val_accuracy: 0.7835\n",
            "Epoch 884/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7858 - val_loss: 0.4814 - val_accuracy: 0.7835\n",
            "Epoch 885/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4657 - accuracy: 0.7840 - val_loss: 0.4812 - val_accuracy: 0.7835\n",
            "Epoch 886/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4657 - accuracy: 0.7840 - val_loss: 0.4812 - val_accuracy: 0.7835\n",
            "Epoch 887/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4657 - accuracy: 0.7840 - val_loss: 0.4811 - val_accuracy: 0.7835\n",
            "Epoch 888/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4655 - accuracy: 0.7840 - val_loss: 0.4811 - val_accuracy: 0.7835\n",
            "Epoch 889/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7821 - val_loss: 0.4811 - val_accuracy: 0.7879\n",
            "Epoch 890/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4655 - accuracy: 0.7858 - val_loss: 0.4810 - val_accuracy: 0.7879\n",
            "Epoch 891/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7858 - val_loss: 0.4809 - val_accuracy: 0.7879\n",
            "Epoch 892/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7840 - val_loss: 0.4810 - val_accuracy: 0.7879\n",
            "Epoch 893/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4653 - accuracy: 0.7840 - val_loss: 0.4810 - val_accuracy: 0.7879\n",
            "Epoch 894/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4651 - accuracy: 0.7840 - val_loss: 0.4809 - val_accuracy: 0.7879\n",
            "Epoch 895/1500\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.4651 - accuracy: 0.7840 - val_loss: 0.4807 - val_accuracy: 0.7879\n",
            "Epoch 896/1500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4651 - accuracy: 0.7803 - val_loss: 0.4804 - val_accuracy: 0.7879\n",
            "Epoch 897/1500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4649 - accuracy: 0.7858 - val_loss: 0.4806 - val_accuracy: 0.7879\n",
            "Epoch 898/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4649 - accuracy: 0.7840 - val_loss: 0.4806 - val_accuracy: 0.7879\n",
            "Epoch 899/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4649 - accuracy: 0.7840 - val_loss: 0.4805 - val_accuracy: 0.7879\n",
            "Epoch 900/1500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.4648 - accuracy: 0.7821 - val_loss: 0.4803 - val_accuracy: 0.7879\n",
            "Epoch 901/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4647 - accuracy: 0.7858 - val_loss: 0.4802 - val_accuracy: 0.7879\n",
            "Epoch 902/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4646 - accuracy: 0.7821 - val_loss: 0.4802 - val_accuracy: 0.7879\n",
            "Epoch 903/1500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4644 - accuracy: 0.7840 - val_loss: 0.4801 - val_accuracy: 0.7879\n",
            "Epoch 904/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4644 - accuracy: 0.7858 - val_loss: 0.4802 - val_accuracy: 0.7879\n",
            "Epoch 905/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4644 - accuracy: 0.7840 - val_loss: 0.4799 - val_accuracy: 0.7879\n",
            "Epoch 906/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4643 - accuracy: 0.7821 - val_loss: 0.4798 - val_accuracy: 0.7879\n",
            "Epoch 907/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4642 - accuracy: 0.7840 - val_loss: 0.4797 - val_accuracy: 0.7879\n",
            "Epoch 908/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4642 - accuracy: 0.7840 - val_loss: 0.4798 - val_accuracy: 0.7879\n",
            "Epoch 909/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4642 - accuracy: 0.7858 - val_loss: 0.4798 - val_accuracy: 0.7879\n",
            "Epoch 910/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4641 - accuracy: 0.7877 - val_loss: 0.4796 - val_accuracy: 0.7879\n",
            "Epoch 911/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4641 - accuracy: 0.7858 - val_loss: 0.4797 - val_accuracy: 0.7879\n",
            "Epoch 912/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4639 - accuracy: 0.7858 - val_loss: 0.4797 - val_accuracy: 0.7879\n",
            "Epoch 913/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4639 - accuracy: 0.7840 - val_loss: 0.4796 - val_accuracy: 0.7879\n",
            "Epoch 914/1500\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7821 - val_loss: 0.4796 - val_accuracy: 0.7879\n",
            "Epoch 915/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4637 - accuracy: 0.7840 - val_loss: 0.4795 - val_accuracy: 0.7879\n",
            "Epoch 916/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4636 - accuracy: 0.7840 - val_loss: 0.4793 - val_accuracy: 0.7879\n",
            "Epoch 917/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4637 - accuracy: 0.7840 - val_loss: 0.4794 - val_accuracy: 0.7879\n",
            "Epoch 918/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4636 - accuracy: 0.7858 - val_loss: 0.4791 - val_accuracy: 0.7879\n",
            "Epoch 919/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4636 - accuracy: 0.7877 - val_loss: 0.4791 - val_accuracy: 0.7879\n",
            "Epoch 920/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4634 - accuracy: 0.7858 - val_loss: 0.4791 - val_accuracy: 0.7879\n",
            "Epoch 921/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4634 - accuracy: 0.7877 - val_loss: 0.4792 - val_accuracy: 0.7835\n",
            "Epoch 922/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4633 - accuracy: 0.7821 - val_loss: 0.4792 - val_accuracy: 0.7835\n",
            "Epoch 923/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4634 - accuracy: 0.7840 - val_loss: 0.4791 - val_accuracy: 0.7835\n",
            "Epoch 924/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4634 - accuracy: 0.7840 - val_loss: 0.4790 - val_accuracy: 0.7835\n",
            "Epoch 925/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4632 - accuracy: 0.7877 - val_loss: 0.4789 - val_accuracy: 0.7835\n",
            "Epoch 926/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4632 - accuracy: 0.7858 - val_loss: 0.4788 - val_accuracy: 0.7835\n",
            "Epoch 927/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4631 - accuracy: 0.7858 - val_loss: 0.4787 - val_accuracy: 0.7879\n",
            "Epoch 928/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4631 - accuracy: 0.7840 - val_loss: 0.4787 - val_accuracy: 0.7835\n",
            "Epoch 929/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4630 - accuracy: 0.7858 - val_loss: 0.4786 - val_accuracy: 0.7835\n",
            "Epoch 930/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4630 - accuracy: 0.7858 - val_loss: 0.4787 - val_accuracy: 0.7835\n",
            "Epoch 931/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4629 - accuracy: 0.7858 - val_loss: 0.4786 - val_accuracy: 0.7835\n",
            "Epoch 932/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4629 - accuracy: 0.7840 - val_loss: 0.4786 - val_accuracy: 0.7835\n",
            "Epoch 933/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4628 - accuracy: 0.7858 - val_loss: 0.4787 - val_accuracy: 0.7835\n",
            "Epoch 934/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4628 - accuracy: 0.7877 - val_loss: 0.4786 - val_accuracy: 0.7835\n",
            "Epoch 935/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4627 - accuracy: 0.7858 - val_loss: 0.4785 - val_accuracy: 0.7835\n",
            "Epoch 936/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4629 - accuracy: 0.7877 - val_loss: 0.4784 - val_accuracy: 0.7879\n",
            "Epoch 937/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4626 - accuracy: 0.7858 - val_loss: 0.4785 - val_accuracy: 0.7879\n",
            "Epoch 938/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4626 - accuracy: 0.7877 - val_loss: 0.4785 - val_accuracy: 0.7879\n",
            "Epoch 939/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4625 - accuracy: 0.7877 - val_loss: 0.4784 - val_accuracy: 0.7879\n",
            "Epoch 940/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4625 - accuracy: 0.7858 - val_loss: 0.4783 - val_accuracy: 0.7879\n",
            "Epoch 941/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4625 - accuracy: 0.7858 - val_loss: 0.4784 - val_accuracy: 0.7879\n",
            "Epoch 942/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4627 - accuracy: 0.7858 - val_loss: 0.4784 - val_accuracy: 0.7879\n",
            "Epoch 943/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4624 - accuracy: 0.7877 - val_loss: 0.4783 - val_accuracy: 0.7879\n",
            "Epoch 944/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4623 - accuracy: 0.7877 - val_loss: 0.4782 - val_accuracy: 0.7879\n",
            "Epoch 945/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4623 - accuracy: 0.7877 - val_loss: 0.4781 - val_accuracy: 0.7879\n",
            "Epoch 946/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4622 - accuracy: 0.7877 - val_loss: 0.4782 - val_accuracy: 0.7879\n",
            "Epoch 947/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4622 - accuracy: 0.7877 - val_loss: 0.4782 - val_accuracy: 0.7879\n",
            "Epoch 948/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4621 - accuracy: 0.7877 - val_loss: 0.4782 - val_accuracy: 0.7879\n",
            "Epoch 949/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4622 - accuracy: 0.7858 - val_loss: 0.4781 - val_accuracy: 0.7879\n",
            "Epoch 950/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4620 - accuracy: 0.7877 - val_loss: 0.4782 - val_accuracy: 0.7879\n",
            "Epoch 951/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4621 - accuracy: 0.7877 - val_loss: 0.4781 - val_accuracy: 0.7879\n",
            "Epoch 952/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4621 - accuracy: 0.7877 - val_loss: 0.4781 - val_accuracy: 0.7879\n",
            "Epoch 953/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.7877 - val_loss: 0.4781 - val_accuracy: 0.7879\n",
            "Epoch 954/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4619 - accuracy: 0.7840 - val_loss: 0.4782 - val_accuracy: 0.7922\n",
            "Epoch 955/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4619 - accuracy: 0.7858 - val_loss: 0.4782 - val_accuracy: 0.7879\n",
            "Epoch 956/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.7877 - val_loss: 0.4781 - val_accuracy: 0.7922\n",
            "Epoch 957/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4621 - accuracy: 0.7877 - val_loss: 0.4781 - val_accuracy: 0.7922\n",
            "Epoch 958/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4617 - accuracy: 0.7858 - val_loss: 0.4781 - val_accuracy: 0.7922\n",
            "Epoch 959/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4617 - accuracy: 0.7896 - val_loss: 0.4780 - val_accuracy: 0.7922\n",
            "Epoch 960/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4617 - accuracy: 0.7896 - val_loss: 0.4777 - val_accuracy: 0.7879\n",
            "Epoch 961/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4617 - accuracy: 0.7877 - val_loss: 0.4777 - val_accuracy: 0.7879\n",
            "Epoch 962/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4616 - accuracy: 0.7877 - val_loss: 0.4777 - val_accuracy: 0.7879\n",
            "Epoch 963/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4616 - accuracy: 0.7877 - val_loss: 0.4777 - val_accuracy: 0.7879\n",
            "Epoch 964/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4614 - accuracy: 0.7877 - val_loss: 0.4776 - val_accuracy: 0.7879\n",
            "Epoch 965/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4614 - accuracy: 0.7858 - val_loss: 0.4776 - val_accuracy: 0.7879\n",
            "Epoch 966/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4614 - accuracy: 0.7877 - val_loss: 0.4777 - val_accuracy: 0.7922\n",
            "Epoch 967/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4614 - accuracy: 0.7858 - val_loss: 0.4777 - val_accuracy: 0.7879\n",
            "Epoch 968/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4613 - accuracy: 0.7877 - val_loss: 0.4777 - val_accuracy: 0.7922\n",
            "Epoch 969/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4614 - accuracy: 0.7858 - val_loss: 0.4775 - val_accuracy: 0.7879\n",
            "Epoch 970/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4613 - accuracy: 0.7896 - val_loss: 0.4775 - val_accuracy: 0.7879\n",
            "Epoch 971/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4612 - accuracy: 0.7877 - val_loss: 0.4774 - val_accuracy: 0.7879\n",
            "Epoch 972/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4614 - accuracy: 0.7877 - val_loss: 0.4774 - val_accuracy: 0.7879\n",
            "Epoch 973/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4611 - accuracy: 0.7896 - val_loss: 0.4775 - val_accuracy: 0.7922\n",
            "Epoch 974/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4610 - accuracy: 0.7858 - val_loss: 0.4776 - val_accuracy: 0.7922\n",
            "Epoch 975/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4611 - accuracy: 0.7877 - val_loss: 0.4777 - val_accuracy: 0.7922\n",
            "Epoch 976/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4611 - accuracy: 0.7877 - val_loss: 0.4779 - val_accuracy: 0.7922\n",
            "Epoch 977/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4610 - accuracy: 0.7896 - val_loss: 0.4776 - val_accuracy: 0.7922\n",
            "Epoch 978/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4609 - accuracy: 0.7877 - val_loss: 0.4776 - val_accuracy: 0.7922\n",
            "Epoch 979/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4610 - accuracy: 0.7896 - val_loss: 0.4777 - val_accuracy: 0.7922\n",
            "Epoch 980/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4609 - accuracy: 0.7896 - val_loss: 0.4776 - val_accuracy: 0.7922\n",
            "Epoch 981/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4608 - accuracy: 0.7896 - val_loss: 0.4773 - val_accuracy: 0.7922\n",
            "Epoch 982/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4609 - accuracy: 0.7877 - val_loss: 0.4773 - val_accuracy: 0.7922\n",
            "Epoch 983/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4607 - accuracy: 0.7877 - val_loss: 0.4774 - val_accuracy: 0.7922\n",
            "Epoch 984/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4607 - accuracy: 0.7877 - val_loss: 0.4773 - val_accuracy: 0.7922\n",
            "Epoch 985/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4608 - accuracy: 0.7877 - val_loss: 0.4773 - val_accuracy: 0.7922\n",
            "Epoch 986/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4608 - accuracy: 0.7896 - val_loss: 0.4772 - val_accuracy: 0.7922\n",
            "Epoch 987/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4607 - accuracy: 0.7896 - val_loss: 0.4773 - val_accuracy: 0.7922\n",
            "Epoch 988/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4607 - accuracy: 0.7877 - val_loss: 0.4774 - val_accuracy: 0.7922\n",
            "Epoch 989/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4606 - accuracy: 0.7914 - val_loss: 0.4774 - val_accuracy: 0.7922\n",
            "Epoch 990/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4604 - accuracy: 0.7877 - val_loss: 0.4774 - val_accuracy: 0.7922\n",
            "Epoch 991/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4606 - accuracy: 0.7877 - val_loss: 0.4775 - val_accuracy: 0.7922\n",
            "Epoch 992/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.7896 - val_loss: 0.4775 - val_accuracy: 0.7922\n",
            "Epoch 993/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4605 - accuracy: 0.7896 - val_loss: 0.4774 - val_accuracy: 0.7922\n",
            "Epoch 994/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4603 - accuracy: 0.7896 - val_loss: 0.4775 - val_accuracy: 0.7922\n",
            "Epoch 995/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4603 - accuracy: 0.7896 - val_loss: 0.4776 - val_accuracy: 0.7922\n",
            "Epoch 996/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4603 - accuracy: 0.7896 - val_loss: 0.4775 - val_accuracy: 0.7922\n",
            "Epoch 997/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4602 - accuracy: 0.7896 - val_loss: 0.4775 - val_accuracy: 0.7922\n",
            "Epoch 998/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4601 - accuracy: 0.7877 - val_loss: 0.4773 - val_accuracy: 0.7922\n",
            "Epoch 999/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4601 - accuracy: 0.7896 - val_loss: 0.4775 - val_accuracy: 0.7922\n",
            "Epoch 1000/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4602 - accuracy: 0.7914 - val_loss: 0.4777 - val_accuracy: 0.7922\n",
            "Epoch 1001/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4601 - accuracy: 0.7896 - val_loss: 0.4776 - val_accuracy: 0.7922\n",
            "Epoch 1002/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4601 - accuracy: 0.7914 - val_loss: 0.4776 - val_accuracy: 0.7922\n",
            "Epoch 1003/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4601 - accuracy: 0.7896 - val_loss: 0.4776 - val_accuracy: 0.7922\n",
            "Epoch 1004/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4599 - accuracy: 0.7896 - val_loss: 0.4777 - val_accuracy: 0.7922\n",
            "Epoch 1005/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4599 - accuracy: 0.7877 - val_loss: 0.4775 - val_accuracy: 0.7922\n",
            "Epoch 1006/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4598 - accuracy: 0.7896 - val_loss: 0.4776 - val_accuracy: 0.7922\n",
            "Epoch 1007/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4598 - accuracy: 0.7914 - val_loss: 0.4776 - val_accuracy: 0.7922\n",
            "Epoch 1008/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4597 - accuracy: 0.7914 - val_loss: 0.4775 - val_accuracy: 0.7922\n",
            "Epoch 1009/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.7896 - val_loss: 0.4776 - val_accuracy: 0.7922\n",
            "Epoch 1010/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4596 - accuracy: 0.7877 - val_loss: 0.4774 - val_accuracy: 0.7922\n",
            "Epoch 1011/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.7914 - val_loss: 0.4775 - val_accuracy: 0.7922\n",
            "Epoch 1012/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4596 - accuracy: 0.7914 - val_loss: 0.4776 - val_accuracy: 0.7922\n",
            "Epoch 1013/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4596 - accuracy: 0.7896 - val_loss: 0.4775 - val_accuracy: 0.7922\n",
            "Epoch 1014/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4598 - accuracy: 0.7896 - val_loss: 0.4776 - val_accuracy: 0.7922\n",
            "Epoch 1015/1500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4597 - accuracy: 0.7896 - val_loss: 0.4774 - val_accuracy: 0.7922\n",
            "Epoch 1016/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4595 - accuracy: 0.7914 - val_loss: 0.4774 - val_accuracy: 0.7922\n",
            "Epoch 1017/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4594 - accuracy: 0.7896 - val_loss: 0.4775 - val_accuracy: 0.7922\n",
            "Epoch 1018/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4594 - accuracy: 0.7914 - val_loss: 0.4776 - val_accuracy: 0.7922\n",
            "Epoch 1019/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4594 - accuracy: 0.7914 - val_loss: 0.4776 - val_accuracy: 0.7922\n",
            "Epoch 1020/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4595 - accuracy: 0.7896 - val_loss: 0.4775 - val_accuracy: 0.7922\n",
            "Epoch 1021/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4594 - accuracy: 0.7877 - val_loss: 0.4774 - val_accuracy: 0.7922\n",
            "Epoch 1022/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4595 - accuracy: 0.7896 - val_loss: 0.4775 - val_accuracy: 0.7922\n",
            "Epoch 1023/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4593 - accuracy: 0.7896 - val_loss: 0.4773 - val_accuracy: 0.7922\n",
            "Epoch 1024/1500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4592 - accuracy: 0.7933 - val_loss: 0.4776 - val_accuracy: 0.7922\n",
            "Epoch 1025/1500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4593 - accuracy: 0.7914 - val_loss: 0.4777 - val_accuracy: 0.7922\n",
            "Epoch 1026/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4593 - accuracy: 0.7896 - val_loss: 0.4775 - val_accuracy: 0.7922\n",
            "Epoch 1027/1500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.4593 - accuracy: 0.7914 - val_loss: 0.4777 - val_accuracy: 0.7922\n",
            "Epoch 1028/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4592 - accuracy: 0.7914 - val_loss: 0.4776 - val_accuracy: 0.7922\n",
            "Epoch 1029/1500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4591 - accuracy: 0.7914 - val_loss: 0.4777 - val_accuracy: 0.7922\n",
            "Epoch 1030/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4590 - accuracy: 0.7877 - val_loss: 0.4776 - val_accuracy: 0.7922\n",
            "Epoch 1031/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4590 - accuracy: 0.7933 - val_loss: 0.4778 - val_accuracy: 0.7922\n",
            "Epoch 1032/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4591 - accuracy: 0.7896 - val_loss: 0.4779 - val_accuracy: 0.7922\n",
            "Epoch 1033/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4589 - accuracy: 0.7914 - val_loss: 0.4778 - val_accuracy: 0.7922\n",
            "Epoch 1034/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4588 - accuracy: 0.7914 - val_loss: 0.4778 - val_accuracy: 0.7922\n",
            "Epoch 1035/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4588 - accuracy: 0.7914 - val_loss: 0.4778 - val_accuracy: 0.7922\n",
            "Epoch 1036/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4588 - accuracy: 0.7896 - val_loss: 0.4777 - val_accuracy: 0.7922\n",
            "Epoch 1037/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4587 - accuracy: 0.7914 - val_loss: 0.4777 - val_accuracy: 0.7922\n",
            "Epoch 1038/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7914 - val_loss: 0.4778 - val_accuracy: 0.7922\n",
            "Epoch 1039/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4586 - accuracy: 0.7914 - val_loss: 0.4778 - val_accuracy: 0.7922\n",
            "Epoch 1040/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4587 - accuracy: 0.7914 - val_loss: 0.4779 - val_accuracy: 0.7922\n",
            "Epoch 1041/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4586 - accuracy: 0.7933 - val_loss: 0.4780 - val_accuracy: 0.7922\n",
            "Epoch 1042/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4587 - accuracy: 0.7914 - val_loss: 0.4780 - val_accuracy: 0.7922\n",
            "Epoch 1043/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4587 - accuracy: 0.7914 - val_loss: 0.4780 - val_accuracy: 0.7922\n",
            "Epoch 1044/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4585 - accuracy: 0.7914 - val_loss: 0.4781 - val_accuracy: 0.7922\n",
            "Epoch 1045/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4585 - accuracy: 0.7877 - val_loss: 0.4778 - val_accuracy: 0.7922\n",
            "Epoch 1046/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4585 - accuracy: 0.7914 - val_loss: 0.4780 - val_accuracy: 0.7922\n",
            "Epoch 1047/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4585 - accuracy: 0.7933 - val_loss: 0.4780 - val_accuracy: 0.7922\n",
            "Epoch 1048/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4584 - accuracy: 0.7914 - val_loss: 0.4781 - val_accuracy: 0.7922\n",
            "Epoch 1049/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4584 - accuracy: 0.7877 - val_loss: 0.4780 - val_accuracy: 0.7922\n",
            "Epoch 1050/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4584 - accuracy: 0.7914 - val_loss: 0.4782 - val_accuracy: 0.7922\n",
            "Epoch 1051/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4582 - accuracy: 0.7933 - val_loss: 0.4782 - val_accuracy: 0.7922\n",
            "Epoch 1052/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4581 - accuracy: 0.7896 - val_loss: 0.4784 - val_accuracy: 0.7922\n",
            "Epoch 1053/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4584 - accuracy: 0.7858 - val_loss: 0.4782 - val_accuracy: 0.7922\n",
            "Epoch 1054/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4581 - accuracy: 0.7896 - val_loss: 0.4782 - val_accuracy: 0.7922\n",
            "Epoch 1055/1500\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.4580 - accuracy: 0.7896 - val_loss: 0.4781 - val_accuracy: 0.7922\n",
            "Epoch 1056/1500\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 0.4580 - accuracy: 0.7914 - val_loss: 0.4783 - val_accuracy: 0.7922\n",
            "Epoch 1057/1500\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.4578 - accuracy: 0.7877 - val_loss: 0.4783 - val_accuracy: 0.7922\n",
            "Epoch 1058/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4580 - accuracy: 0.7896 - val_loss: 0.4783 - val_accuracy: 0.7922\n",
            "Epoch 1059/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4579 - accuracy: 0.7877 - val_loss: 0.4784 - val_accuracy: 0.7922\n",
            "Epoch 1060/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4576 - accuracy: 0.7914 - val_loss: 0.4784 - val_accuracy: 0.7922\n",
            "Epoch 1061/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4576 - accuracy: 0.7914 - val_loss: 0.4786 - val_accuracy: 0.7922\n",
            "Epoch 1062/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4577 - accuracy: 0.7858 - val_loss: 0.4784 - val_accuracy: 0.7922\n",
            "Epoch 1063/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4575 - accuracy: 0.7914 - val_loss: 0.4786 - val_accuracy: 0.7922\n",
            "Epoch 1064/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4575 - accuracy: 0.7877 - val_loss: 0.4785 - val_accuracy: 0.7922\n",
            "Epoch 1065/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4574 - accuracy: 0.7896 - val_loss: 0.4787 - val_accuracy: 0.7922\n",
            "Epoch 1066/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4576 - accuracy: 0.7877 - val_loss: 0.4786 - val_accuracy: 0.7922\n",
            "Epoch 1067/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4572 - accuracy: 0.7877 - val_loss: 0.4785 - val_accuracy: 0.7922\n",
            "Epoch 1068/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4573 - accuracy: 0.7914 - val_loss: 0.4787 - val_accuracy: 0.7922\n",
            "Epoch 1069/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4572 - accuracy: 0.7914 - val_loss: 0.4788 - val_accuracy: 0.7922\n",
            "Epoch 1070/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4572 - accuracy: 0.7877 - val_loss: 0.4787 - val_accuracy: 0.7922\n",
            "Epoch 1071/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4571 - accuracy: 0.7914 - val_loss: 0.4786 - val_accuracy: 0.7922\n",
            "Epoch 1072/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4570 - accuracy: 0.7914 - val_loss: 0.4787 - val_accuracy: 0.7922\n",
            "Epoch 1073/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4572 - accuracy: 0.7896 - val_loss: 0.4784 - val_accuracy: 0.7922\n",
            "Epoch 1074/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4569 - accuracy: 0.7877 - val_loss: 0.4783 - val_accuracy: 0.7922\n",
            "Epoch 1075/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4570 - accuracy: 0.7896 - val_loss: 0.4784 - val_accuracy: 0.7922\n",
            "Epoch 1076/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4568 - accuracy: 0.7896 - val_loss: 0.4786 - val_accuracy: 0.7922\n",
            "Epoch 1077/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4569 - accuracy: 0.7914 - val_loss: 0.4788 - val_accuracy: 0.7922\n",
            "Epoch 1078/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4568 - accuracy: 0.7877 - val_loss: 0.4787 - val_accuracy: 0.7922\n",
            "Epoch 1079/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4567 - accuracy: 0.7914 - val_loss: 0.4788 - val_accuracy: 0.7922\n",
            "Epoch 1080/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4567 - accuracy: 0.7896 - val_loss: 0.4788 - val_accuracy: 0.7922\n",
            "Epoch 1081/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4566 - accuracy: 0.7914 - val_loss: 0.4789 - val_accuracy: 0.7922\n",
            "Epoch 1082/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4566 - accuracy: 0.7896 - val_loss: 0.4787 - val_accuracy: 0.7922\n",
            "Epoch 1083/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4566 - accuracy: 0.7896 - val_loss: 0.4787 - val_accuracy: 0.7922\n",
            "Epoch 1084/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4567 - accuracy: 0.7933 - val_loss: 0.4789 - val_accuracy: 0.7922\n",
            "Epoch 1085/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4565 - accuracy: 0.7896 - val_loss: 0.4787 - val_accuracy: 0.7922\n",
            "Epoch 1086/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4564 - accuracy: 0.7896 - val_loss: 0.4787 - val_accuracy: 0.7922\n",
            "Epoch 1087/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4564 - accuracy: 0.7933 - val_loss: 0.4789 - val_accuracy: 0.7922\n",
            "Epoch 1088/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4564 - accuracy: 0.7914 - val_loss: 0.4788 - val_accuracy: 0.7922\n",
            "Epoch 1089/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4563 - accuracy: 0.7933 - val_loss: 0.4789 - val_accuracy: 0.7922\n",
            "Epoch 1090/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4562 - accuracy: 0.7914 - val_loss: 0.4791 - val_accuracy: 0.7922\n",
            "Epoch 1091/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4563 - accuracy: 0.7877 - val_loss: 0.4791 - val_accuracy: 0.7922\n",
            "Epoch 1092/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4562 - accuracy: 0.7877 - val_loss: 0.4792 - val_accuracy: 0.7922\n",
            "Epoch 1093/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4563 - accuracy: 0.7914 - val_loss: 0.4791 - val_accuracy: 0.7922\n",
            "Epoch 1094/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4561 - accuracy: 0.7896 - val_loss: 0.4793 - val_accuracy: 0.7922\n",
            "Epoch 1095/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4561 - accuracy: 0.7914 - val_loss: 0.4790 - val_accuracy: 0.7922\n",
            "Epoch 1096/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4561 - accuracy: 0.7914 - val_loss: 0.4791 - val_accuracy: 0.7922\n",
            "Epoch 1097/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4560 - accuracy: 0.7914 - val_loss: 0.4792 - val_accuracy: 0.7922\n",
            "Epoch 1098/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4560 - accuracy: 0.7914 - val_loss: 0.4791 - val_accuracy: 0.7922\n",
            "Epoch 1099/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4559 - accuracy: 0.7858 - val_loss: 0.4791 - val_accuracy: 0.7922\n",
            "Epoch 1100/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4559 - accuracy: 0.7933 - val_loss: 0.4794 - val_accuracy: 0.7922\n",
            "Epoch 1101/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4560 - accuracy: 0.7896 - val_loss: 0.4792 - val_accuracy: 0.7922\n",
            "Epoch 1102/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4558 - accuracy: 0.7896 - val_loss: 0.4792 - val_accuracy: 0.7922\n",
            "Epoch 1103/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4558 - accuracy: 0.7877 - val_loss: 0.4791 - val_accuracy: 0.7922\n",
            "Epoch 1104/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4558 - accuracy: 0.7914 - val_loss: 0.4791 - val_accuracy: 0.7922\n",
            "Epoch 1105/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4558 - accuracy: 0.7914 - val_loss: 0.4791 - val_accuracy: 0.7922\n",
            "Epoch 1106/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4559 - accuracy: 0.7896 - val_loss: 0.4790 - val_accuracy: 0.7922\n",
            "Epoch 1107/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4556 - accuracy: 0.7914 - val_loss: 0.4792 - val_accuracy: 0.7922\n",
            "Epoch 1108/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4556 - accuracy: 0.7877 - val_loss: 0.4790 - val_accuracy: 0.7922\n",
            "Epoch 1109/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4556 - accuracy: 0.7896 - val_loss: 0.4790 - val_accuracy: 0.7922\n",
            "Epoch 1110/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4556 - accuracy: 0.7896 - val_loss: 0.4791 - val_accuracy: 0.7922\n",
            "Epoch 1111/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4555 - accuracy: 0.7896 - val_loss: 0.4794 - val_accuracy: 0.7922\n",
            "Epoch 1112/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4554 - accuracy: 0.7896 - val_loss: 0.4791 - val_accuracy: 0.7922\n",
            "Epoch 1113/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4555 - accuracy: 0.7914 - val_loss: 0.4796 - val_accuracy: 0.7922\n",
            "Epoch 1114/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4553 - accuracy: 0.7914 - val_loss: 0.4796 - val_accuracy: 0.7922\n",
            "Epoch 1115/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4554 - accuracy: 0.7914 - val_loss: 0.4795 - val_accuracy: 0.7922\n",
            "Epoch 1116/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4553 - accuracy: 0.7896 - val_loss: 0.4796 - val_accuracy: 0.7922\n",
            "Epoch 1117/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4552 - accuracy: 0.7896 - val_loss: 0.4797 - val_accuracy: 0.7922\n",
            "Epoch 1118/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4553 - accuracy: 0.7896 - val_loss: 0.4799 - val_accuracy: 0.7922\n",
            "Epoch 1119/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4552 - accuracy: 0.7896 - val_loss: 0.4799 - val_accuracy: 0.7922\n",
            "Epoch 1120/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4551 - accuracy: 0.7896 - val_loss: 0.4797 - val_accuracy: 0.7922\n",
            "Epoch 1121/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4552 - accuracy: 0.7914 - val_loss: 0.4797 - val_accuracy: 0.7922\n",
            "Epoch 1122/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4551 - accuracy: 0.7896 - val_loss: 0.4797 - val_accuracy: 0.7922\n",
            "Epoch 1123/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4552 - accuracy: 0.7914 - val_loss: 0.4797 - val_accuracy: 0.7922\n",
            "Epoch 1124/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4551 - accuracy: 0.7896 - val_loss: 0.4796 - val_accuracy: 0.7922\n",
            "Epoch 1125/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4550 - accuracy: 0.7896 - val_loss: 0.4796 - val_accuracy: 0.7922\n",
            "Epoch 1126/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4551 - accuracy: 0.7914 - val_loss: 0.4798 - val_accuracy: 0.7922\n",
            "Epoch 1127/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4550 - accuracy: 0.7877 - val_loss: 0.4793 - val_accuracy: 0.7922\n",
            "Epoch 1128/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4550 - accuracy: 0.7896 - val_loss: 0.4796 - val_accuracy: 0.7922\n",
            "Epoch 1129/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4550 - accuracy: 0.7914 - val_loss: 0.4796 - val_accuracy: 0.7922\n",
            "Epoch 1130/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4549 - accuracy: 0.7896 - val_loss: 0.4798 - val_accuracy: 0.7922\n",
            "Epoch 1131/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4548 - accuracy: 0.7840 - val_loss: 0.4796 - val_accuracy: 0.7922\n",
            "Epoch 1132/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4550 - accuracy: 0.7877 - val_loss: 0.4793 - val_accuracy: 0.7922\n",
            "Epoch 1133/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4549 - accuracy: 0.7896 - val_loss: 0.4795 - val_accuracy: 0.7922\n",
            "Epoch 1134/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4547 - accuracy: 0.7914 - val_loss: 0.4793 - val_accuracy: 0.7922\n",
            "Epoch 1135/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4547 - accuracy: 0.7877 - val_loss: 0.4795 - val_accuracy: 0.7922\n",
            "Epoch 1136/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4548 - accuracy: 0.7896 - val_loss: 0.4793 - val_accuracy: 0.7922\n",
            "Epoch 1137/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4547 - accuracy: 0.7896 - val_loss: 0.4793 - val_accuracy: 0.7922\n",
            "Epoch 1138/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4546 - accuracy: 0.7896 - val_loss: 0.4794 - val_accuracy: 0.7922\n",
            "Epoch 1139/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4545 - accuracy: 0.7914 - val_loss: 0.4792 - val_accuracy: 0.7922\n",
            "Epoch 1140/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4546 - accuracy: 0.7896 - val_loss: 0.4795 - val_accuracy: 0.7922\n",
            "Epoch 1141/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4544 - accuracy: 0.7877 - val_loss: 0.4795 - val_accuracy: 0.7922\n",
            "Epoch 1142/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4545 - accuracy: 0.7933 - val_loss: 0.4797 - val_accuracy: 0.7922\n",
            "Epoch 1143/1500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.4543 - accuracy: 0.7896 - val_loss: 0.4795 - val_accuracy: 0.7922\n",
            "Epoch 1144/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4544 - accuracy: 0.7877 - val_loss: 0.4794 - val_accuracy: 0.7922\n",
            "Epoch 1145/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4543 - accuracy: 0.7896 - val_loss: 0.4798 - val_accuracy: 0.7922\n",
            "Epoch 1146/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4543 - accuracy: 0.7877 - val_loss: 0.4796 - val_accuracy: 0.7922\n",
            "Epoch 1147/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4544 - accuracy: 0.7877 - val_loss: 0.4794 - val_accuracy: 0.7922\n",
            "Epoch 1148/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4543 - accuracy: 0.7896 - val_loss: 0.4795 - val_accuracy: 0.7922\n",
            "Epoch 1149/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4544 - accuracy: 0.7877 - val_loss: 0.4794 - val_accuracy: 0.7922\n",
            "Epoch 1150/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4543 - accuracy: 0.7914 - val_loss: 0.4796 - val_accuracy: 0.7922\n",
            "Epoch 1151/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4541 - accuracy: 0.7914 - val_loss: 0.4796 - val_accuracy: 0.7922\n",
            "Epoch 1152/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4542 - accuracy: 0.7896 - val_loss: 0.4797 - val_accuracy: 0.7922\n",
            "Epoch 1153/1500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4542 - accuracy: 0.7896 - val_loss: 0.4799 - val_accuracy: 0.7922\n",
            "Epoch 1154/1500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4541 - accuracy: 0.7896 - val_loss: 0.4799 - val_accuracy: 0.7922\n",
            "Epoch 1155/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4541 - accuracy: 0.7896 - val_loss: 0.4797 - val_accuracy: 0.7922\n",
            "Epoch 1156/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4540 - accuracy: 0.7933 - val_loss: 0.4799 - val_accuracy: 0.7922\n",
            "Epoch 1157/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4540 - accuracy: 0.7896 - val_loss: 0.4800 - val_accuracy: 0.7922\n",
            "Epoch 1158/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4540 - accuracy: 0.7914 - val_loss: 0.4801 - val_accuracy: 0.7922\n",
            "Epoch 1159/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4540 - accuracy: 0.7877 - val_loss: 0.4800 - val_accuracy: 0.7922\n",
            "Epoch 1160/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4539 - accuracy: 0.7933 - val_loss: 0.4797 - val_accuracy: 0.7922\n",
            "Epoch 1161/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4539 - accuracy: 0.7896 - val_loss: 0.4798 - val_accuracy: 0.7922\n",
            "Epoch 1162/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4539 - accuracy: 0.7914 - val_loss: 0.4799 - val_accuracy: 0.7922\n",
            "Epoch 1163/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4540 - accuracy: 0.7896 - val_loss: 0.4803 - val_accuracy: 0.7922\n",
            "Epoch 1164/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4538 - accuracy: 0.7877 - val_loss: 0.4799 - val_accuracy: 0.7922\n",
            "Epoch 1165/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4537 - accuracy: 0.7877 - val_loss: 0.4800 - val_accuracy: 0.7922\n",
            "Epoch 1166/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4539 - accuracy: 0.7914 - val_loss: 0.4804 - val_accuracy: 0.7922\n",
            "Epoch 1167/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4538 - accuracy: 0.7896 - val_loss: 0.4803 - val_accuracy: 0.7922\n",
            "Epoch 1168/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4538 - accuracy: 0.7896 - val_loss: 0.4803 - val_accuracy: 0.7922\n",
            "Epoch 1169/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4538 - accuracy: 0.7914 - val_loss: 0.4801 - val_accuracy: 0.7922\n",
            "Epoch 1170/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4536 - accuracy: 0.7877 - val_loss: 0.4800 - val_accuracy: 0.7922\n",
            "Epoch 1171/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4537 - accuracy: 0.7896 - val_loss: 0.4797 - val_accuracy: 0.7922\n",
            "Epoch 1172/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4537 - accuracy: 0.7914 - val_loss: 0.4799 - val_accuracy: 0.7922\n",
            "Epoch 1173/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4537 - accuracy: 0.7933 - val_loss: 0.4801 - val_accuracy: 0.7922\n",
            "Epoch 1174/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4537 - accuracy: 0.7896 - val_loss: 0.4800 - val_accuracy: 0.7922\n",
            "Epoch 1175/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4536 - accuracy: 0.7914 - val_loss: 0.4800 - val_accuracy: 0.7922\n",
            "Epoch 1176/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4535 - accuracy: 0.7933 - val_loss: 0.4803 - val_accuracy: 0.7922\n",
            "Epoch 1177/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4535 - accuracy: 0.7914 - val_loss: 0.4800 - val_accuracy: 0.7922\n",
            "Epoch 1178/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4535 - accuracy: 0.7933 - val_loss: 0.4802 - val_accuracy: 0.7922\n",
            "Epoch 1179/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4534 - accuracy: 0.7896 - val_loss: 0.4801 - val_accuracy: 0.7922\n",
            "Epoch 1180/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4533 - accuracy: 0.7896 - val_loss: 0.4801 - val_accuracy: 0.7922\n",
            "Epoch 1181/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4534 - accuracy: 0.7896 - val_loss: 0.4802 - val_accuracy: 0.7922\n",
            "Epoch 1182/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4533 - accuracy: 0.7914 - val_loss: 0.4801 - val_accuracy: 0.7922\n",
            "Epoch 1183/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4534 - accuracy: 0.7896 - val_loss: 0.4801 - val_accuracy: 0.7922\n",
            "Epoch 1184/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4532 - accuracy: 0.7914 - val_loss: 0.4797 - val_accuracy: 0.7922\n",
            "Epoch 1185/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4534 - accuracy: 0.7914 - val_loss: 0.4801 - val_accuracy: 0.7922\n",
            "Epoch 1186/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4532 - accuracy: 0.7896 - val_loss: 0.4801 - val_accuracy: 0.7922\n",
            "Epoch 1187/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4531 - accuracy: 0.7896 - val_loss: 0.4801 - val_accuracy: 0.7922\n",
            "Epoch 1188/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4530 - accuracy: 0.7914 - val_loss: 0.4799 - val_accuracy: 0.7922\n",
            "Epoch 1189/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4532 - accuracy: 0.7933 - val_loss: 0.4802 - val_accuracy: 0.7922\n",
            "Epoch 1190/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4531 - accuracy: 0.7914 - val_loss: 0.4799 - val_accuracy: 0.7922\n",
            "Epoch 1191/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4531 - accuracy: 0.7933 - val_loss: 0.4800 - val_accuracy: 0.7922\n",
            "Epoch 1192/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4529 - accuracy: 0.7914 - val_loss: 0.4798 - val_accuracy: 0.7922\n",
            "Epoch 1193/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4531 - accuracy: 0.7896 - val_loss: 0.4803 - val_accuracy: 0.7922\n",
            "Epoch 1194/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4528 - accuracy: 0.7914 - val_loss: 0.4801 - val_accuracy: 0.7922\n",
            "Epoch 1195/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4530 - accuracy: 0.7914 - val_loss: 0.4800 - val_accuracy: 0.7922\n",
            "Epoch 1196/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4529 - accuracy: 0.7914 - val_loss: 0.4802 - val_accuracy: 0.7922\n",
            "Epoch 1197/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4529 - accuracy: 0.7933 - val_loss: 0.4802 - val_accuracy: 0.7922\n",
            "Epoch 1198/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4528 - accuracy: 0.7933 - val_loss: 0.4803 - val_accuracy: 0.7922\n",
            "Epoch 1199/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4529 - accuracy: 0.7896 - val_loss: 0.4801 - val_accuracy: 0.7922\n",
            "Epoch 1200/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4527 - accuracy: 0.7933 - val_loss: 0.4802 - val_accuracy: 0.7922\n",
            "Epoch 1201/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4529 - accuracy: 0.7933 - val_loss: 0.4807 - val_accuracy: 0.7922\n",
            "Epoch 1202/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4527 - accuracy: 0.7933 - val_loss: 0.4807 - val_accuracy: 0.7922\n",
            "Epoch 1203/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4528 - accuracy: 0.7896 - val_loss: 0.4798 - val_accuracy: 0.7922\n",
            "Epoch 1204/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4529 - accuracy: 0.7914 - val_loss: 0.4799 - val_accuracy: 0.7922\n",
            "Epoch 1205/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4527 - accuracy: 0.7933 - val_loss: 0.4802 - val_accuracy: 0.7922\n",
            "Epoch 1206/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4527 - accuracy: 0.7914 - val_loss: 0.4803 - val_accuracy: 0.7922\n",
            "Epoch 1207/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4529 - accuracy: 0.7896 - val_loss: 0.4804 - val_accuracy: 0.7922\n",
            "Epoch 1208/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4526 - accuracy: 0.7896 - val_loss: 0.4806 - val_accuracy: 0.7922\n",
            "Epoch 1209/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4526 - accuracy: 0.7952 - val_loss: 0.4808 - val_accuracy: 0.7922\n",
            "Epoch 1210/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4524 - accuracy: 0.7933 - val_loss: 0.4807 - val_accuracy: 0.7922\n",
            "Epoch 1211/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4525 - accuracy: 0.7933 - val_loss: 0.4808 - val_accuracy: 0.7922\n",
            "Epoch 1212/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4525 - accuracy: 0.7896 - val_loss: 0.4807 - val_accuracy: 0.7922\n",
            "Epoch 1213/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4524 - accuracy: 0.7933 - val_loss: 0.4809 - val_accuracy: 0.7922\n",
            "Epoch 1214/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4523 - accuracy: 0.7914 - val_loss: 0.4809 - val_accuracy: 0.7922\n",
            "Epoch 1215/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4523 - accuracy: 0.7914 - val_loss: 0.4809 - val_accuracy: 0.7922\n",
            "Epoch 1216/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4524 - accuracy: 0.7914 - val_loss: 0.4811 - val_accuracy: 0.7922\n",
            "Epoch 1217/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4524 - accuracy: 0.7914 - val_loss: 0.4806 - val_accuracy: 0.7922\n",
            "Epoch 1218/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4524 - accuracy: 0.7933 - val_loss: 0.4806 - val_accuracy: 0.7922\n",
            "Epoch 1219/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4522 - accuracy: 0.7933 - val_loss: 0.4809 - val_accuracy: 0.7922\n",
            "Epoch 1220/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4522 - accuracy: 0.7933 - val_loss: 0.4809 - val_accuracy: 0.7922\n",
            "Epoch 1221/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4522 - accuracy: 0.7933 - val_loss: 0.4810 - val_accuracy: 0.7922\n",
            "Epoch 1222/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4521 - accuracy: 0.7914 - val_loss: 0.4810 - val_accuracy: 0.7922\n",
            "Epoch 1223/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4521 - accuracy: 0.7933 - val_loss: 0.4810 - val_accuracy: 0.7922\n",
            "Epoch 1224/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4520 - accuracy: 0.7933 - val_loss: 0.4808 - val_accuracy: 0.7922\n",
            "Epoch 1225/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4522 - accuracy: 0.7933 - val_loss: 0.4811 - val_accuracy: 0.7922\n",
            "Epoch 1226/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4520 - accuracy: 0.7914 - val_loss: 0.4811 - val_accuracy: 0.7922\n",
            "Epoch 1227/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4519 - accuracy: 0.7914 - val_loss: 0.4810 - val_accuracy: 0.7922\n",
            "Epoch 1228/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4520 - accuracy: 0.7914 - val_loss: 0.4812 - val_accuracy: 0.7922\n",
            "Epoch 1229/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4519 - accuracy: 0.7914 - val_loss: 0.4809 - val_accuracy: 0.7922\n",
            "Epoch 1230/1500\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 0.4519 - accuracy: 0.7933 - val_loss: 0.4811 - val_accuracy: 0.7922\n",
            "Epoch 1231/1500\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 0.4517 - accuracy: 0.7933 - val_loss: 0.4815 - val_accuracy: 0.7922\n",
            "Epoch 1232/1500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.4519 - accuracy: 0.7952 - val_loss: 0.4812 - val_accuracy: 0.7922\n",
            "Epoch 1233/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4518 - accuracy: 0.7952 - val_loss: 0.4809 - val_accuracy: 0.7922\n",
            "Epoch 1234/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4519 - accuracy: 0.7933 - val_loss: 0.4813 - val_accuracy: 0.7922\n",
            "Epoch 1235/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4516 - accuracy: 0.7933 - val_loss: 0.4813 - val_accuracy: 0.7922\n",
            "Epoch 1236/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4516 - accuracy: 0.7952 - val_loss: 0.4815 - val_accuracy: 0.7922\n",
            "Epoch 1237/1500\n",
            "17/17 [==============================] - 0s 25ms/step - loss: 0.4518 - accuracy: 0.7933 - val_loss: 0.4814 - val_accuracy: 0.7922\n",
            "Epoch 1238/1500\n",
            "17/17 [==============================] - 0s 25ms/step - loss: 0.4517 - accuracy: 0.7933 - val_loss: 0.4813 - val_accuracy: 0.7922\n",
            "Epoch 1239/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4516 - accuracy: 0.7933 - val_loss: 0.4812 - val_accuracy: 0.7922\n",
            "Epoch 1240/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4514 - accuracy: 0.7914 - val_loss: 0.4812 - val_accuracy: 0.7922\n",
            "Epoch 1241/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4515 - accuracy: 0.7914 - val_loss: 0.4810 - val_accuracy: 0.7922\n",
            "Epoch 1242/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4515 - accuracy: 0.7933 - val_loss: 0.4813 - val_accuracy: 0.7922\n",
            "Epoch 1243/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4512 - accuracy: 0.7914 - val_loss: 0.4811 - val_accuracy: 0.7922\n",
            "Epoch 1244/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4513 - accuracy: 0.7933 - val_loss: 0.4813 - val_accuracy: 0.7922\n",
            "Epoch 1245/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4512 - accuracy: 0.7970 - val_loss: 0.4815 - val_accuracy: 0.7922\n",
            "Epoch 1246/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4513 - accuracy: 0.7914 - val_loss: 0.4813 - val_accuracy: 0.7922\n",
            "Epoch 1247/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4511 - accuracy: 0.7933 - val_loss: 0.4814 - val_accuracy: 0.7922\n",
            "Epoch 1248/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4511 - accuracy: 0.7933 - val_loss: 0.4815 - val_accuracy: 0.7922\n",
            "Epoch 1249/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4511 - accuracy: 0.7933 - val_loss: 0.4813 - val_accuracy: 0.7922\n",
            "Epoch 1250/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4511 - accuracy: 0.7952 - val_loss: 0.4811 - val_accuracy: 0.7922\n",
            "Epoch 1251/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4511 - accuracy: 0.7970 - val_loss: 0.4814 - val_accuracy: 0.7922\n",
            "Epoch 1252/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4511 - accuracy: 0.7952 - val_loss: 0.4815 - val_accuracy: 0.7922\n",
            "Epoch 1253/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4509 - accuracy: 0.7914 - val_loss: 0.4817 - val_accuracy: 0.7922\n",
            "Epoch 1254/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4510 - accuracy: 0.7933 - val_loss: 0.4819 - val_accuracy: 0.7922\n",
            "Epoch 1255/1500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4509 - accuracy: 0.7952 - val_loss: 0.4815 - val_accuracy: 0.7922\n",
            "Epoch 1256/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4509 - accuracy: 0.7952 - val_loss: 0.4818 - val_accuracy: 0.7922\n",
            "Epoch 1257/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4508 - accuracy: 0.7933 - val_loss: 0.4818 - val_accuracy: 0.7922\n",
            "Epoch 1258/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4507 - accuracy: 0.7914 - val_loss: 0.4820 - val_accuracy: 0.7922\n",
            "Epoch 1259/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4507 - accuracy: 0.7952 - val_loss: 0.4820 - val_accuracy: 0.7922\n",
            "Epoch 1260/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4506 - accuracy: 0.7933 - val_loss: 0.4818 - val_accuracy: 0.7922\n",
            "Epoch 1261/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4507 - accuracy: 0.7952 - val_loss: 0.4817 - val_accuracy: 0.7922\n",
            "Epoch 1262/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4505 - accuracy: 0.7970 - val_loss: 0.4819 - val_accuracy: 0.7922\n",
            "Epoch 1263/1500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.4505 - accuracy: 0.7970 - val_loss: 0.4815 - val_accuracy: 0.7922\n",
            "Epoch 1264/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4507 - accuracy: 0.7952 - val_loss: 0.4811 - val_accuracy: 0.7922\n",
            "Epoch 1265/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4504 - accuracy: 0.7933 - val_loss: 0.4815 - val_accuracy: 0.7922\n",
            "Epoch 1266/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4504 - accuracy: 0.7914 - val_loss: 0.4816 - val_accuracy: 0.7922\n",
            "Epoch 1267/1500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.4505 - accuracy: 0.7970 - val_loss: 0.4820 - val_accuracy: 0.7922\n",
            "Epoch 1268/1500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.4502 - accuracy: 0.7952 - val_loss: 0.4817 - val_accuracy: 0.7922\n",
            "Epoch 1269/1500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.4502 - accuracy: 0.7970 - val_loss: 0.4820 - val_accuracy: 0.7922\n",
            "Epoch 1270/1500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.4503 - accuracy: 0.7970 - val_loss: 0.4818 - val_accuracy: 0.7922\n",
            "Epoch 1271/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4502 - accuracy: 0.7952 - val_loss: 0.4820 - val_accuracy: 0.7922\n",
            "Epoch 1272/1500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4502 - accuracy: 0.7933 - val_loss: 0.4823 - val_accuracy: 0.7922\n",
            "Epoch 1273/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4502 - accuracy: 0.7952 - val_loss: 0.4823 - val_accuracy: 0.7922\n",
            "Epoch 1274/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4502 - accuracy: 0.7970 - val_loss: 0.4821 - val_accuracy: 0.7922\n",
            "Epoch 1275/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4499 - accuracy: 0.7933 - val_loss: 0.4816 - val_accuracy: 0.7922\n",
            "Epoch 1276/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4501 - accuracy: 0.7989 - val_loss: 0.4818 - val_accuracy: 0.7922\n",
            "Epoch 1277/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4500 - accuracy: 0.7933 - val_loss: 0.4820 - val_accuracy: 0.7922\n",
            "Epoch 1278/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4498 - accuracy: 0.7933 - val_loss: 0.4818 - val_accuracy: 0.7922\n",
            "Epoch 1279/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4500 - accuracy: 0.7952 - val_loss: 0.4823 - val_accuracy: 0.7922\n",
            "Epoch 1280/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4498 - accuracy: 0.7933 - val_loss: 0.4826 - val_accuracy: 0.7922\n",
            "Epoch 1281/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4499 - accuracy: 0.7952 - val_loss: 0.4822 - val_accuracy: 0.7922\n",
            "Epoch 1282/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4498 - accuracy: 0.7952 - val_loss: 0.4826 - val_accuracy: 0.7922\n",
            "Epoch 1283/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4497 - accuracy: 0.7952 - val_loss: 0.4824 - val_accuracy: 0.7922\n",
            "Epoch 1284/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4497 - accuracy: 0.7914 - val_loss: 0.4824 - val_accuracy: 0.7922\n",
            "Epoch 1285/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4497 - accuracy: 0.7952 - val_loss: 0.4822 - val_accuracy: 0.7922\n",
            "Epoch 1286/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4495 - accuracy: 0.7989 - val_loss: 0.4821 - val_accuracy: 0.7922\n",
            "Epoch 1287/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4495 - accuracy: 0.7952 - val_loss: 0.4822 - val_accuracy: 0.7922\n",
            "Epoch 1288/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4495 - accuracy: 0.7989 - val_loss: 0.4827 - val_accuracy: 0.7922\n",
            "Epoch 1289/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4495 - accuracy: 0.7952 - val_loss: 0.4826 - val_accuracy: 0.7922\n",
            "Epoch 1290/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4495 - accuracy: 0.7952 - val_loss: 0.4820 - val_accuracy: 0.7922\n",
            "Epoch 1291/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4493 - accuracy: 0.7933 - val_loss: 0.4822 - val_accuracy: 0.7922\n",
            "Epoch 1292/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4493 - accuracy: 0.7952 - val_loss: 0.4823 - val_accuracy: 0.7922\n",
            "Epoch 1293/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4494 - accuracy: 0.7970 - val_loss: 0.4826 - val_accuracy: 0.7922\n",
            "Epoch 1294/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4492 - accuracy: 0.7989 - val_loss: 0.4825 - val_accuracy: 0.7922\n",
            "Epoch 1295/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4493 - accuracy: 0.7970 - val_loss: 0.4825 - val_accuracy: 0.7922\n",
            "Epoch 1296/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4494 - accuracy: 0.7952 - val_loss: 0.4827 - val_accuracy: 0.7922\n",
            "Epoch 1297/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4492 - accuracy: 0.7952 - val_loss: 0.4828 - val_accuracy: 0.7922\n",
            "Epoch 1298/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4490 - accuracy: 0.7970 - val_loss: 0.4829 - val_accuracy: 0.7922\n",
            "Epoch 1299/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4491 - accuracy: 0.7970 - val_loss: 0.4831 - val_accuracy: 0.7922\n",
            "Epoch 1300/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4490 - accuracy: 0.7933 - val_loss: 0.4827 - val_accuracy: 0.7922\n",
            "Epoch 1301/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4490 - accuracy: 0.7989 - val_loss: 0.4826 - val_accuracy: 0.7922\n",
            "Epoch 1302/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4489 - accuracy: 0.7970 - val_loss: 0.4830 - val_accuracy: 0.7922\n",
            "Epoch 1303/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.7989 - val_loss: 0.4830 - val_accuracy: 0.7922\n",
            "Epoch 1304/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4488 - accuracy: 0.7970 - val_loss: 0.4834 - val_accuracy: 0.7922\n",
            "Epoch 1305/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4489 - accuracy: 0.7970 - val_loss: 0.4832 - val_accuracy: 0.7922\n",
            "Epoch 1306/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4487 - accuracy: 0.7989 - val_loss: 0.4833 - val_accuracy: 0.7922\n",
            "Epoch 1307/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4487 - accuracy: 0.7952 - val_loss: 0.4832 - val_accuracy: 0.7922\n",
            "Epoch 1308/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4488 - accuracy: 0.7989 - val_loss: 0.4832 - val_accuracy: 0.7922\n",
            "Epoch 1309/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4486 - accuracy: 0.7952 - val_loss: 0.4833 - val_accuracy: 0.7922\n",
            "Epoch 1310/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4486 - accuracy: 0.7970 - val_loss: 0.4831 - val_accuracy: 0.7922\n",
            "Epoch 1311/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4488 - accuracy: 0.7970 - val_loss: 0.4832 - val_accuracy: 0.7922\n",
            "Epoch 1312/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4485 - accuracy: 0.7970 - val_loss: 0.4835 - val_accuracy: 0.7922\n",
            "Epoch 1313/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4485 - accuracy: 0.7952 - val_loss: 0.4833 - val_accuracy: 0.7922\n",
            "Epoch 1314/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4485 - accuracy: 0.7952 - val_loss: 0.4835 - val_accuracy: 0.7922\n",
            "Epoch 1315/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4486 - accuracy: 0.7989 - val_loss: 0.4835 - val_accuracy: 0.7922\n",
            "Epoch 1316/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4483 - accuracy: 0.7989 - val_loss: 0.4835 - val_accuracy: 0.7922\n",
            "Epoch 1317/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4485 - accuracy: 0.7970 - val_loss: 0.4835 - val_accuracy: 0.7922\n",
            "Epoch 1318/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4484 - accuracy: 0.7989 - val_loss: 0.4838 - val_accuracy: 0.7922\n",
            "Epoch 1319/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4484 - accuracy: 0.7970 - val_loss: 0.4842 - val_accuracy: 0.7922\n",
            "Epoch 1320/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4483 - accuracy: 0.7989 - val_loss: 0.4842 - val_accuracy: 0.7922\n",
            "Epoch 1321/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4482 - accuracy: 0.7970 - val_loss: 0.4841 - val_accuracy: 0.7922\n",
            "Epoch 1322/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.7970 - val_loss: 0.4842 - val_accuracy: 0.7922\n",
            "Epoch 1323/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4481 - accuracy: 0.7952 - val_loss: 0.4840 - val_accuracy: 0.7922\n",
            "Epoch 1324/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4480 - accuracy: 0.7989 - val_loss: 0.4841 - val_accuracy: 0.7922\n",
            "Epoch 1325/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4482 - accuracy: 0.7933 - val_loss: 0.4838 - val_accuracy: 0.7922\n",
            "Epoch 1326/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4481 - accuracy: 0.7970 - val_loss: 0.4837 - val_accuracy: 0.7922\n",
            "Epoch 1327/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4480 - accuracy: 0.7989 - val_loss: 0.4842 - val_accuracy: 0.7922\n",
            "Epoch 1328/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4481 - accuracy: 0.7970 - val_loss: 0.4841 - val_accuracy: 0.7922\n",
            "Epoch 1329/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4478 - accuracy: 0.7952 - val_loss: 0.4841 - val_accuracy: 0.7922\n",
            "Epoch 1330/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4479 - accuracy: 0.7970 - val_loss: 0.4843 - val_accuracy: 0.7922\n",
            "Epoch 1331/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4478 - accuracy: 0.7952 - val_loss: 0.4843 - val_accuracy: 0.7922\n",
            "Epoch 1332/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4477 - accuracy: 0.7970 - val_loss: 0.4845 - val_accuracy: 0.7922\n",
            "Epoch 1333/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4477 - accuracy: 0.7970 - val_loss: 0.4849 - val_accuracy: 0.7922\n",
            "Epoch 1334/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4479 - accuracy: 0.7952 - val_loss: 0.4846 - val_accuracy: 0.7922\n",
            "Epoch 1335/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4477 - accuracy: 0.7952 - val_loss: 0.4849 - val_accuracy: 0.7922\n",
            "Epoch 1336/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4476 - accuracy: 0.7970 - val_loss: 0.4849 - val_accuracy: 0.7922\n",
            "Epoch 1337/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4475 - accuracy: 0.7970 - val_loss: 0.4849 - val_accuracy: 0.7922\n",
            "Epoch 1338/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4473 - accuracy: 0.7952 - val_loss: 0.4844 - val_accuracy: 0.7922\n",
            "Epoch 1339/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4475 - accuracy: 0.7952 - val_loss: 0.4844 - val_accuracy: 0.7922\n",
            "Epoch 1340/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.7970 - val_loss: 0.4845 - val_accuracy: 0.7922\n",
            "Epoch 1341/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4474 - accuracy: 0.7970 - val_loss: 0.4847 - val_accuracy: 0.7922\n",
            "Epoch 1342/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4473 - accuracy: 0.7952 - val_loss: 0.4848 - val_accuracy: 0.7922\n",
            "Epoch 1343/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.7970 - val_loss: 0.4847 - val_accuracy: 0.7922\n",
            "Epoch 1344/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4473 - accuracy: 0.7952 - val_loss: 0.4852 - val_accuracy: 0.7922\n",
            "Epoch 1345/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4474 - accuracy: 0.7970 - val_loss: 0.4848 - val_accuracy: 0.7922\n",
            "Epoch 1346/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4473 - accuracy: 0.7952 - val_loss: 0.4850 - val_accuracy: 0.7922\n",
            "Epoch 1347/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4473 - accuracy: 0.7952 - val_loss: 0.4847 - val_accuracy: 0.7922\n",
            "Epoch 1348/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4472 - accuracy: 0.7970 - val_loss: 0.4849 - val_accuracy: 0.7922\n",
            "Epoch 1349/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4470 - accuracy: 0.7970 - val_loss: 0.4850 - val_accuracy: 0.7922\n",
            "Epoch 1350/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4472 - accuracy: 0.7970 - val_loss: 0.4846 - val_accuracy: 0.7922\n",
            "Epoch 1351/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4471 - accuracy: 0.7970 - val_loss: 0.4847 - val_accuracy: 0.7922\n",
            "Epoch 1352/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4471 - accuracy: 0.7952 - val_loss: 0.4846 - val_accuracy: 0.7922\n",
            "Epoch 1353/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4470 - accuracy: 0.7989 - val_loss: 0.4848 - val_accuracy: 0.7922\n",
            "Epoch 1354/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4469 - accuracy: 0.7970 - val_loss: 0.4847 - val_accuracy: 0.7922\n",
            "Epoch 1355/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4470 - accuracy: 0.7952 - val_loss: 0.4845 - val_accuracy: 0.7922\n",
            "Epoch 1356/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4470 - accuracy: 0.7952 - val_loss: 0.4851 - val_accuracy: 0.7922\n",
            "Epoch 1357/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4469 - accuracy: 0.7952 - val_loss: 0.4843 - val_accuracy: 0.7922\n",
            "Epoch 1358/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4469 - accuracy: 0.7952 - val_loss: 0.4842 - val_accuracy: 0.7922\n",
            "Epoch 1359/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4469 - accuracy: 0.7970 - val_loss: 0.4842 - val_accuracy: 0.7922\n",
            "Epoch 1360/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4468 - accuracy: 0.7952 - val_loss: 0.4847 - val_accuracy: 0.7922\n",
            "Epoch 1361/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4468 - accuracy: 0.7970 - val_loss: 0.4848 - val_accuracy: 0.7922\n",
            "Epoch 1362/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4469 - accuracy: 0.7970 - val_loss: 0.4851 - val_accuracy: 0.7922\n",
            "Epoch 1363/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4466 - accuracy: 0.7970 - val_loss: 0.4850 - val_accuracy: 0.7922\n",
            "Epoch 1364/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4466 - accuracy: 0.7989 - val_loss: 0.4847 - val_accuracy: 0.7922\n",
            "Epoch 1365/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4467 - accuracy: 0.7970 - val_loss: 0.4846 - val_accuracy: 0.7922\n",
            "Epoch 1366/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4465 - accuracy: 0.7970 - val_loss: 0.4850 - val_accuracy: 0.7922\n",
            "Epoch 1367/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4465 - accuracy: 0.7970 - val_loss: 0.4852 - val_accuracy: 0.7922\n",
            "Epoch 1368/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4464 - accuracy: 0.7970 - val_loss: 0.4855 - val_accuracy: 0.7922\n",
            "Epoch 1369/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4464 - accuracy: 0.7970 - val_loss: 0.4857 - val_accuracy: 0.7922\n",
            "Epoch 1370/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4464 - accuracy: 0.7952 - val_loss: 0.4856 - val_accuracy: 0.7922\n",
            "Epoch 1371/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4463 - accuracy: 0.7933 - val_loss: 0.4852 - val_accuracy: 0.7922\n",
            "Epoch 1372/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4464 - accuracy: 0.7970 - val_loss: 0.4854 - val_accuracy: 0.7922\n",
            "Epoch 1373/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4463 - accuracy: 0.7970 - val_loss: 0.4857 - val_accuracy: 0.7922\n",
            "Epoch 1374/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4462 - accuracy: 0.7970 - val_loss: 0.4856 - val_accuracy: 0.7922\n",
            "Epoch 1375/1500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.4463 - accuracy: 0.7970 - val_loss: 0.4855 - val_accuracy: 0.7922\n",
            "Epoch 1376/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4462 - accuracy: 0.7933 - val_loss: 0.4853 - val_accuracy: 0.7922\n",
            "Epoch 1377/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4463 - accuracy: 0.7989 - val_loss: 0.4854 - val_accuracy: 0.7922\n",
            "Epoch 1378/1500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4461 - accuracy: 0.7933 - val_loss: 0.4853 - val_accuracy: 0.7922\n",
            "Epoch 1379/1500\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.4462 - accuracy: 0.7989 - val_loss: 0.4855 - val_accuracy: 0.7922\n",
            "Epoch 1380/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4460 - accuracy: 0.7952 - val_loss: 0.4853 - val_accuracy: 0.7922\n",
            "Epoch 1381/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4459 - accuracy: 0.7970 - val_loss: 0.4856 - val_accuracy: 0.7922\n",
            "Epoch 1382/1500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4461 - accuracy: 0.7970 - val_loss: 0.4854 - val_accuracy: 0.7922\n",
            "Epoch 1383/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4460 - accuracy: 0.7933 - val_loss: 0.4854 - val_accuracy: 0.7922\n",
            "Epoch 1384/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4461 - accuracy: 0.7989 - val_loss: 0.4856 - val_accuracy: 0.7922\n",
            "Epoch 1385/1500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4460 - accuracy: 0.7989 - val_loss: 0.4858 - val_accuracy: 0.7922\n",
            "Epoch 1386/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4460 - accuracy: 0.7970 - val_loss: 0.4856 - val_accuracy: 0.7922\n",
            "Epoch 1387/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4459 - accuracy: 0.7952 - val_loss: 0.4856 - val_accuracy: 0.7922\n",
            "Epoch 1388/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4459 - accuracy: 0.7970 - val_loss: 0.4854 - val_accuracy: 0.7922\n",
            "Epoch 1389/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4457 - accuracy: 0.7970 - val_loss: 0.4854 - val_accuracy: 0.7922\n",
            "Epoch 1390/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4457 - accuracy: 0.7970 - val_loss: 0.4853 - val_accuracy: 0.7922\n",
            "Epoch 1391/1500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.4458 - accuracy: 0.7933 - val_loss: 0.4853 - val_accuracy: 0.7922\n",
            "Epoch 1392/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4458 - accuracy: 0.7989 - val_loss: 0.4856 - val_accuracy: 0.7922\n",
            "Epoch 1393/1500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.4456 - accuracy: 0.7952 - val_loss: 0.4852 - val_accuracy: 0.7922\n",
            "Epoch 1394/1500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4456 - accuracy: 0.7952 - val_loss: 0.4854 - val_accuracy: 0.7922\n",
            "Epoch 1395/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4456 - accuracy: 0.7989 - val_loss: 0.4857 - val_accuracy: 0.7922\n",
            "Epoch 1396/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4457 - accuracy: 0.7952 - val_loss: 0.4856 - val_accuracy: 0.7922\n",
            "Epoch 1397/1500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4456 - accuracy: 0.7952 - val_loss: 0.4853 - val_accuracy: 0.7922\n",
            "Epoch 1398/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4456 - accuracy: 0.7989 - val_loss: 0.4858 - val_accuracy: 0.7922\n",
            "Epoch 1399/1500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4455 - accuracy: 0.7952 - val_loss: 0.4860 - val_accuracy: 0.7922\n",
            "Epoch 1400/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4456 - accuracy: 0.7970 - val_loss: 0.4858 - val_accuracy: 0.7922\n",
            "Epoch 1401/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4455 - accuracy: 0.7970 - val_loss: 0.4861 - val_accuracy: 0.7922\n",
            "Epoch 1402/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4456 - accuracy: 0.7952 - val_loss: 0.4855 - val_accuracy: 0.7922\n",
            "Epoch 1403/1500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4453 - accuracy: 0.7989 - val_loss: 0.4859 - val_accuracy: 0.7922\n",
            "Epoch 1404/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4455 - accuracy: 0.7970 - val_loss: 0.4857 - val_accuracy: 0.7922\n",
            "Epoch 1405/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4454 - accuracy: 0.7989 - val_loss: 0.4861 - val_accuracy: 0.7922\n",
            "Epoch 1406/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4454 - accuracy: 0.7989 - val_loss: 0.4863 - val_accuracy: 0.7922\n",
            "Epoch 1407/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4453 - accuracy: 0.7989 - val_loss: 0.4863 - val_accuracy: 0.7922\n",
            "Epoch 1408/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4453 - accuracy: 0.7952 - val_loss: 0.4863 - val_accuracy: 0.7922\n",
            "Epoch 1409/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4452 - accuracy: 0.7933 - val_loss: 0.4861 - val_accuracy: 0.7922\n",
            "Epoch 1410/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4451 - accuracy: 0.7970 - val_loss: 0.4863 - val_accuracy: 0.7922\n",
            "Epoch 1411/1500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4453 - accuracy: 0.7970 - val_loss: 0.4865 - val_accuracy: 0.7922\n",
            "Epoch 1412/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4452 - accuracy: 0.7989 - val_loss: 0.4862 - val_accuracy: 0.7922\n",
            "Epoch 1413/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4454 - accuracy: 0.7970 - val_loss: 0.4864 - val_accuracy: 0.7922\n",
            "Epoch 1414/1500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4451 - accuracy: 0.8007 - val_loss: 0.4868 - val_accuracy: 0.7922\n",
            "Epoch 1415/1500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4449 - accuracy: 0.7989 - val_loss: 0.4867 - val_accuracy: 0.7922\n",
            "Epoch 1416/1500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4451 - accuracy: 0.7970 - val_loss: 0.4866 - val_accuracy: 0.7922\n",
            "Epoch 1417/1500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4450 - accuracy: 0.7989 - val_loss: 0.4867 - val_accuracy: 0.7922\n",
            "Epoch 1418/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4450 - accuracy: 0.7989 - val_loss: 0.4861 - val_accuracy: 0.7922\n",
            "Epoch 1419/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4449 - accuracy: 0.7989 - val_loss: 0.4866 - val_accuracy: 0.7922\n",
            "Epoch 1420/1500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4449 - accuracy: 0.7970 - val_loss: 0.4866 - val_accuracy: 0.7922\n",
            "Epoch 1421/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4450 - accuracy: 0.7989 - val_loss: 0.4867 - val_accuracy: 0.7922\n",
            "Epoch 1422/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4449 - accuracy: 0.7970 - val_loss: 0.4867 - val_accuracy: 0.7922\n",
            "Epoch 1423/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4449 - accuracy: 0.7989 - val_loss: 0.4867 - val_accuracy: 0.7922\n",
            "Epoch 1424/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4448 - accuracy: 0.7952 - val_loss: 0.4867 - val_accuracy: 0.7922\n",
            "Epoch 1425/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4449 - accuracy: 0.7989 - val_loss: 0.4867 - val_accuracy: 0.7922\n",
            "Epoch 1426/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4447 - accuracy: 0.7989 - val_loss: 0.4871 - val_accuracy: 0.7922\n",
            "Epoch 1427/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4446 - accuracy: 0.7989 - val_loss: 0.4872 - val_accuracy: 0.7922\n",
            "Epoch 1428/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4448 - accuracy: 0.7989 - val_loss: 0.4870 - val_accuracy: 0.7922\n",
            "Epoch 1429/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4445 - accuracy: 0.7970 - val_loss: 0.4872 - val_accuracy: 0.7922\n",
            "Epoch 1430/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4446 - accuracy: 0.7970 - val_loss: 0.4871 - val_accuracy: 0.7922\n",
            "Epoch 1431/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4447 - accuracy: 0.7970 - val_loss: 0.4869 - val_accuracy: 0.7922\n",
            "Epoch 1432/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4446 - accuracy: 0.7952 - val_loss: 0.4866 - val_accuracy: 0.7922\n",
            "Epoch 1433/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4446 - accuracy: 0.8007 - val_loss: 0.4871 - val_accuracy: 0.7922\n",
            "Epoch 1434/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4445 - accuracy: 0.8007 - val_loss: 0.4870 - val_accuracy: 0.7922\n",
            "Epoch 1435/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4445 - accuracy: 0.7989 - val_loss: 0.4870 - val_accuracy: 0.7922\n",
            "Epoch 1436/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4445 - accuracy: 0.7989 - val_loss: 0.4871 - val_accuracy: 0.7922\n",
            "Epoch 1437/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4445 - accuracy: 0.7933 - val_loss: 0.4868 - val_accuracy: 0.7922\n",
            "Epoch 1438/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4445 - accuracy: 0.7989 - val_loss: 0.4871 - val_accuracy: 0.7922\n",
            "Epoch 1439/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4445 - accuracy: 0.7989 - val_loss: 0.4868 - val_accuracy: 0.7922\n",
            "Epoch 1440/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4443 - accuracy: 0.8007 - val_loss: 0.4870 - val_accuracy: 0.7922\n",
            "Epoch 1441/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4443 - accuracy: 0.7970 - val_loss: 0.4867 - val_accuracy: 0.7922\n",
            "Epoch 1442/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4442 - accuracy: 0.7989 - val_loss: 0.4871 - val_accuracy: 0.7922\n",
            "Epoch 1443/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4444 - accuracy: 0.7970 - val_loss: 0.4867 - val_accuracy: 0.7922\n",
            "Epoch 1444/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4442 - accuracy: 0.8007 - val_loss: 0.4871 - val_accuracy: 0.7922\n",
            "Epoch 1445/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4442 - accuracy: 0.7989 - val_loss: 0.4872 - val_accuracy: 0.7922\n",
            "Epoch 1446/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4442 - accuracy: 0.7970 - val_loss: 0.4871 - val_accuracy: 0.7922\n",
            "Epoch 1447/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.8026 - val_loss: 0.4874 - val_accuracy: 0.7922\n",
            "Epoch 1448/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4442 - accuracy: 0.7970 - val_loss: 0.4869 - val_accuracy: 0.7922\n",
            "Epoch 1449/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.7989 - val_loss: 0.4872 - val_accuracy: 0.7922\n",
            "Epoch 1450/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4441 - accuracy: 0.7970 - val_loss: 0.4872 - val_accuracy: 0.7922\n",
            "Epoch 1451/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4439 - accuracy: 0.7989 - val_loss: 0.4874 - val_accuracy: 0.7922\n",
            "Epoch 1452/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4439 - accuracy: 0.7970 - val_loss: 0.4869 - val_accuracy: 0.7922\n",
            "Epoch 1453/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4440 - accuracy: 0.7970 - val_loss: 0.4869 - val_accuracy: 0.7922\n",
            "Epoch 1454/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4441 - accuracy: 0.7989 - val_loss: 0.4869 - val_accuracy: 0.7922\n",
            "Epoch 1455/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4440 - accuracy: 0.7970 - val_loss: 0.4872 - val_accuracy: 0.7922\n",
            "Epoch 1456/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4440 - accuracy: 0.7989 - val_loss: 0.4876 - val_accuracy: 0.7922\n",
            "Epoch 1457/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4440 - accuracy: 0.7970 - val_loss: 0.4878 - val_accuracy: 0.7922\n",
            "Epoch 1458/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4438 - accuracy: 0.7989 - val_loss: 0.4874 - val_accuracy: 0.7922\n",
            "Epoch 1459/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4438 - accuracy: 0.7970 - val_loss: 0.4873 - val_accuracy: 0.7922\n",
            "Epoch 1460/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4439 - accuracy: 0.7989 - val_loss: 0.4873 - val_accuracy: 0.7922\n",
            "Epoch 1461/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4440 - accuracy: 0.7989 - val_loss: 0.4875 - val_accuracy: 0.7922\n",
            "Epoch 1462/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4439 - accuracy: 0.7970 - val_loss: 0.4879 - val_accuracy: 0.7922\n",
            "Epoch 1463/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4438 - accuracy: 0.7952 - val_loss: 0.4878 - val_accuracy: 0.7922\n",
            "Epoch 1464/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4438 - accuracy: 0.7970 - val_loss: 0.4878 - val_accuracy: 0.7922\n",
            "Epoch 1465/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4437 - accuracy: 0.7989 - val_loss: 0.4879 - val_accuracy: 0.7922\n",
            "Epoch 1466/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.7970 - val_loss: 0.4875 - val_accuracy: 0.7922\n",
            "Epoch 1467/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4437 - accuracy: 0.7989 - val_loss: 0.4878 - val_accuracy: 0.7922\n",
            "Epoch 1468/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4436 - accuracy: 0.8007 - val_loss: 0.4878 - val_accuracy: 0.7922\n",
            "Epoch 1469/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4437 - accuracy: 0.7989 - val_loss: 0.4873 - val_accuracy: 0.7922\n",
            "Epoch 1470/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4437 - accuracy: 0.8007 - val_loss: 0.4877 - val_accuracy: 0.7922\n",
            "Epoch 1471/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.8007 - val_loss: 0.4876 - val_accuracy: 0.7922\n",
            "Epoch 1472/1500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.7989 - val_loss: 0.4877 - val_accuracy: 0.7922\n",
            "Epoch 1473/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4433 - accuracy: 0.8007 - val_loss: 0.4878 - val_accuracy: 0.7922\n",
            "Epoch 1474/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4436 - accuracy: 0.8007 - val_loss: 0.4880 - val_accuracy: 0.7922\n",
            "Epoch 1475/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4435 - accuracy: 0.8007 - val_loss: 0.4878 - val_accuracy: 0.7922\n",
            "Epoch 1476/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4434 - accuracy: 0.7989 - val_loss: 0.4880 - val_accuracy: 0.7922\n",
            "Epoch 1477/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4434 - accuracy: 0.8007 - val_loss: 0.4881 - val_accuracy: 0.7922\n",
            "Epoch 1478/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4434 - accuracy: 0.7952 - val_loss: 0.4875 - val_accuracy: 0.7922\n",
            "Epoch 1479/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4435 - accuracy: 0.8007 - val_loss: 0.4878 - val_accuracy: 0.7922\n",
            "Epoch 1480/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4433 - accuracy: 0.7989 - val_loss: 0.4876 - val_accuracy: 0.7922\n",
            "Epoch 1481/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4432 - accuracy: 0.8007 - val_loss: 0.4877 - val_accuracy: 0.7922\n",
            "Epoch 1482/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4431 - accuracy: 0.8026 - val_loss: 0.4880 - val_accuracy: 0.7922\n",
            "Epoch 1483/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4432 - accuracy: 0.8007 - val_loss: 0.4882 - val_accuracy: 0.7922\n",
            "Epoch 1484/1500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4431 - accuracy: 0.7970 - val_loss: 0.4878 - val_accuracy: 0.7922\n",
            "Epoch 1485/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4431 - accuracy: 0.8007 - val_loss: 0.4879 - val_accuracy: 0.7922\n",
            "Epoch 1486/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4432 - accuracy: 0.8026 - val_loss: 0.4879 - val_accuracy: 0.7922\n",
            "Epoch 1487/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4432 - accuracy: 0.8026 - val_loss: 0.4879 - val_accuracy: 0.7922\n",
            "Epoch 1488/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4433 - accuracy: 0.7970 - val_loss: 0.4876 - val_accuracy: 0.7922\n",
            "Epoch 1489/1500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4430 - accuracy: 0.8007 - val_loss: 0.4880 - val_accuracy: 0.7922\n",
            "Epoch 1490/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4431 - accuracy: 0.8045 - val_loss: 0.4882 - val_accuracy: 0.7922\n",
            "Epoch 1491/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4430 - accuracy: 0.7970 - val_loss: 0.4884 - val_accuracy: 0.7922\n",
            "Epoch 1492/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4430 - accuracy: 0.8007 - val_loss: 0.4885 - val_accuracy: 0.7922\n",
            "Epoch 1493/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4429 - accuracy: 0.8026 - val_loss: 0.4881 - val_accuracy: 0.7922\n",
            "Epoch 1494/1500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4430 - accuracy: 0.7989 - val_loss: 0.4882 - val_accuracy: 0.7922\n",
            "Epoch 1495/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4430 - accuracy: 0.7989 - val_loss: 0.4878 - val_accuracy: 0.7965\n",
            "Epoch 1496/1500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4430 - accuracy: 0.8007 - val_loss: 0.4880 - val_accuracy: 0.7965\n",
            "Epoch 1497/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4429 - accuracy: 0.7970 - val_loss: 0.4882 - val_accuracy: 0.7922\n",
            "Epoch 1498/1500\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.4429 - accuracy: 0.7970 - val_loss: 0.4881 - val_accuracy: 0.7965\n",
            "Epoch 1499/1500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4427 - accuracy: 0.8007 - val_loss: 0.4883 - val_accuracy: 0.7965\n",
            "Epoch 1500/1500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4427 - accuracy: 0.8007 - val_loss: 0.4885 - val_accuracy: 0.7965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "200 Epochs\n",
        "- Accuracy: 75.98%\n",
        "- Validation Accuracy: 77.06%\n",
        "- Validation Loss: 46.55%\n",
        "- Loss: 51.04%\n",
        "\n",
        "500 Epochs\n",
        "- Accuracy: 77.84%\n",
        "- Validation Accuracy: 78.35%\n",
        "- Validation Loss: 44.51%\n",
        "- Loss: 46.88%\n",
        "\n",
        "1500 Epochs\n",
        "- Accuracy: 80.07%\n",
        "- Validation Accuracy: 79.65%\n",
        "- Validation Loss: 48.85%\n",
        "- Loss: 44.27%"
      ],
      "metadata": {
        "id": "XJ6N7ZTvNwAV"
      },
      "id": "XJ6N7ZTvNwAV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization"
      ],
      "metadata": {
        "id": "b9k-1VpNQaph"
      },
      "id": "b9k-1VpNQaph"
    },
    {
      "cell_type": "code",
      "source": [
        "#graph the trajectory for 200 epochs\n",
        "\n",
        "run_hist_3.history.keys()\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_3.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_3.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "QloVzd9C9JUC",
        "outputId": "b231d574-ded9-48c4-cc81-79b2284db8fc"
      },
      "id": "QloVzd9C9JUC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7c6f5d5bc820>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trajectory for 500 epochs\n",
        "\n",
        "run_hist_4.history.keys()\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_4.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_4.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "RCxyOFfmOvkz",
        "outputId": "77f3b873-91bf-4ea4-9dc2-54872d4d13e1"
      },
      "id": "RCxyOFfmOvkz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7c6f5c7666b0>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trajectory for 1500 epochs\n",
        "\n",
        "run_hist_5.history.keys()\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_5.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_5.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "S8Ha-UhGUnv5",
        "outputId": "45c14fee-fdd4-428b-b22a-65f48fa9c4d1"
      },
      "id": "S8Ha-UhGUnv5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7c6f5d7cab30>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "intimate-factory",
      "metadata": {
        "id": "intimate-factory"
      },
      "source": [
        "#### Conclusion\n",
        "\n",
        "- In conclusion, we've added modified the network by changing the number of nodes present in each layer, furthermore, we've modified the output layer to contain 2 nodes as we had 2 classification classes, which was Positive and Negative.\n",
        "\n",
        "- In relation to this, changing the epochs to a certain number also helps with the learning of the model, as too many epochs may lead to overfitting whereas the model will not be able to enough opportunity to learn the patterns in the data if the epoch is insuffiecient. According to [Profi](https://www.linkedin.com/advice/3/how-can-you-improve-neural-network-performance-xkrxe#:~:text=If%20we%20train%20for%20too,the%20right%20nr%20of%20epochs.): \"*If we train for too many epochs, the network might become too specialized in the training data, memorizing it instead of learning the general patterns*\". As evident by the 1500 epochs graph wherein we can notice that validation loss slowly increases."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}